<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Xiang&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://canva4.github.io/"/>
  <updated>2020-11-05T13:11:41.993Z</updated>
  <id>http://canva4.github.io/</id>
  
  <author>
    <name>阿翔</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Embedding Literature Review</title>
    <link href="http://canva4.github.io/2020/10/30/Embedding-Literature-Review/"/>
    <id>http://canva4.github.io/2020/10/30/Embedding-Literature-Review/</id>
    <published>2020-10-30T03:14:49.000Z</published>
    <updated>2020-11-05T13:11:41.993Z</updated>
    
    <content type="html"><![CDATA[<p>Embeddings主要思路分类：</p><ul><li>NLP类方法 使用LSTM等对时序数据做表示</li><li>Graph Embedding 对图做嵌入（引入图的原因之一是：用图可以表示复杂关系的长时间时间序列）</li><li>类似CNN的方法也可以看为Embedding</li><li>对比学习，学到更好的表示 or Embedding</li></ul><p>知乎LINKS</p><ol><li>Embedding的原因 <a href="https://zhuanlan.zhihu.com/p/164502624">https://zhuanlan.zhihu.com/p/164502624</a> </li><li>Embedding的简单发展史（主要为Word2vec -&gt; Item2Vec）<a href="https://zhuanlan.zhihu.com/p/164502624">https://zhuanlan.zhihu.com/p/164502624</a></li><li>万物皆可Embedding <a href="https://zhuanlan.zhihu.com/p/109935332">https://zhuanlan.zhihu.com/p/109935332</a></li><li>Embedding在深度学习中的3大方向 <a href="https://zhuanlan.zhihu.com/p/67218758">https://zhuanlan.zhihu.com/p/67218758</a></li><li></li></ol><p>Papers</p><ol><li>Graph Embedding Techniques, Applications, and Performance: A Survey 2017 <a href="https://arxiv.org/abs/1705.02801">LINK</a></li></ol><p>知乎翻译：<a href="https://zhuanlan.zhihu.com/p/62629465">https://zhuanlan.zhihu.com/p/62629465</a></p><ol start="2"><li>A Tutorial on Network Embeddings 2018 <a href="https://arxiv.org/abs/1808.02590">LINK</a></li></ol><p>知乎翻译：<a href="https://zhuanlan.zhihu.com/p/42022918">https://zhuanlan.zhihu.com/p/42022918</a></p><ol start="3"><li>Tutorial on NLP-Inspired Network Embedding 2019 <a href="https://arxiv.org/abs/1910.07212">LINK</a></li></ol><h1 id="Paper-List："><a href="#Paper-List：" class="headerlink" title="Paper List："></a>Paper List：</h1><ol><li>A Tutorial on Network Embeddings 2018</li><li>Tutorial on NLP-Inspired Network Embedding 2019</li><li>DeepWalk</li><li>LINE </li><li>Node2Vec</li><li>GraphAttention</li><li>SDNE</li><li>HOPE</li><li>Learning edge representations via low-rank asymmetric projections  2017</li><li>Deep graph kernels 2015</li></ol><h1 id="A-Tutorial-on-Network-Embeddings"><a href="#A-Tutorial-on-Network-Embeddings" class="headerlink" title="A Tutorial on Network Embeddings"></a>A Tutorial on Network Embeddings</h1><p>Author: Haochen Chen er al <a href="https://arxiv.org/abs/1808.02590">LINK</a></p><p>Journal: Social and Information Networks 2018</p><p><strong>Goal of Network Embeddings：</strong></p><p>Network embedding methods aim at learning low-dimensional latent representation of nodes in a network.</p><p>而获得的embeddings应该有如下的性质：</p><ul><li><strong>适应性（Adaptability）</strong>- 现实的网络在不断发展；新的应用算法不应该要求不断地重复学习过程。</li><li><strong>可扩展性（Scalability）</strong>- 真实网络本质上通常很大，因此网络嵌入算法应该能够在短时间内处理大规模网络。</li><li><strong>社区感知（Community aware）</strong>- 潜在表示之间的距离应表示用于评估网络的相应成员之间的相似性的度量。这就要求同质网络能够泛化。</li><li><strong>低维（Low dimensional）</strong>- 当标记数据稀缺时，低维模型更好地推广并加速收敛和推理。</li><li><strong>连续的（Continuous）</strong></li></ul><h2 id="从传统ML降维的角度看Graph-Embedding"><a href="#从传统ML降维的角度看Graph-Embedding" class="headerlink" title="从传统ML降维的角度看Graph Embedding"></a>从传统ML降维的角度看Graph Embedding</h2><p>这其中使用了例如：PCA和MDS等方法，这类方法都可以看为使用一个n by k矩阵来代表原始数据的n by m矩阵，其中k&lt;m。之后又提出了一些新的降维方法比如：IsoMap，LLE等方法。总体来讲这类方法在小的网络上显示了不错的性能，但由于其复杂度往往随矩阵规模而指数增长，导致这种方法无法应用于大型的图。</p><p>另外一类就是图的谱方法了（如LE: Laplacian eigenmaps），基本上来讲使用拉普拉斯矩阵or标准化的拉普拉斯矩阵的特征值和特征向量的信息来对于每个节点进行聚类和划分以实现嵌入的效果。这类方法的主要问题是：对矩阵的特征值分解是与矩阵规模呈指数形式的，所以在large network中也较难应用，且这类基于spectrum的方法的性能往往逊色于基于neural network的方法。</p><h2 id="The-Age-of-Deep-Learning"><a href="#The-Age-of-Deep-Learning" class="headerlink" title="The Age of Deep Learning"></a>The Age of Deep Learning</h2><p><strong>DeepWalk在图上使用表示学习（或深度学习）的方法，是一个非常经典的方法</strong>。DeepWalk 通过将节点视为单词并生成短随机游走（random walk）作为句子来弥补网络嵌入和单词嵌入之间的差距。然后，可以使用 Skip-gram 等，应用于这些随机游走以获得网络嵌入。</p><p>优点：</p><ul><li>Online algorithm</li><li>Scalable</li></ul><p>也引出了一种在图上使用Deep Learning的paradigm</p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/11/05/ySGZqvIswTxdeLD.png" alt="image-20201105105601325" style="zoom:80%;" /><h2 id="Unsupervised-Network-Embeddings"><a href="#Unsupervised-Network-Embeddings" class="headerlink" title="Unsupervised Network Embeddings"></a>Unsupervised Network Embeddings</h2><p>最经典的还是DeepWalk，其有如下两个地方可以改进：</p><ul><li><p>Source of Context Node（如何产生序列）</p></li><li><p>Embedding Learning Methods(deepwalk中使用skip-gram，当然也可以使用其他学习序列表示的方法)</p></li></ul><p>针对于Deep Walk的可改良点，有这些改进的方法。<img src= "/img/loading.gif" data-lazy-src="C:\Users\12552\AppData\Roaming\Typora\typora-user-images\image-20201105113538975.png" alt="image-20201105113538975"></p><p>其中比较出名的有的：LINE，Node2Vec，GraphAttention等。后面的SDNE和DNGR则引入了deep learning中较深的encoder类方法。</p><p>值得注意的是，这些方法主要是用于undirected graph中的。</p><h3 id="Directed-Graph-Embedding"><a href="#Directed-Graph-Embedding" class="headerlink" title="Directed Graph Embedding"></a>Directed Graph Embedding</h3><p>基本上全部的基于无向图的方法都可以很自然的推广到无向图中。</p><p>其中常见和经典的方法为：HOPE</p><h3 id="Edge-Embedding"><a href="#Edge-Embedding" class="headerlink" title="Edge Embedding"></a>Edge Embedding</h3><p>这类embedding可以用于link prediction等task中。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/11/05/W1Hxt5GgIqs6TDU.png" alt="image-20201105150551272"></p><h3 id="Signed-Graph-Embeddings"><a href="#Signed-Graph-Embeddings" class="headerlink" title="Signed Graph Embeddings"></a>Signed Graph Embeddings</h3><p>Signed Graph指：边的权值只为-1or1，主要方法报过：SiNE和SNE。</p><h3 id="Subgraph-Embeddings"><a href="#Subgraph-Embeddings" class="headerlink" title="Subgraph Embeddings"></a>Subgraph Embeddings</h3><p>经典方法为Deep Kernel也是这类方法的常见范式。</p><h3 id="Meta-strategies-for-Improving-Network-Embeddings"><a href="#Meta-strategies-for-Improving-Network-Embeddings" class="headerlink" title="Meta-strategies for Improving Network Embeddings"></a>Meta-strategies for Improving Network Embeddings</h3><p>主要方法HARP。HARP is a general meta-strategy to improve all of the state-of-the-art neural algorithms for embedding graphs, including DeepWalk, LINE, and Node2vec.</p><h2 id="Attributed-Network-Embeddings"><a href="#Attributed-Network-Embeddings" class="headerlink" title="Attributed Network Embeddings"></a>Attributed Network Embeddings</h2><p>前面的讨论针对的主要是没有attribute的图，而对于有attribute的图，其attribute一般是附加在节点上的，一般主要研究两类attribute</p><ul><li>high-level features such as text or images</li><li>node labels</li></ul><p>针对第一点（high-level features）：常见方法包括：TADW，CENE</p><p>针对第二点（node labels 常见于 引用网络和社交网络）：GENE</p><p>当然在许多真正的网络中，并不是所有节点都是有label的，所以也有一些Semi-supervised的方法设计出来。例如：Planetoid，Max-margin Deep Walk, </p><h2 id="Heterogeneous-Network-Embeddings"><a href="#Heterogeneous-Network-Embeddings" class="headerlink" title="Heterogeneous Network Embeddings"></a>Heterogeneous Network Embeddings</h2><p>Heterogeneous Network/Graph 异质图，即have multiple classes of nodes or edges。大部分异构网络嵌入方法通过联合最小化每种modality的损失来学习节点嵌入。这些方法要么直接在相同的潜在空间中学习所有节点嵌入，要么事先为每个模态构建嵌入，然后将它们映射到相同的潜在空间。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>此paper主要是总结了一下目前常见的和经典的一些图嵌入的方法（连介绍都算不上），也对于在不同应用场景上的方法做了一个分类，很适合在之后想在某个场景使用图嵌入方法时来进行查阅。这部分note也主要是这个目的。作者也简单总结了未来图嵌入可能的发展方向，不过本文是2018年的，之后会跟进一些2018年之后更新的方法。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Embeddings主要思路分类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NLP类方法 使用LSTM等对时序数据做表示&lt;/li&gt;
&lt;li&gt;Graph Embedding 对图做嵌入（引入图的原因之一是：用图可以表示复杂关系的长时间时间序列）&lt;/li&gt;
&lt;li&gt;类似CNN的方法也可以看为
      
    
    </summary>
    
    
      <category term="Works" scheme="http://canVa4.github.io/categories/Works/"/>
    
    
      <category term="Embedding" scheme="http://canVa4.github.io/tags/Embedding/"/>
    
      <category term="Literature Review" scheme="http://canVa4.github.io/tags/Literature-Review/"/>
    
  </entry>
  
  <entry>
    <title>CS224w HomeWork 1</title>
    <link href="http://canva4.github.io/2020/10/28/CS224w-HomeWork-1/"/>
    <id>http://canva4.github.io/2020/10/28/CS224w-HomeWork-1/</id>
    <published>2020-10-28T08:21:31.000Z</published>
    <updated>2020-11-09T08:13:47.834Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CS224w-HomeWork-1"><a href="#CS224w-HomeWork-1" class="headerlink" title="CS224w HomeWork 1"></a>CS224w HomeWork 1</h1><p>本文旨在记录CS224w Machine Learning With Graphs 2019完成作业中遇到的问题和作业的结果。</p><p>我的github仓库 <a href="https://github.com/canVa4/CS224w">LINK</a>。</p><h2 id="Part-1-Network-Characteristics"><a href="#Part-1-Network-Characteristics" class="headerlink" title="Part 1 Network Characteristics"></a>Part 1 Network Characteristics</h2><p>课程中反复强调的一个非常重要的观点就是：想要比较一个网络的属性，我们需要一个criterion或者一个null network。</p><p>所以这部分的核心就是null network or criterion的生成。我们需要生成Erdös-Renyi Random Graphs和Small-World Random Network。</p><h3 id="Erdos-Renyi-Random-Graphs"><a href="#Erdos-Renyi-Random-Graphs" class="headerlink" title="Erdös-Renyi Random Graphs"></a>Erdös-Renyi Random Graphs</h3><p>非常的简单，即：undirected graph with n nodes, and m edges picked uniformly at random. 需要的参数就是节点数和边数了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">genErdosRenyi</span>(<span class="params">N=<span class="number">5242</span>, E=<span class="number">14484</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param - N: number of nodes</span></span><br><span class="line"><span class="string">    :param - E: number of edges</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    return type: snap.PUNGraph</span></span><br><span class="line"><span class="string">    return: Erdos-Renyi graph with N nodes and E edges</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Your code here!</span></span><br><span class="line">    Graph = snap.PUNGraph.New()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        Graph.AddNode(i)</span><br><span class="line">    cnt = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> cnt &lt; E:</span><br><span class="line">        src = np.random.randint(<span class="number">0</span>, N)</span><br><span class="line">        dst = np.random.randint(<span class="number">0</span>, N)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> Graph.IsEdge(src, dst):</span><br><span class="line">            Graph.AddEdge(src, dst)</span><br><span class="line">            cnt += <span class="number">1</span></span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="keyword">return</span> Graph</span><br></pre></td></tr></table></figure><h3 id="Small-World-Random-Network"><a href="#Small-World-Random-Network" class="headerlink" title="Small-World Random Network"></a>Small-World Random Network</h3><p>生成Small-World Random Network需要三步。分别为：</p><ol><li>Begin with N nodes arranged as a ring, i.e. imagine the nodes form a circle and each node is connected to its two direct neighbors.</li><li>Connect each node to the neighbors of its neighbors.</li><li>Randomly select some given number pairs of nodes not yet connected and add an edge between them.</li></ol><p>实现起来并不困难，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">genCircle</span>(<span class="params">N=<span class="number">5242</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param - N: number of nodes</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    return type: snap.PUNGraph</span></span><br><span class="line"><span class="string">    return: Circle graph with N nodes and N edges. Imagine the nodes form a</span></span><br><span class="line"><span class="string">        circle and each node is connected to its two direct neighbors.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Your code here!</span></span><br><span class="line">    Graph = snap.PUNGraph.New()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        Graph.AddNode(i)</span><br><span class="line">    Graph.AddEdge(N - <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N - <span class="number">1</span>):</span><br><span class="line">        Graph.AddEdge(i, i + <span class="number">1</span>)</span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="keyword">return</span> Graph</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">connectNbrOfNbr</span>(<span class="params">Graph, N=<span class="number">5242</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param - Graph: snap.PUNGraph object representing a circle graph on N nodes</span></span><br><span class="line"><span class="string">    :param - N: number of nodes</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    return type: snap.PUNGraph</span></span><br><span class="line"><span class="string">    return: Graph object with additional N edges added by connecting each node</span></span><br><span class="line"><span class="string">        to the neighbors of its neighbors</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Your code here!</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        n1 = (i + <span class="number">1</span> + N) % N</span><br><span class="line">        n2 = (i - <span class="number">1</span> + N) % N</span><br><span class="line">        Graph.AddEdge(n1, n2)</span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="keyword">return</span> Graph</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">connectRandomNodes</span>(<span class="params">Graph, M=<span class="number">4000</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param - Graph: snap.PUNGraph object representing an undirected graph</span></span><br><span class="line"><span class="string">    :param - M: number of edges to be added</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    return type: snap.PUNGraph</span></span><br><span class="line"><span class="string">    return: Graph object with additional M edges added by connecting M randomly</span></span><br><span class="line"><span class="string">        selected pairs of nodes not already connected.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Your code here!</span></span><br><span class="line">    N = Graph.GetNodes()</span><br><span class="line">    cnt = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> cnt &lt; M:</span><br><span class="line">        src = np.random.randint(<span class="number">0</span>, N)</span><br><span class="line">        dst = np.random.randint(<span class="number">0</span>, N)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> Graph.IsEdge(src, dst):</span><br><span class="line">            Graph.AddEdge(src, dst)</span><br><span class="line">            cnt += <span class="number">1</span></span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="keyword">return</span> Graph</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">genSmallWorld</span>(<span class="params">N=<span class="number">5242</span>, E=<span class="number">14484</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param - N: number of nodes</span></span><br><span class="line"><span class="string">    :param - E: number of edges</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    return type: snap.PUNGraph</span></span><br><span class="line"><span class="string">    return: Small-World graph with N nodes and E edges</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    Graph = genCircle(N)</span><br><span class="line">    Graph = connectNbrOfNbr(Graph, N)</span><br><span class="line">    Graph = connectRandomNodes(Graph, <span class="number">4000</span>)</span><br><span class="line">    <span class="keyword">return</span> Graph</span><br></pre></td></tr></table></figure><h3 id="Question-1-1-Degree-Distribution"><a href="#Question-1-1-Degree-Distribution" class="headerlink" title="Question 1.1 Degree Distribution"></a>Question 1.1 Degree Distribution</h3><p>计算Degree Distribution。Degree Distribution就是：</p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/28/XTKUEY1jAedIkOM.png" alt="image-20201028163717245" style="zoom:50%;" /><p>这里并不需要计算出分数，而是直接将度为k的节点数以log-log图画出来。</p><p>这里画图使用matplotlib，首先要生成x,y坐标上对应的数。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getDataPointsToPlot</span>(<span class="params">Graph</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param - Graph: snap.PUNGraph object representing an undirected graph</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    return values:</span></span><br><span class="line"><span class="string">    X: list of degrees</span></span><br><span class="line"><span class="string">    Y: list of frequencies: Y[i] = fraction of nodes with degree X[i]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Your code here!</span></span><br><span class="line">    X, Y = [], []</span><br><span class="line">    DegToCntV = snap.TIntPrV()</span><br><span class="line">    snap.GetDegCnt(Graph, DegToCntV)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> DegToCntV:</span><br><span class="line">        X.append(item.GetVal1())</span><br><span class="line">        Y.append(item.GetVal2())</span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="keyword">return</span> X, Y</span><br></pre></td></tr></table></figure><p>画图部分代码已给出，这里不再列出。值得注意的是画log-log图使用<code>plt.loglog</code>即可。</p><h4 id="Answers"><a href="#Answers" class="headerlink" title="Answers"></a>Answers</h4><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/28/OLJ8VwY4PeaIBxM.png" alt="image-20201028164113889" style="zoom:67%;" /><h3 id="Question-1-2-Clustering-Coefficient"><a href="#Question-1-2-Clustering-Coefficient" class="headerlink" title="Question 1.2 Clustering Coefficient"></a>Question 1.2 Clustering Coefficient</h3><p>计算Clustering Coefficient。公式如下：</p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/28/h2bqeKRVTHPc3uA.png" alt="image-20201028164303055" style="zoom:50%;" /><p>代码如下，可能稍微负责的就是找该节点邻居间边的数量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcClusteringCoefficientSingleNode</span>(<span class="params">Node, Graph</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param - Node: node from snap.PUNGraph object. Graph.Nodes() will give an</span></span><br><span class="line"><span class="string">                   iterable of nodes in a graph</span></span><br><span class="line"><span class="string">    :param - Graph: snap.PUNGraph object representing an undirected graph</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    return type: float</span></span><br><span class="line"><span class="string">    returns: local clustering coeffient of Node</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Your code here!</span></span><br><span class="line">    C = <span class="number">0.0</span></span><br><span class="line">    neigbors = []</span><br><span class="line">    deg = Node.GetDeg()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(deg):</span><br><span class="line">        neigbors.append(Graph.GetNI(Node.GetNbrNId(i)))</span><br><span class="line">    cnt_nbr = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(deg):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i):</span><br><span class="line">            cnt_nbr += neigbors[i].IsInNId(neigbors[j].GetId())</span><br><span class="line">    <span class="keyword">if</span> deg &gt;= <span class="number">2</span>:</span><br><span class="line">        C = <span class="number">2</span> * cnt_nbr / (deg * (deg - <span class="number">1.0</span>))</span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="keyword">return</span> C</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcClusteringCoefficient</span>(<span class="params">Graph</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param - Graph: snap.PUNGraph object representing an undirected graph</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    return type: float</span></span><br><span class="line"><span class="string">    returns: clustering coeffient of Graph</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Your code here! If you filled out calcClusteringCoefficientSingleNode,</span></span><br><span class="line">    <span class="comment">#       you&#x27;ll probably want to call it in a loop here</span></span><br><span class="line">    C = <span class="number">0.0</span></span><br><span class="line">    V = Graph.GetNodes()</span><br><span class="line">    <span class="keyword">for</span> NI <span class="keyword">in</span> Graph.Nodes():</span><br><span class="line">        Ci = calcClusteringCoefficientSingleNode(NI, Graph)</span><br><span class="line">        C = C + Ci</span><br><span class="line">    C = C / V</span><br><span class="line"></span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="keyword">return</span> C</span><br></pre></td></tr></table></figure><h4 id="Answers-1"><a href="#Answers-1" class="headerlink" title="Answers"></a>Answers</h4><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/28/CitYa4IGqexDrbW.png" alt="image-20201028165111378"  /><h2 id="Part-2-Structural-Roles-Rolx-and-ReFex"><a href="#Part-2-Structural-Roles-Rolx-and-ReFex" class="headerlink" title="Part 2 Structural Roles: Rolx and ReFex"></a>Part 2 Structural Roles: Rolx and ReFex</h2><p>本部分主要是implement计算每个节点Structural Role的方法（实现Rolx 和 ReFex方法），可以看做一种对于每个节点拓扑信息的提取方法，将每个节点的拓扑信息变为一个向量，即实现一个feature extraction的方法。这里的feature extraction主要包含两步：</p><ol><li>Basic Features: First extract basic local features from every node.</li><li>Recursive Features: Then aggregate the basic features along graph edges so that global features are also obtained.</li></ol><h3 id="Basic-Features"><a href="#Basic-Features" class="headerlink" title="Basic Features"></a>Basic Features</h3><p>首先是计算basic feature，主要指的是节点本身的local features。这里计算的basic feature为一个三维向量。</p><p>其三个维度的意义是：</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/29/EdNXguTZCts9Bnj.png" alt="image-20201029171924469"></p><p>这里简单的记录一下计算2和3的方法。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/29/24UTaJ1bmz5vQWE.png" alt="image-20201029195853008"></p><p>有了上图，这几个关系就很明确了，将代码完善即可。</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_basic_features</span>(<span class="params">node, graph</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    提取basic features</span></span><br><span class="line"><span class="string">    :param node: 目标节点，SNAP中的node类，而非ID，可以用GetNI()获得</span></span><br><span class="line"><span class="string">    :param graph: 目标图（无向图）</span></span><br><span class="line"><span class="string">    :return: 长度为3的array 分别为：该节点deg，egonet内部deg，进出egonet的边数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    degree = node.GetDeg()</span><br><span class="line"></span><br><span class="line">    neighbors = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算全部邻居的deg的和</span></span><br><span class="line">    total_deg_nbr = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(degree):</span><br><span class="line">        <span class="comment"># 获取全部的邻居，目标构建egonet</span></span><br><span class="line">        neighbor = graph.GetNI(node.GetNbrNId(i))</span><br><span class="line">        neighbors.append(neighbor)</span><br><span class="line">        total_deg_nbr += neighbor.GetDeg()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算邻居之间边的数量</span></span><br><span class="line">    edge_between_nbr = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(neighbors)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i):</span><br><span class="line">            edge_between_nbr += neighbors[i].IsNbrNId(neighbors[j].GetId())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.array((degree, edge_between_nbr + degree, total_deg_nbr - <span class="number">2</span> * edge_between_nbr - degree))</span><br></pre></td></tr></table></figure><p>我的结果为：</p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/29/CRQPthH7lSfYaWc.png" alt="image-20201029200007798" style="zoom:50%;" /><h3 id="Recursive-Features"><a href="#Recursive-Features" class="headerlink" title="Recursive Features"></a>Recursive Features</h3><p>也相对简单，使用下图的公式即可。具体细节，请参照官方作业的pdf。</p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/29/4ND6q9Hz8xIWJap.png" alt="image-20201029200049787" style="zoom: 67%;" /><p>核心函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">recursive_features</span>(<span class="params">v_mat, graph</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    迭代一次</span></span><br><span class="line"><span class="string">    :param v_mat: np array</span></span><br><span class="line"><span class="string">    :param graph: 目标图</span></span><br><span class="line"><span class="string">    :return: 新的v_mat，向量长度变为原来的3倍</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    cnt_node, ori_len = v_mat.shape</span><br><span class="line">    new_mat = np.zeros((cnt_node, ori_len))</span><br><span class="line">    mean_mat = np.zeros((cnt_node, ori_len))</span><br><span class="line">    sum_mat = np.zeros((cnt_node, ori_len))</span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> graph.Nodes():</span><br><span class="line">        nodeId = node.GetId()</span><br><span class="line">        cnt_nbrs = node.GetDeg()</span><br><span class="line">        new_mat[nodeId] = v_mat[nodeId]</span><br><span class="line">        <span class="keyword">if</span> cnt_nbrs == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(cnt_nbrs):</span><br><span class="line">            nbr_id = node.GetNbrNId(i)</span><br><span class="line">            mean_mat[nodeId] += v_mat[nbr_id]</span><br><span class="line">            sum_mat[nodeId] += v_mat[nbr_id]</span><br><span class="line">        mean_mat[nodeId] = mean_mat[nodeId] / cnt_nbrs</span><br><span class="line">    <span class="keyword">return</span> np.concatenate((new_mat, mean_mat, sum_mat), axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>结果如下：</p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/29/kfYKOELZ7HrcUAy.png" alt="image-20201029200224081" style="zoom:50%;" /><h3 id="Role-Discovery"><a href="#Role-Discovery" class="headerlink" title="Role Discovery"></a>Role Discovery</h3><p>主要工作即为：根据计算出的迭代3次的cosine similarity，绘出其分布直方图；根据直方图判别有几种role（看凸起即可），并随机选一个role中的一个节点，根据其local(basic) feature绘制其2-hop子图。唯一难点可能就是2-hop子图的绘制，这里我使用了networkx来绘制。我使用了python中的set()来滤去重复节点，这种方法时间复杂度显然很高。不过对于小图而言还是能接受的。</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Draw_SubGraph</span>(<span class="params">Graph, Node_id</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    绘图函数 Node 节点2-hop子图</span></span><br><span class="line"><span class="string">    :param Graph: 目标图</span></span><br><span class="line"><span class="string">    :param NI_id: 目标节点</span></span><br><span class="line"><span class="string">    :return: 无</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    Nodes = []</span><br><span class="line">    Edges = []</span><br><span class="line">    center_node = Graph.GetNI(Node_id)</span><br><span class="line">    Nodes.append(Node_id)</span><br><span class="line">    colors = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 所有1-hop节点放进去</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(center_node.GetDeg()):</span><br><span class="line">        nbr_id = center_node.GetNbrNId(i)</span><br><span class="line">        Nodes.append(nbr_id)</span><br><span class="line">    <span class="comment"># 所有2-hop节点放进去</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(Nodes)):</span><br><span class="line">        mid_node = Graph.GetNI(Nodes[i])</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(mid_node.GetDeg()):</span><br><span class="line">            nbr_id = mid_node.GetNbrNId(j)</span><br><span class="line">            Nodes.append(nbr_id)</span><br><span class="line">    Nodes = list(set(Nodes))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> mid_id <span class="keyword">in</span> Nodes:</span><br><span class="line">        <span class="keyword">if</span> mid_id == Node_id:</span><br><span class="line">            colors.append(<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            colors.append(<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">    <span class="comment"># print(Nodes)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(Nodes)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i):</span><br><span class="line">            <span class="keyword">if</span> Graph.IsEdge(Nodes[i], Nodes[j]):</span><br><span class="line">                Edges.append((Nodes[i], Nodes[j]))</span><br><span class="line">    <span class="comment"># print(len(Edges))</span></span><br><span class="line">    G = nx.Graph()</span><br><span class="line">    G.add_nodes_from(Nodes)</span><br><span class="line">    G.add_edges_from(Edges)</span><br><span class="line">    nx.draw_networkx(G, node_color=colors)</span><br><span class="line">    <span class="comment"># plt.show()</span></span><br></pre></td></tr></table></figure><p>运行结果如下：分别为直方图和2-hop子图。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/29/86VsXSJYwZ3DnNR.png" alt="image-20201029200326758" style="zoom:50%;" /><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/29/jgJoFmLKwrCZ2QD.png" alt="image-20201029200838918" style="zoom:50%;" /></p><h3 id="Overall"><a href="#Overall" class="headerlink" title="Overall"></a>Overall</h3><p>最大的感觉就是光听一遍和写完一遍代码对于整个流程完全有着不同程度的理解，还是得多练啊。。。</p><p>中间也卡了不少次，花费了不少的时间T.T</p><h2 id="Part-3-Community-detection-using-the-Louvain-algorithm"><a href="#Part-3-Community-detection-using-the-Louvain-algorithm" class="headerlink" title="Part 3 Community detection using the Louvain algorithm"></a>Part 3 Community detection using the Louvain algorithm</h2><p><strong>Community is just sets of tightly connected nodes.</strong></p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/11/03/KLAc6P95G8W4dxv.png" alt="image-20201103104601046" style="zoom:67%;" /><p>如上图所示，这个就是Community Detection后的结果。这类Community detection的算法一般将：原本问题变为一个优化问题。</p><p>首先是定义一个优化目标，其应该是A measure of how well a network is partitioned into communities，该值正比于划分的好坏.  即对于每一个可能的partition都给出一个分数，目标就是找到使该分数最大的一个划分。这里使用的指标为：<strong>Modularity</strong>。定义如下图所示。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/11/03/KxdW8jNcHizRuSg.png" alt="image-20201103105343050" style="zoom:80%;" />公式化之后变为：注：这里的Null model使用的是<strong>configuration model</strong>。即：有同样的degree distribution但node之间的连接是uniformly random的。</p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/11/03/W1ZkKhylRXFou7Q.png" alt="image-20201103104747043" style="zoom: 80%;" /><p>其取值在[-1,1]之间，It is positive if the number of edges within groups exceeds the expected number. </p><p>然而直接优化这个问题是一个NP hard问题。所以提出了<strong>Louvain algorithm</strong>。这是一种greedy algorithm。并且可以提供一种<strong>Hierarchical communities</strong>. 其整体流程如下：</p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/11/03/wY4eihbvVKT65F3.png" alt="image-20201103110548639" style="zoom:80%;" /><p>值得注意的是这种方法假设：community是disjoint的。</p><h3 id="Q3-1-Proof-for-Modularity-gain-when-an-isolated-node-moves-into-a-community"><a href="#Q3-1-Proof-for-Modularity-gain-when-an-isolated-node-moves-into-a-community" class="headerlink" title="Q3-1 Proof for Modularity gain when an isolated node moves into a community"></a>Q3-1 Proof for Modularity gain when an isolated node moves into a community</h3><p>证明如图：</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/11/03/65UYz17gLoMFIQq.png" alt="image-20201103150122229"></p><h3 id="Q3-2-Louvain-algorithm-on-a-16-node-network"><a href="#Q3-2-Louvain-algorithm-on-a-16-node-network" class="headerlink" title="Q3-2 Louvain algorithm on a 16 node network"></a>Q3-2 Louvain algorithm on a 16 node network</h3><p>Answers for Graph H:</p><ol><li>1</li><li>12 NOTE: 6*2</li><li>$4 \cdot Q_c = 4(\frac{12}{2m}-\frac{14^2}{4m^2})$,where $m=12\cdot4+1\cdot4=52$, Q=0.158</li></ol><p>Answers for Graph J:</p><ol><li>2</li><li>26</li><li>Q=2(26/104-(28/104)^2)=0.355</li></ol><h3 id="Q3-3-Louvain-algorithm-on-a-128-node-network"><a href="#Q3-3-Louvain-algorithm-on-a-128-node-network" class="headerlink" title="Q3-3 Louvain algorithm on a 128 node network"></a>Q3-3 Louvain algorithm on a 128 node network</h3><p>与Q3-2是相同的计算方式，比较简单，不再计算一遍了。</p><h2 id="Part-4-Spectral-clustering"><a href="#Part-4-Spectral-clustering" class="headerlink" title="Part 4 Spectral clustering"></a>Part 4 Spectral clustering</h2><p>经典的谱聚类的方法。讲得还是很精彩和清晰的。我在这里简单的总结一下整体的思路框架。</p><p>首先是谱聚类的目标，对于图做一个good partition分成不同的部分，即不同的clustering。</p><p>所以我们要有一个指标来衡量一个good partition。引出了cut。</p><p>+</p><p>这个指标的最大问题是没有将每个cluster内部的连接考虑进去，在优化该指标时，即最小化cut指标时，我们总可以找到如下的“最优指标”，但该指标显然不是我们期望的。原因就是没有考虑每个cluster内部的连接。</p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/11/04/BWUP9Rpac2CGjdl.png" alt="image-20201104163807540" style="zoom:67%;" /><p>为了解决这个问题，引入了指标<strong>Conductance</strong></p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/11/04/aFuU1NYBLbfhvie.png" alt="image-20201104163936635"></p><p>相当于对于cluster的连接做了一个正则，这样优化该指标，我们可以找到一个更好的partition。</p><p>下面作者引入了邻接矩阵的谱，拉普拉斯矩阵的谱（拉普拉斯矩阵有很好的性质，半正定矩阵，必定有全1向量为eigenvector，其对应了eigenvalue为0），最终将寻找第二小的特征值和特征向量与一个partition挂钩（直观解释），并且从理论推导出小的特征值为最优Conductance的一个下界。这样就寻找将拉普拉斯矩阵第二小的特征值和特征向量和找到最优partition联系了起来。简单回顾Spectral Clustering后，开始完成这部分的作业。</p><h3 id="Q4-1-A-Spectral-Algorithm-for-Normalized-Cut-Minimization-Foundations"><a href="#Q4-1-A-Spectral-Algorithm-for-Normalized-Cut-Minimization-Foundations" class="headerlink" title="Q4-1 A Spectral Algorithm for Normalized Cut Minimization: Foundations"></a>Q4-1 A Spectral Algorithm for Normalized Cut Minimization: Foundations</h3><p>一些公式推导的题目，具体题目见官网源文件。</p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/11/04/AUeCo94uExJrwn1.png" alt="image-20201104174652449" style="zoom:80%;" /><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/11/04/OgNUo1s7FDqtGkX.png" alt="image-20201104174758916"></p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/11/04/dgx7PFJvmIj5Qzu.png" alt="image-20201104174838628"></p><h3 id="Q4-2-Normalized-Cut-Minimization-Solving-for-the-Minimizer（Uncertain）"><a href="#Q4-2-Normalized-Cut-Minimization-Solving-for-the-Minimizer（Uncertain）" class="headerlink" title="Q4-2 Normalized Cut Minimization: Solving for the Minimizer（Uncertain）"></a>Q4-2 Normalized Cut Minimization: Solving for the Minimizer（Uncertain）</h3><p>本部分的证明不太确定，最后部分使用的Rayleigh定理不太确定。</p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/11/04/CYFUQRcvtD4VZMO.png" alt="image-20201104210042302" style="zoom:67%;" /><h3 id="Q4-3-Relating-Modularity-to-Cuts-and-Volumes"><a href="#Q4-3-Relating-Modularity-to-Cuts-and-Volumes" class="headerlink" title="Q4-3 Relating Modularity to Cuts and Volumes"></a>Q4-3 Relating Modularity to Cuts and Volumes</h3><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/11/04/FhUZy3amOexgTQi.png" alt="image-20201104205957243"></p><h1 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h1><p>至此homework1的内容全部结束了，整体而言的难度不是很高，在编程上有snap库极大的简化了编程上的难度。整体来讲homework1涉及了很多分析图的方法和非常多的基本却关键的概念。比如：如何衡量一个图的特点（通过一些全局的指标比如：degree distribution，Clustering Coefficient，diameter），这是要和random graph做对比的。包括后面的涉及的如何衡量一个节点的特征（Role），motifs，graphlet的概念，community/group的概念，这些都是分析复杂图的基石。</p><p>整体而言，目前这部分课程也让我对于图论产生了很大的兴趣，由于本人之前没有离散数学or图论的基础，对于一些例如induced graph的概念并不是清楚，之后计划会额外自学一些关于图论方面的知识。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;CS224w-HomeWork-1&quot;&gt;&lt;a href=&quot;#CS224w-HomeWork-1&quot; class=&quot;headerlink&quot; title=&quot;CS224w HomeWork 1&quot;&gt;&lt;/a&gt;CS224w HomeWork 1&lt;/h1&gt;&lt;p&gt;本文旨在记录CS22
      
    
    </summary>
    
    
      <category term="Notes" scheme="http://canVa4.github.io/categories/Notes/"/>
    
    
      <category term="CS224w" scheme="http://canVa4.github.io/tags/CS224w/"/>
    
      <category term="GNN" scheme="http://canVa4.github.io/tags/GNN/"/>
    
  </entry>
  
  <entry>
    <title>FFT idea for Displacement Measurement</title>
    <link href="http://canva4.github.io/2020/10/27/FFT-idea-for-Displacement-Measurement/"/>
    <id>http://canva4.github.io/2020/10/27/FFT-idea-for-Displacement-Measurement/</id>
    <published>2020-10-27T12:00:33.000Z</published>
    <updated>2020-10-27T13:12:02.586Z</updated>
    
    <content type="html"><![CDATA[<h1 id="FFT-idea-for-Displacement-Measurement"><a href="#FFT-idea-for-Displacement-Measurement" class="headerlink" title="FFT idea for Displacement Measurement"></a>FFT idea for Displacement Measurement</h1><p>Displacement Measurement任务核心：利用加速度计、陀螺仪（加速度和陀螺仪数据）来计算位移。</p><h2 id="Origin-Paper-Reading"><a href="#Origin-Paper-Reading" class="headerlink" title="Origin Paper Reading"></a>Origin Paper Reading</h2><p>原始思路：核心：计算倾角θ。假设：底部固定，只发生上部的形变。</p><p>计算倾角使用：加速度和陀螺仪来计算，二者的计算结果结合，通过参数α来调节。</p><p>在获取加速度数据前，先通过低通滤波器滤除震动噪声；获取角加速度前，先通过高通滤波器滤除漂移。</p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/27/W3rebtwV5Ohp1Yz.png" alt="image-20201027201049406" style="zoom:50%;" /><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/27/x5nZbIdwqLCJVfj.png" alt="image-20201027201103750" style="zoom: 50%;" /><h2 id="Idae-Using-FFT-to-calculate-Displacement"><a href="#Idae-Using-FFT-to-calculate-Displacement" class="headerlink" title="Idae: Using FFT to calculate Displacement"></a>Idae: Using FFT to calculate Displacement</h2><p>一时域信号x(t)，设其样本长度为T。则其傅里叶变换为$X(f)=\int_{0}^{T}x(t)e^{-j2\pi ft}dt$。</p><p>信号x(t)被采集（即采样）后，变为离散形式$x(nt_s)$，$t_s$为采样周期。设在T时间内采样了N个数据，就有：</p><ul><li>$$X(k)=\sum_{n=0}^{N-1}x(n)e^{-j(\frac{2\pi}{N})nk}$$</li></ul><p>其对应的傅里叶反变换为：</p><ul><li>$$x(n)=\frac{1}{N}\sum_{n=0}^{N-1}X(k)e^{j(\frac{2\pi}{N})nk}$$</li></ul><p>傅里叶变换后得到的X(k)是一个长度为N的离散复数序列。其第k个数据为：</p><p>$$X(k)=X(k/T)=a_k+jb_k$$</p><p>其代表了x(t)中频率为k/T的简谐运动分量，该分量用$x_k$表示。应有：</p><p>$$x_k=A_k\cos{(2\pi kt/T + \phi_k)}$$</p><p>其中$A_k=\sqrt{a_k^2+b_k^2}$为其幅值，$\phi_k=arctan(b_k/a_k)$为其相角。</p><p>运动台产生的应为一系列简谐运动的叠加，假设通过建筑物系统后仍为一系列简谐运动的叠加（看成时不变系统，如果有这个性质最好了，滤波就很方便，需要一些结构方面知识来确认），那么可以方便的滤除非明显频点的幅值，来降低噪声。若没有此性质，目前初步计划是使用一个低通滤波来滤除噪声（同原始论文）。</p><p>假设我们收到了加速度信号a(n)，对其使用傅里叶变换，得到：</p><p>$$A(k)=\sum_{n=0}^{N-1}a(n)e^{-j(\frac{2\pi}{N})nk}=u_k+jv_k$$</p><p>设真实的位移（Displacement）序列为d(n)，傅里叶变换后为D(k)。D(k)自然也能也成简谐运动的形式。根据加速度和位移是积分的关系。</p><p>若加速度为$a = Acos(\omega t+\phi)$，则位移$x=\int\int adt=\frac{A}{\omega^2}cos(\omega t+\phi-\pi)$。</p><p>直接可得</p><p>$$d_{1k}=\frac{A_k}{\omega_k^2}cos(\phi_k-\pi)$$</p><p>$$d_{2k}=\frac{A_k}{\omega_k^2}sin(\phi_k-\pi)$$</p><p>其中$A_k=\sqrt{u_k^2+v_k^2}$，$\phi_k=arctan(v_k/u_k)$，$w_k=2\pi k/T$。</p><p>而$D(k)=d_{1k}+jd_{2k}$。这样我们就得到了D(k)，再将D(k)做傅里叶反变换即可得到d(n)。即一段时间内的位移情况。</p><p>TODO：</p><ol><li>测试此方法。</li><li>思考如何引入角加速度的信息。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;FFT-idea-for-Displacement-Measurement&quot;&gt;&lt;a href=&quot;#FFT-idea-for-Displacement-Measurement&quot; class=&quot;headerlink&quot; title=&quot;FFT idea for Displ
      
    
    </summary>
    
    
      <category term="Works" scheme="http://canVa4.github.io/categories/Works/"/>
    
    
      <category term="FFT" scheme="http://canVa4.github.io/tags/FFT/"/>
    
      <category term="Displacement Measurement" scheme="http://canVa4.github.io/tags/Displacement-Measurement/"/>
    
  </entry>
  
  <entry>
    <title>Crack Detection Paper Reading</title>
    <link href="http://canva4.github.io/2020/10/23/Crack-Detection-Paper-Reading/"/>
    <id>http://canva4.github.io/2020/10/23/Crack-Detection-Paper-Reading/</id>
    <published>2020-10-23T11:51:09.000Z</published>
    <updated>2020-11-07T10:16:02.231Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Crack-Detection-Paper-Reading"><a href="#Crack-Detection-Paper-Reading" class="headerlink" title="Crack Detection Paper Reading"></a>Crack Detection Paper Reading</h1><h3 id="LIST"><a href="#LIST" class="headerlink" title="LIST:"></a>LIST:</h3><ol><li><p>Autonomous concrete crack detection using deep fully convolutional neural network 2019</p></li><li><p>DeepCrack: Learning Hierarchical Convolutional Features for Crack Detection 2018</p></li><li><p>Holistically-Nested Edge Detection(经典边缘检测算法HED) 2015</p></li><li><p>Feature Pyramid and Hierarchical Boosting Network for Pavement Crack Detection 2019</p></li><li><p>A review on computer vision based defect detection and condition assessment of concrete and asphalt civil infrastructure 2015 <strong>TODO: 精读</strong></p></li><li><p>CrackGAN 2018 <strong>TODO</strong></p></li><li><p>SegNet 2016</p></li><li><p>Feature Pyramid Networks for Object Detection 2017</p></li><li><p>RCF <strong>TODO</strong></p><p><strong>THE FOLLOWINGS ARE MAINLY CLASSIFICATION TASK</strong></p></li><li><p>Image based techniques for crack detection, classification and quantification in asphalt pavement: a review 2017 <strong>CLF</strong></p></li><li><p>Review and Analysis of Crack Detection and Classification Techniques based on Crack Types 2019</p></li><li><p>Concrete Cracks Detection Based on Deep Learning Image Classification <a href="https://www.mdpi.com/2504-3900/2/8/489">LINK</a> 2019</p></li><li><p>Multi-scale classification network for road crack detection 2018 <strong>CLF</strong></p></li></ol><h3 id="In-general-why-using-Deep-Learning-methods-instead-of-traditional-CV-algorithm"><a href="#In-general-why-using-Deep-Learning-methods-instead-of-traditional-CV-algorithm" class="headerlink" title="In general, why using Deep Learning  methods instead of traditional CV algorithm:"></a>In general, why using Deep Learning  methods instead of traditional CV algorithm:</h3><p>Cracks may constantly suffer from noise in the background, leading to poor continuity and low contrast. That lead to the traditional CV algorithms have bad performance on these cases.</p><h3 id="Which-kind-of-tasks-in-CV-are-corresponding-to-Crack-Detection"><a href="#Which-kind-of-tasks-in-CV-are-corresponding-to-Crack-Detection" class="headerlink" title="Which kind of tasks in CV are corresponding to Crack Detection?"></a>Which kind of tasks in CV are corresponding to Crack Detection?</h3><p>Meanly 2 task:</p><ol><li>Semantic Segmentation</li><li>Edge Detection</li></ol><h3 id="Main-DataSets"><a href="#Main-DataSets" class="headerlink" title="Main DataSets:"></a>Main DataSets:</h3><ol><li>CRACK500</li><li>GAPs384</li><li>Cracktree200</li><li>sCFD</li><li>Aigle-RN &amp; ESAR &amp; LCMS</li></ol><h3 id="Metric-For-Crack-Detection-Task"><a href="#Metric-For-Crack-Detection-Task" class="headerlink" title="Metric For Crack Detection Task"></a>Metric For Crack Detection Task</h3><ol><li>最常见的指标之一就是PR（precision and recall）了，将二者统一，即变为F1-measure，这个在各个论文中评价crack detection 模型的性能中经常出现。</li></ol><ul><li>$$F_1=\frac{2*PR}{P+R}$$</li></ul><p>该值位于0~1之间，约接近1认为模型性能越好。</p><p>其缺点为：无法很好的表明检测到的裂缝和地面真实情况之间的重叠程度，尤其是在裂缝较大时。</p><ol start="2"><li>ODS &amp; OIS</li></ol><p>这两个是edge detection中的指标。边缘检测领域的标准准则是固定scale or threshhold(ODS)数据集上的最佳F值，每个图像中最佳scale or threshhold数据集上的平均F值(OIS)。</p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/29/FoQfzMcXZ89ngas.png" alt="image-20201029215820897" style="zoom:80%;" /><ol start="3"><li><p>AP(准确率)</p></li><li><p>FPHBN中提出的average intersection over union(AIU)。</p></li></ol><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/29/jbvE5lNcuyCkQKO.png" alt="image-20201029220020769" style="zoom:80%;" /><p>其中$N_t$表示阈值t的总个数,t在区间[0.01,0.99]内，间隔是0.01;对于给定的阈值t, $N_{pg}^t{}$为预测区域与真实裂缝区域相交（重叠）区域的像素个数，$N_p^t$和$N_g^t$分别表示预测裂缝区域和真值裂缝区域的像素数。因此，AIU在0到1之间，值越大，性能越好。数据集的AIU是数据集中所有图像的AIU的平均值。</p><p>提出的主要目的就是弥补PR指标的缺点，作为一个complementary measurement。AIU takes the width information into consideration to evaluate detections and illustrates the overall overlap extent between detections and ground truth.</p><h2 id="Autonomous-concrete-crack-detection-using-deep-fully-convolutional-neural-network"><a href="#Autonomous-concrete-crack-detection-using-deep-fully-convolutional-neural-network" class="headerlink" title="Autonomous concrete crack detection using deep fully convolutional neural network"></a>Autonomous concrete crack detection using deep fully convolutional neural network</h2><p>Author: Cao Vu Dung, Le Duc Anh     <a href="https://www.sciencedirect.com/science/article/pii/S0926580518306745">Paper Link</a></p><p>Journal: Automation in Construction 2019</p><p>Key Point: <strong>Concrete Crack Detection,  FCN(Fully CNN), Semantic Segmentation(Use FCN), Evaluate crack density, Test the Model on a real video</strong></p><p>数据集：<a href="https://data.mendeley.com/datasets/5y9wdsg2zt/1">https://data.mendeley.com/datasets/5y9wdsg2zt/1</a></p><p>模型很简单：Classification + Semantic Segmentation(FCN)</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/23/FEscvZiNOMCJPYK.png" alt="image-20201023202412382"></p><p>Semantic Segmentation Result：</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/23/jpxeIOHzhwlG67m.png" alt="image-20201023202652414"></p><p>总结：特点不多，主要将CV中的Semantic Segmentation的经典方法（FCN）引入至Crack Detection领域，并且使用了较大的预训练( VGG16, ResNet, Inception)模型，获得结论使用预训练模型可以获得更好的预测结果，在实验部分做了不少工作。最后用了一个现实中的视频来验证一下model的效果。</p><h2 id="DeepCrack-Learning-Hierarchical-Convolutional-Features-for-Crack-Detection"><a href="#DeepCrack-Learning-Hierarchical-Convolutional-Features-for-Crack-Detection" class="headerlink" title="DeepCrack: Learning Hierarchical Convolutional Features for Crack Detection"></a>DeepCrack: Learning Hierarchical Convolutional Features for Crack Detection</h2><p>Author: Qin Zou er al  <a href="https://ieeexplore.ieee.org/document/8517148/similar">Paper LINK</a></p><p>Journal: IEEE TRANSACTIONS ON IMAGE PROCESSING(Published at 2018 Oct)</p><p>KEY WORDS: <strong>基于SegNet，fuse the feature map from encoder and decoder at different scales，crack/line/edge detection</strong></p><p>整体模型：</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/24/FZEbNWKCVmY38Ap.png" alt="image-20201024200409648"></p><p><strong>模型核心：</strong></p><p>In DeepCrack, they first pairwisely fuse the convolutional features of the encoder network and decoder network at each scale, which produces the single-scale fused feature map, and then combine the fused feature maps at all scales into a multi-scale fusion map for crack detection. 这也是模型相比于SegNet最大的改进。</p><p>下图为SegNet的模型结构：</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/27/iTbVDvAxs74yfS3.png" alt="image-20201027092352162"></p><p>下图为encoder和decoder的feature map是如何聚合的（即论文中的skip-layer）。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/24/wT7AYeSmjWBNgus.png" alt="image-20201024200734542"></p><p><strong>Loss Function</strong></p><p>使用的是cross entropy（并没有对于不平衡类别 即：imbalance classification做处理）</p><p>最终的loss是由每层聚合的feature map和多层聚合的feature map的损失相加。</p><p><strong>Experiments And Results</strong></p><p>Modeling by <strong>caffee</strong></p><p><strong>Datasets</strong>: </p><ol><li>Training: CrackTree260</li><li>Testing: CRKWH100, CrackLS315, Stone331</li></ol><p><strong>Compare With Other Models</strong></p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/27/cg2CBjQtMNGwLx7.png" alt="image-20201027090600436"></p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/27/l6FXZJpDygiqBWf.png" alt="image-20201027090703558"></p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/27/twXOKVsmTEg6Pvu.png" alt="image-20201027090730577"></p><p><strong>Other Experiments</strong></p><ol><li>作者也比较了每一个scale对于最终结果的影响，即：在最终的loss中对于每一层的loss增加一个权重。</li><li>是否使用预训练模型的比较。有趣的是预训练的效果并不好，作者给出解释是：because that the pretrained model is well fit for nature image segmentation and is impossible or very difficult to be fine-tuned for crack detection.</li><li>作者讨论了在真实label中加入噪声对于模型的影响。结论是：对于噪声并不敏感。</li><li>作者还比较了不同的up-sampling方法的影响。即：传统的在max pooling时记录index的方法和bilinear interpolation的方法。结论：传统的在max pooling时记录index的up-sampling方法更好。</li><li>Different Weights on the Crack and Non-Crack Background，即在计算loss时对于不同的类别（即 crack or non-crack）赋予不同的权重。结论：会对性能提升，降低了类别不平衡的影响。</li><li>作者还比较了<strong>Running Efficiency</strong>, 上图给出的FPS为对于512×512大小的图片的实时处理速度。DeepCrack为：0.153 second per image。不过其使用的设备是GeForce GTX TITAN-X GPU和2.3GHz主频的E5-2630 CPU.</li></ol><h2 id="Holistically-Nested-Edge-Detection-HED"><a href="#Holistically-Nested-Edge-Detection-HED" class="headerlink" title="Holistically-Nested Edge Detection(HED)"></a>Holistically-Nested Edge Detection(HED)</h2><p>Author: Saining Xie er al  <a href="https://arxiv.org/abs/1504.06375">Paper LINK</a></p><p>Conference: CVPR 2015</p><p>KEY WORDS: <strong>基于VGGNET，mutil-scale fuse，edge detection</strong></p><p>此paper为使用CNN(VGG)的经典边缘检测模型，后期出现在多篇Crack Detection模型的baseline中。下一篇Feature Pyramid and Hierarchical Boosting Network for Pavement Crack Detection得部分思路也是来源于HED的。这里主要总结和介绍一下模型部分。</p><p>其中Holistically表示该算法试图训练一个image-to-image的网络；Nested则强调在生成的输出过程中通过不断的集成和学习得到更精确的边缘预测图的过程。HED使用VGG改造的网络，针对整张图片提取特征信息，使用multi-scale fusion，multi-loss的方法。</p><p>值得注意的是，该方法的速度还是比较快的，可以达到0.4s per image(on the NYU Depth dataset)</p><p><strong>Model Detail</strong></p><p>下图为整个HED的模型结构。特征提取使用的是pre-trained的VGG网络。</p><p>作者给出performance提升的原因是：</p><ol><li>patch-based CNN edge detection methods</li><li>FCN-like image-to-image training allows models to simultaneously train on a significantly larger amount of samples</li><li>deep supervision in model guides the learning of more transparent features</li><li>interpolating the side outputs in the end-to-end learning encourages coherent contributions from each layer(used in fuse)</li></ol><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/27/Oh8aFMxQpDrIdje.png" alt="image-20201027155719185"></p><p>本文的一大亮点就是使用了与以往不同的multi-scale fuse的方法。如下图所示：</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/27/F2GtTpIRcxJqyDu.png" alt="image-20201027163733313"></p><p>(a)Multi-stream learning 示意图，可以看到图中的平行的网络下（不同的网络有不同的参数和receptive field），输入是同时输进去，经过不同路的network之后，再连接到一个global out layer得到输出。</p><p>(b)Skip-layer network learning 示意图，该方法主要连接各个单的初始网络流得到特征图，并将图结合在一起输出。</p><p>这里（a）和（b）都是使用一个输出的loss函数进行单一的回归预测，而边缘检测可能通过多个回归预测得到结合的边缘图效果更好。</p><p>(c)Single model on multiple inputs 示意图，单一网络，图像resize方法得到多尺度进行输入。当用于test端时，有点类似于集成学习的感觉。</p><p>(d)Training independent networks ，通过多个独立网络分别对不同深度和输出loss进行多尺度预测，该方法下训练样本量较大。</p><p>(e)Holistically-nested networks，本文提出的结构，从（d）演化来，类似地是一个相互独立多网络多尺度预测系统，但是将multiple side outputs组合成一个单一深度网络。</p><p>这种方法的好处在于：基于hidden layer的supervision更有利于performance的提升；也相对的减小了模型的复杂度；在fuse时可以自由的调配每个scale的权重，或者通过学习来学到一个更好的参数。</p><p>作者主要使用了VGG16，并对其进行小幅度修改。</p><p><strong>Loss Function</strong></p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/27/QbWvcajnZixkYL7.png" alt="image-20201027170404471"></p><p>总的side-output loss为每一个side-output的加权和，权重可以通过学习来获得。由于edge detection任务的特性，大部分pixel为非edge的，所以存在明显的类别不平衡，每个side-output的loss使用下图的公式来解决这个问题。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/27/F3lSQWU8Ndg2J5b.png" alt="image-20201027170511603"></p><p>另外一部分的loss是fuse loss。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/27/8yiP3qKzN2dwOrS.png" alt="image-20201027170911639"></p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/27/BJA6Lk8pPaTo1dN.png" alt="image-20201027170938292"></p><p>h为fuse的一组参数。最终的loss和学习目标为：</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/27/Wa4JQD8bkIrnVhN.png" alt="image-20201027171037647"></p><p><strong>Experiment Results:</strong></p><p>Results on BSDS500 datasets.</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/27/HoQmpjAEGfNy5LC.png" alt="image-20201027195428396"></p><h2 id="Feature-Pyramid-and-Hierarchical-Boosting-Network-for-Pavement-Crack-Detection"><a href="#Feature-Pyramid-and-Hierarchical-Boosting-Network-for-Pavement-Crack-Detection" class="headerlink" title="Feature Pyramid and Hierarchical Boosting Network for Pavement Crack Detection"></a>Feature Pyramid and Hierarchical Boosting Network for Pavement Crack Detection</h2><p>Author: Fan Yang er al  <a href="https://arxiv.org/abs/1901.06340">Paper LINK</a></p><p>Conference: CVPR 2019</p><p>KEY WORDS: <strong>Pavement Crack Detection，主要将Feature Pyramid Network(FPN)应用于Crack Detection task，提出新的 measurement for crack detection: average intersection over union (AIU)</strong></p><p><strong>模型细节：</strong></p><p>FPHBN使用了HED（本篇文档中也有HED的介绍与总结）作为其backbone net，在其之上引入了FPN的思想（FPN在本文档中也有介绍与总结）。</p><p>下图就是HED与FPHBN的模型对比图，可以很明显的看到，在HED后面加入了类似于FPN的思想（top-down + skip connection）和Hierarchy Boostings。Hierarchy Boostings可以起到平衡top layer与bottom layer的权重，可以让模型pay attention to hard examples.</p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/29/tQwqR5f9MONEAGk.png" alt="image-20201029210048041" style="zoom: 80%;" /><p>整个模型分为四个部分：</p><ol><li>A bottom-up architecture for hierarchical feature extraction</li><li>A feature pyramid for merging context information to lower layers using a top-down architecture</li><li>Side networks for deep supervision learning. The side network at each level performs crack prediction individually.</li><li>A hierarchical boosting module to adjust sample weights in a nested way</li></ol><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/29/J6YuzEiAtFc49Le.png" alt="image-20201029212056151"></p><p>这里主要介绍一下Hierarchical Boosting，1~3部分即为HED+FPN，这二者在本文中都有介绍。</p><p>使用Hierarchical Boosting是为了解决HED的一个缺点，即：the network cannot effectively learn parameters from misclassified samples during training phase. 这个是因为edge detection task 本质的类别不平衡导致的，虽然在HED中引入了系数β来损失函数对不同类别的权重，但这种方法并不能区分easy and hard samples，因为类别不平衡很容易导致损失函数主要被不平衡类别占据。</p><p>作者针对这个问题（还有一些其他解决方法），提出了Hierarchical Boosting来reweigh samples。</p><p>想法来源于，回看feature pyramid层，可以看到，上层的信息会传递到下层，这种信息会告诉下层那些样本是hard的，这样这些下层的网络就可以pay attention to这些hard样本了。于是作者就想到来facilitating communication between adjacent side networks.</p><p>实现起来就是重写每一个side network的损失函数：$d_i^{m+1}$ 为第m+1个side network的预测值与真实值在第i个像素的差异。</p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/29/BtihxYVnDHAX2yJ.png" alt="image-20201029215013161" style="zoom:80%;" /><p><strong>Experiments And Results</strong></p><p>可以看到在inference时的速度也比HED有了提升。</p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/29/Jgt6xp2SoLkrzAG.png" alt="image-20201029215415393" style="zoom:80%;" /><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/29/q5Y9OGf8UuWPetN.png" alt="image-20201029215633706" style="zoom:80%;" /><p>Related Paper:</p><p>Y. Liu, M.-M. Cheng, X. Hu, K. Wang, and X. Bai, “Richer convolutional features for edge detection,”</p><p>Deeply-supervised nets</p><h2 id="Feature-Pyramid-Networks-for-Object-Detection"><a href="#Feature-Pyramid-Networks-for-Object-Detection" class="headerlink" title="Feature Pyramid Networks for Object Detection"></a>Feature Pyramid Networks for Object Detection</h2><p>Author: Lin er al   <a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Lin_Feature_Pyramid_Networks_CVPR_2017_paper.pdf">Paper Link</a></p><p>Journal: CVPR 2017</p><p>Key Point: <strong>Adding Pyramid representation into Deep Learning Methods, Multi-scale and pyramidal hierarchy</strong></p><p>Other’s Note: <a href="https://zhuanlan.zhihu.com/p/78160468">ZhiHu Link</a></p><p><strong>总结：</strong> FPN本质是另一种特征提取的结构，获得的representation可以用于很多不同的task，例如object detection 或者 semantic segmentation(crack detection就可以看为是这种任务)。其最大的好处是：在保持原有性能的情况下，极大的降低了模型的复杂度，让模型更feasible。现在FPN已经经常作为各种Detecton和segmentation算法的标准组件。</p><p>下图给出了几种常见的pyramid形式的特征提取方法。例如b方法就是常见的CNN所使用的结构。</p><img src= "/img/loading.gif" data-lazy-src="C:\Users\12552\AppData\Roaming\Typora\typora-user-images\image-20201028201708812.png" alt="image-20201028201708812" style="zoom:67%;" /><p>值得注意的是，在图中边框更粗的代表了更high-level的语义的特征（很符合直观）。个人理解：许多常见的multi-scale方法就是类似c的方法，将每层CNN的结果聚合作为预测结果，如SSD(Single Shot Detector)，SegNet和上面的HED。作者给出的(c)方法的缺点为：This in-network feature hierarchy produces feature maps of different spatial resolutions, but introduces large semantic gaps caused by different depths. The high-resolution maps have low-level features that harm their representational capacity for object recognition.</p><p>(a) 中的 Featurized image pyramid结构在ImageNet 或 COCO上取得了很好的表现，因为这种方法产生了multi-scale的representation而且每层特征提取都semantically strong。这种方法的主要问题就是：inference time过长，导致实际难以应用。</p><p>下图为FPN网络的具体图示，作者也引入了类似ResNet的skip connection。</p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/28/brWwTLKR79zapf2.png" alt="image-20201028204220471" style="zoom: 67%;" /><p>整体结构主要包含三个部分：</p><ol><li>Bottom-up pathway 正常使用backbone网络，如Resnet</li><li>Top-down pathway 使用nearest neighbor upsampling</li><li>Lateral connections 如下图所示。</li></ol><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/28/1QGbFcIAe9O67vE.png" alt="image-20201028210642456"></p><h2 id="SegNet-SegNet-A-Deep-Convolutional-Encoder-Decoder-Architecture-for-Image-Segmentation"><a href="#SegNet-SegNet-A-Deep-Convolutional-Encoder-Decoder-Architecture-for-Image-Segmentation" class="headerlink" title="SegNet: SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation"></a>SegNet: SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation</h2><p>Author: Vijay Badrinarayanan er al  </p><p>Journal: TPAMI 2015</p><p>Key Point: <strong>Semantic Segmentation，compare different upsampling methods</strong></p><ul><li>本文提出的SegNet和FCN、DeepLab-LargeFOV、DeconvNet做了比较，这种比较揭示了在实现良好分割性能的前提下内存使用情况与分割准确性的权衡。</li><li>SegNet的主要动机是场景理解的应用。因此它在设计的时候考虑了要在预测期间保证内存和计算时间上的效率。</li><li>定量的评估表明，SegNet在和其他架构的比较上，时间和内存的使用都比较高效。</li></ul><p><strong>模型细节</strong></p><p>Encoder: VGG16，移除全连接层(基本操作)</p><p>Decoder: Use pooling indices computed in the max-pooling step of the corresponding encoder to perform non-linear upsampling. </p><p>特点：相比于最经典的FCN等，有更少的参数，相对更快的inference time。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/11/02/LyvwAGCUunghDzl.png" alt="image-20201101113757989"></p><p>实际上，SegNet与FCN最大的差别就在于upsampling的不同。作者在文章中还探讨了不同upsampling对性能的影响和每个方法可能的优劣。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/11/02/RI9yD4W1tjLhTk6.png" alt="image-20201101121932268"></p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/11/02/iVmDakgBtvPA9rG.png" alt="image-20201101121952246"></p><p>通过上表分析，可以得到如下分析结果：</p><ul><li>bilinear interpolation 表现最差，说明了在进行segmentation时，decoder是可学习的还是非常重要的。</li><li>SegNet-Basic与FCN-Basic对比，均具有较好的精度，不同点在于SegNet存储空间消耗小，FCN-Basic由于feature map进行了降维，所以时间更短。</li><li>SegNet-Basic与FCN-Basic-NoAddition对比，两者的decoder有很大相似之处，SegNet-Basic的精度更高，一方面是由于SegNet-Basic具有较大的decoder,同时说明了encoder过程中低层次feature map的重要性。</li><li>FCN-Basic-NoAddition与SegNet-Basic-SingleChannelDecoder：证明了当面临存储消耗，精度和inference时间的妥协的时候，我们可以选择SegNet，当内存和inference时间不受限的时候，模型越大，表现越好。</li></ul><p>作者总结到：</p><ul><li>encoder特征图全部存储时，性能最好。 这最明显地反映在语义轮廓描绘度量（BF）中。</li><li>当限制存储时，可以使用适当的decoder（例如SegNet类型）来存储和使用encoder特征图（维数降低，max-pooling indices）的压缩形式来提高性能。</li><li>更大更复杂的decoder提高了网络的性能。</li></ul><h2 id="Concrete-Cracks-Detection-Based-on-Deep-Learning-Image-Classification"><a href="#Concrete-Cracks-Detection-Based-on-Deep-Learning-Image-Classification" class="headerlink" title="Concrete Cracks Detection Based on Deep Learning Image Classification"></a>Concrete Cracks Detection Based on Deep Learning Image Classification</h2><p>Author: Wilson Ricardo Leal da Silva 1,OrcID andDiogo Schwerz de Lucena 2  <a href="https://www.mdpi.com/2504-3900/2/8/489">LINK</a></p><p>Journal: The 18th International Conference on Experimental Mechanics (ICEM 2018) 材料领域的会议</p><p>总结：模型真的非常简单。使用VGG16作为Backbone Net，在其上面做transfer Learning（pre-train model）。</p><p>整体感觉，没想到2018年的会议上也有这么水的文章，不过引用了一些可以扩展阅读的文献。</p><p>模型训练使用NVIDIA Tesla K80（约12G显存）</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/11/05/diWuIegAlKoED4L.png" alt="image-20201105220013434"></p><h3 id="Related-Paper"><a href="#Related-Paper" class="headerlink" title="Related Paper"></a>Related Paper</h3><p>使用无人机做Crack detection</p><ol><li>Robust crack detection for unmanned aerial vehicles inspection in an acontrario decision framework 2015</li><li>Development of Crack Detection System with Unmanned Aerial Vehicles and Digital Image Processing 2015</li></ol><p>Deep Learning System for Automated Cracking</p><ol start="3"><li>Basis and Design of a Deep Learning System for Automated Cracking Survey 2017</li><li>Automatic Pavement Crack Detection Based on Structured Prediction with the Convolutional Neural Network. 2018</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Crack-Detection-Paper-Reading&quot;&gt;&lt;a href=&quot;#Crack-Detection-Paper-Reading&quot; class=&quot;headerlink&quot; title=&quot;Crack Detection Paper Reading&quot;&gt;&lt;/a
      
    
    </summary>
    
    
      <category term="Works" scheme="http://canVa4.github.io/categories/Works/"/>
    
      <category term="Papers" scheme="http://canVa4.github.io/categories/Works/Papers/"/>
    
    
      <category term="Crack Detection" scheme="http://canVa4.github.io/tags/Crack-Detection/"/>
    
      <category term="Deep Learning" scheme="http://canVa4.github.io/tags/Deep-Learning/"/>
    
      <category term="CV" scheme="http://canVa4.github.io/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>Running Neural Networks On Embedding Systems</title>
    <link href="http://canva4.github.io/2020/10/04/Running-Nuerual-Networks-On-Embedding-Systems/"/>
    <id>http://canva4.github.io/2020/10/04/Running-Nuerual-Networks-On-Embedding-Systems/</id>
    <published>2020-10-04T09:11:39.000Z</published>
    <updated>2020-11-02T10:25:24.017Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Running-Neural-Networks-On-Embedding-Systems"><a href="#Running-Neural-Networks-On-Embedding-Systems" class="headerlink" title="Running Neural Networks On Embedding Systems"></a>Running Neural Networks On Embedding Systems</h1><p>我检索资料时，核心的关键词是：<strong>云平台+边缘计算、IoT、AI加速</strong>。所以主要看的是有GPU或者有ASIC（专用集成电路）的方案。</p><p>经过资料的查找之后，我发现许多做硬件的大公司比如：高通、NVIDIA，Google、海思都有自己的解决方案。</p><p>以下为我找到的一些资料。资料来源：各个公司的官网；淘宝，论坛、博客。</p><p>同时给出一些我个人的简易分析，这些分析可能不是很准确，因为只是根据网上资料所得的结果。</p><p>TODO:</p><ul><li>各个芯片的加速程度对比</li></ul><h2 id="Qualcomm-高通"><a href="#Qualcomm-高通" class="headerlink" title="Qualcomm 高通"></a>Qualcomm 高通</h2><p>高通的优势之一就是其提供了一整套完整的硬件和软件的解决方案。<a href="https://www.qualcomm.com/products/artificial-intelligence">高通AI LINK</a> </p><p>其中Qualcomm NPE(Neural Processing Engine) 使用Caffe or tensorflow写好模型后，用Qualcomm NPE SDK添加到晓龙CPU/GPU上运行模型。整个开发使用流程如下所示。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/04/jar7ecdq9KwPXGT.png" alt="image-20201004205847255"></p><p>其主要应用领域就用手机AI、IoT领域等。 </p><p><strong>优势：</strong></p><ul><li>有完整的软件+硬件方案</li><li>模型建立后部署方便</li><li>支持AI的晓龙芯片性能强大，因为是SOC，一个芯片实现了非常多的功能</li></ul><p><strong>不足：</strong></p><ul><li>Data Center支持有限</li><li>目前国际形势可能导致不方便购买其解决方案（还未详细了解）<h2 id="Cambricon-寒武纪"><a href="#Cambricon-寒武纪" class="headerlink" title="Cambricon 寒武纪"></a>Cambricon 寒武纪</h2></li></ul><p>寒武纪是国内的一家目前在智能芯片市场上很出名的企业。是一家国内提供智能芯片，满足：有终端硬件+云平台的需求。<a href="http://www.cambricon.com/index.php?m=content&c=index&a=lists&catid=71">寒武纪 LINK</a> </p><p>寒武纪同样也有几款主打的AI加速芯片。同时他也有一个云平台——寒武纪人工智能开发平台（Cambricon NeuWare）是寒武纪专门针对其云、边、端的智能处理器产品打造的软件开发平台， Neuware采用端云一体的架构，可同时支持寒武纪云、边、端的全系列产品。寒武纪终端IP、边缘端芯片及云端芯片共享同样的软件接口和完备生态，可以方便地进行智能应用的开发，迁移和调优。</p><p>开发者可以借助云端丰富的计算资源进行算法模型的解析与调试，利用Neuware生成离线模型，并能够在任意搭载寒武纪智能终端IP的设备运行，解决了终端调试手段受硬件资源限制的问题。</p><p>下图为其端云一体业务部署流程。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/04/Xxi7QG9Cale16OP.png" alt="image-20201004211854078"></p><p>下图为其软件栈。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/04/YnSeXP6Cs2UGE4f.png" alt="image-20201004211515460"></p><p><strong>优势：</strong></p><ul><li>国内的方案，购买、实施、使用相对方便</li><li>有专门的云平台</li></ul><p><strong>不足：</strong></p><ul><li>真实性能和效果未知</li><li>其云端的重点好像是主要用于调试和部署</li></ul><h2 id="NVIDIA-Jetson-系列"><a href="#NVIDIA-Jetson-系列" class="headerlink" title="NVIDIA Jetson 系列"></a>NVIDIA Jetson 系列</h2><p>NVIDIA Jetson 系列。GPU大厂的解决方法，据我所知，在机器人领域使用很多。其Jetson系列都有GPU，且可运行Linux操作系统。比如：我原来所在北邮机器人队，需要摄像头进行一些较大运算量算法时，就使用的是Jetson系列的TX2。</p><p>其主打：适用于新一代自主机器的嵌入式系统；NVIDIA Jetson：适用于一切自主机器的 AI 平台。Jetson系统所提供的性能和能效可提高自主机器软件的运行速度，而且功耗更低。每个系统都是一个完备的模块化系统 (SOM)，具备 CPU、GPU、PMIC、DRAM 和闪存，可节省开发时间。自然也具有可扩展性，比如：支持USB，串口，HDMI等接口（不同的型号不太一样）。</p><p>其主要有四个如下的产品，从左至右性能依次提升。（当然价格和功耗也会提升）</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/05/JX2FyS5eZEABtPT.png" alt="image-20201005210658302"></p><p>例如：广泛用于智能小车、比较需要计算量的智能产品中的Jetson Nano。</p><p>Jetson Nano 模块是一款低成本的 AI 计算机，具备超高的性能和能效，可以运行现代 AI 工作负载，并行运行多个神经网络，以及同时处理来自多个高清传感器的数据。这使其成为向嵌入式产品中添加高级 AI 的理想的入门级选项。</p><p>下图为Jetson Nano的照片，可以看到其支持多种外设接口。<a href="https://detail.tmall.com/item.htm?id=608609593274&ali_refid=a3_430582_1006:1268380158:N:sH2jsRQiqncfQma5KNTJH3QCsGA2TDnC:33fec7c4be41b2615b4987bf0b673408&ali_trackid=1_33fec7c4be41b2615b4987bf0b673408&spm=a230r.1.14.13&skuId=4314923092276">淘宝链接</a></p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/05/slfVR6Y3WiXoSAZ.png" alt="image-20201005210954346"></p><p>而且其另一大优势时都是NVIDIA一家的，其GPU支持CUDA，这样例如：pytorch等可以很方便的部署。</p><p>Jetson 平台由 Jetpack SDK 提供支持，包括板级支持包 (BSP)、Linux 操作系统、NVIDIA CUDA(R)，并且兼容第三方平台。开发者可以利用 DeepStream SDK 在 Jetson 上快速构建和部署高效的视频分析管线。</p><p>下面是其软件栈：</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/05/RCc2L8bsJ4uS3YK.png" alt="image-20201005211204653"></p><p><strong>优势：</strong></p><ul><li>产品种类多，可选择空间大</li><li>模型部署方便</li><li>购买比较方便（淘宝即可）</li><li>教程和应用实例比较多</li></ul><p><strong>不足：</strong></p><ul><li>加速性能由于不同的GPU架构可能差距很大</li></ul><p>TODO: Data Center 调研</p><h2 id="Google-TPU"><a href="#Google-TPU" class="headerlink" title="Google TPU"></a>Google TPU</h2><h3 id="Cloud-TPU"><a href="#Cloud-TPU" class="headerlink" title="Cloud TPU"></a>Cloud TPU</h3><p>张量处理单元 (TPU) 是专门设计用于处理机器学习应用计算需求的 ASIC 设备。有着很完善的文档，教程等。<a href="https://cloud.google.com/tpu/docs/quickstart?hl=zh-cn">链接</a></p><h3 id="Edge-TPU"><a href="#Edge-TPU" class="headerlink" title="Edge TPU"></a>Edge TPU</h3><p>作为Cloud TPU的补充，目前Edge TPU主要作用于推理，专为在边缘运行TensorFlow Lite ML模型而设计。</p><p>AIY Edge TPU 加速器是一个适用于现有系统的神经网络协处理器，一个加速棒。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/05/pm8INj3TZcfRiME.png" alt="image-20201005214027249"></p><p>AIY Edge TPU Dev开发板 是一个带搭载Edge TPU的单板计算机。类似于NVIDIA Jetson Nano。下图左边为树莓派，中间为Google Edge TPU Dev，右边为NVIDIA Jetson Nano</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/05/c5OB3J7nwXb6WFP.png" alt="image-20201005214053059"></p><p>其Edge TPU是对于TensorFlow Lite有专门优化的，在计算速度上强于Jetson Nano。</p><p><strong>优势：</strong></p><ul><li>云端非常强大</li><li>文档支持良好</li><li>对于TensorFlow有专门优化</li></ul><p><strong>不足：</strong></p><ul><li>国内可能不支持</li></ul><h2 id="瑞芯微电子"><a href="#瑞芯微电子" class="headerlink" title="瑞芯微电子"></a>瑞芯微电子</h2><p>国内的一家提供相关解决方案的厂家。主要为为高端智能硬件、手机周边、平板电脑、电视机顶盒、工控等多个领域提供专业芯片解决方案。</p><p>目前许多门禁系统的人脸识别部分，有许多使用的是瑞芯的RK3288或者RK3399（性能更强）系列。均使用arm内核。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/20/eqaQcPkpIGWxgLX.png" alt="image-20201020114444744"></p><h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><p>AI加速计算，如：Intel Movidius神经计算棒（可以结合树莓派使用，即支持Linux操作系统）</p><p>华为旗下的高端芯片企业。主打AI处理器。也提供了许多领域的解决方案：如：IoT，Face Cam，门禁系统等的解决方法。主要偏向于高端市场。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Running-Neural-Networks-On-Embedding-Systems&quot;&gt;&lt;a href=&quot;#Running-Neural-Networks-On-Embedding-Systems&quot; class=&quot;headerlink&quot; title=&quot;Runn
      
    
    </summary>
    
    
      <category term="Works" scheme="http://canVa4.github.io/categories/Works/"/>
    
    
      <category term="TPU" scheme="http://canVa4.github.io/tags/TPU/"/>
    
      <category term="嵌入式系统" scheme="http://canVa4.github.io/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="智能终端" scheme="http://canVa4.github.io/tags/%E6%99%BA%E8%83%BD%E7%BB%88%E7%AB%AF/"/>
    
  </entry>
  
  <entry>
    <title>单片机解决方案调研（2）</title>
    <link href="http://canva4.github.io/2020/09/14/%E5%8D%95%E7%89%87%E6%9C%BA%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B0%83%E7%A0%94%EF%BC%882%EF%BC%89/"/>
    <id>http://canva4.github.io/2020/09/14/%E5%8D%95%E7%89%87%E6%9C%BA%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B0%83%E7%A0%94%EF%BC%882%EF%BC%89/</id>
    <published>2020-09-14T12:36:48.000Z</published>
    <updated>2020-10-14T05:15:10.613Z</updated>
    
    <content type="html"><![CDATA[<h1 id="解决方案调研（2）"><a href="#解决方案调研（2）" class="headerlink" title="解决方案调研（2）"></a>解决方案调研（2）</h1><p>GOAL：针对上一次老师提出的点进行补充调研。<a href="https://ieeexplore.ieee.org/document/8812785">https://ieeexplore.ieee.org/document/8812785</a></p><p>KEY WORDS: <strong>具体通信细节、耗电量估算、MSP系列、Google edge TPU（另写一篇）</strong></p><p>在认真读完SnowFort这篇文章后，我更进一步了解了我们设计的预期，想相比于SnowFort有更进一步的提升，可能可以在如下方面做一些升级：</p><ul><li>提升Mote的运算性能，以便可以在mote上进行更多的数据处理</li><li>提升Mote的可扩展性，可以让每个mote接入更多种类的传感器</li><li>令Mote有更长or维持当前的功率（使用时间）</li><li>提升Base Station的运算性能，可以不用考虑其功率情况</li><li>组网能力提升、通信距离提升</li><li>云端功能、数据处理算法提升</li></ul><p>综上，除了对于老师上次提出的点进行补充，我也尝试着从这些方面来尝试改进。</p><h2 id="具体通信细节"><a href="#具体通信细节" class="headerlink" title="具体通信细节"></a>具体通信细节</h2><p>在上一篇调研的最后有一个简易的实现方案。<a href="https://canva4.github.io/2020/09/14/%E5%8D%95%E7%89%87%E6%9C%BA%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B0%83%E7%A0%94%EF%BC%882%EF%BC%89/">LINK</a></p><h3 id="STM32-PART"><a href="#STM32-PART" class="headerlink" title="STM32 PART"></a>STM32 PART</h3><p>无限通信部分STM32系列方案使用的是 <a href="https://detail.tmall.com/item.htm?id=609757779633&ali_refid=a3_430582_1006:1267360122:N:9/mfWI1BJMLzXLT4ATlUnA==:de4e276b258975c722c4a03cf64e8c17&ali_trackid=1_de4e276b258975c722c4a03cf64e8c17&spm=a230r.1.14.8">ATK-ESP8266</a> 。</p><p>该模块的核心性能指标如图所示：</p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/14/VsDwkx5XSnAEjLQ.png" alt="image-20200914204633006" style="zoom: 67%;" /><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/14/RWDBFwVb9e6svLY.png" alt="image-20200914204839819" style="zoom:67%;" /><h3 id="M5STACK-PART"><a href="#M5STACK-PART" class="headerlink" title="M5STACK PART"></a>M5STACK PART</h3><p>其核心是esp32系列芯片。esp32是esp8266的升级版，其WIFI支持：802.11 b/n/g，与ATK-ESP8266相似。其相比于ATK-ESP8266还支持蓝牙。</p><ul><li>传统蓝牙支持 L2CAP，SDP，GAP，SMP，AVDTP，AVCTP，A2DP (SNK) 和 AVRCP (CT) 协议</li><li>低功耗蓝牙 (Bluetooth LE) 支持 L2CAP，GAP，GATT，SMP，和 GATT 之上的 BluFi，SPP-like 协议等</li></ul><h2 id="STM32L-低功耗系列"><a href="#STM32L-低功耗系列" class="headerlink" title="STM32L 低功耗系列"></a>STM32L 低功耗系列</h2><p><strong>产品栈</strong></p><p><img src= "/img/loading.gif" data-lazy-src="C:\Users\12552\AppData\Roaming\Typora\typora-user-images\image-20201014114115216.png" alt="image-20201014114115216"></p><p><strong>超低功耗模式中的不同产品系列</strong></p><p>有M0+内核的STM32L0，有Cortex-M3内核的L1以及Cortex-M4内核的L4和L4+，其中L0和L1都有5种低功耗模式，这5种低功耗模式分别是低功耗的运行、睡眠、低功耗睡眠、停止和待机。对于L4和L4+，它们在5种低功耗模式基础上又添加了停止模式下的stop 1、stop 2和shutdown关断模式。可以通过内部的寄存器配置，来切换工作模式，在不同的模式下会有不同的唤醒时间。尤其是L4产品中shutdown模式，做到了非常低的功耗。</p><p><strong>低功耗运行模式</strong></p><p>其实低功耗运行模式还是一种运行模式，只是它的电流消耗很低，它与运行模式最大的区别是给内核供电的内部电压调节器电压要低于正常的运行模式下的电压值，即使用的低功耗的电压器来供电。在此情况下，系统最大的运行频率也会明显降低，例如L4在低功耗运行模式时最大的频率不超过2MHz。</p><p><strong>睡眠模式</strong></p><p>在睡眠模式，系统的CPU也就是Cortex-M内核的时钟被关闭了，但外设是可以继续保持运转的，它整个I/O的引脚状态与运行模式下也是相同的。</p><p><strong>低功耗睡眠模式</strong></p><p>低功耗睡眠模式是基于睡眠模式下的低功耗模式，是具有极低电流消耗的睡眠模式，它内核的时钟也是被关闭的，同时外设时钟频率受到了限制，因为它的电压调节器属于低功耗状态，内部的FLASH是要被停止的，所以低功耗睡眠模式只能从低功耗运行模式进入，这个是和其他模式不同的，其他模式都可以从运行模式直接做切换。</p><p>在低功耗运行和睡眠模式下，可以有一个BAM模式，它的工作方式是通过RTC加一个外设加DMA加SRAM，在不需要CPU干预的情况下就可以自行做数据采集，一旦到了数据采集需要到CPU处理的条件时，然后再把CPU唤醒做处理，所以这整个一个小系统就实现了一个协处理器的功能。</p><p><strong>停止模式</strong></p><p>首先说一下其的供电系统，其中有一个Vcore，它是内核的一个供电区域，负责给CPU内核供电，并且还给系统内部的存储器和它的数字外设供电。</p><p>停止模式中，除了CPU，也就是Cortex-M内核的时钟被关闭外，内核供电域的时钟也被停止，在停止模式下，内核供电域的时钟全部都停掉，PLL内部、外部的高速时钟全部都停掉，电压调节器为内核供电域供电，保留寄存器和内部SRAM中的内容。</p><p>在L4和L4+系列中，停止模式被细分为stop 0、stop 1和stop 2三种模式，按照功耗从低到高来说，stop 2是功耗最低的一个stop模式，它整个Vcore电源域放在了更低的漏电流模式下，使用了低功耗的电压调节器，只有最少的外设可以工作，所以它的功耗相对来说是最低的，但是唤醒时间是最长的。</p><p>Stop 1模式提供了更多的外设和唤醒源，唤醒时间也会更长一些；</p><p>Stop 0模式主电压调节器打开，可以得到最快的唤醒时间；</p><p>在所有的stop模式下，所有的高速振荡器停止，而低速振荡器保持活动，外设设置为active，需要的时候就可以使用这些高速时钟，能保证它在一些特定的事件下去唤醒设备。</p><p><strong>待机模式</strong></p><p>在待机模式下，内核的供电是直接断电的，电压调节器掉电区寄存器的内容会完全丢失，包括内部的SRAM，所以最大的区别即，系统从待机模式下的低功耗唤醒的时候，系统是要复位的。</p><p>默认条件的待机模式下，SRAM的内容是会丢失的，但是在L4里增加了SRAM 2，如果需要在待机模式后系统唤醒的时候有SRAM能保存一些内容，那就可以使用SRAM 2，它需要有多余220nA的额外电流消耗。</p><p><strong>Shutdown模式</strong></p><p>在shutdown模式，系统达到了最低的功耗，电压调节器的供电就被关断了，内核的供电也完全被断开，只有备份域的LSE、RTC可以工作所以在L4器件实现了一个新的模式，这个模式主要实现的目的就是为了延长电池供电之后整个器件的使用寿命，它其实是通过关闭内部的稳压器以及禁止使用耗电的监控，所以这个模式可以达到最低的功耗电流。</p><h2 id="MSP系列芯片"><a href="#MSP系列芯片" class="headerlink" title="MSP系列芯片"></a>MSP系列芯片</h2><p>MSP430的电压已经降到了3.3v，且MSP430比芯片分成了许多不同的模块部分，不用的部分功能模块可以关闭，电流近似为零，这样就极大的节省了能耗；另一个值得注意的是，其可以有三个时钟源，并产生更多的内部可用工作频率，让内部各个模块工作在不同的频率，不用的时钟也可以关掉。<strong>具体寄存器和模式切换TODO</strong></p><h2 id="MSP430-VS-STML4"><a href="#MSP430-VS-STML4" class="headerlink" title="MSP430 VS STML4"></a>MSP430 VS STML4</h2><p><strong>ULP Benchmark</strong></p><p>在超低功耗MCU领域，有一些评测不同芯片功耗水平的Benchmark。</p><p>其中比较有名和有代表性的是：ULP Benchmark <a href="https://www.eembc.org/ulpmark/scores.php">https://www.eembc.org/ulpmark/scores.php</a></p><p>NOTE：不同的编译方法，在真实功耗上会有很大的差异性。例如使用IAR和ARM GCC编译器在同一个芯片上的表现可能还不同。</p><p>从表中可以看到，STM32L4的大部分产品的在该Benchmark上的得分都是高于MSP430系列的。</p><p>其中，我选择了STM32L433（L4中较常见的一款，淘宝可买到）和MSP430FR5969（为MSP430Core）对比，可以看到STM32L4的功耗在该Benchmark下更低。<a href="https://www.eembc.org/viewer/?benchmark_seq=2760,2679">DETAIL</a></p><p><img src= "/img/loading.gif" data-lazy-src="C:\Users\12552\AppData\Roaming\Typora\typora-user-images\image-20201014121221114.png" alt="image-20201014121221114"></p><h2 id="耗电量估算"><a href="#耗电量估算" class="headerlink" title="耗电量估算"></a>耗电量估算</h2><p>ESP8266系列功耗</p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/27/gjav2t9mG5BpFUT.png" alt="image-20200927172219640" style="zoom:67%;" /><p>TODO：</p><p>LINKS：</p><p>ULP Benchmark <a href="https://www.eembc.org/ulpmark/scores.php">https://www.eembc.org/ulpmark/scores.php</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;解决方案调研（2）&quot;&gt;&lt;a href=&quot;#解决方案调研（2）&quot; class=&quot;headerlink&quot; title=&quot;解决方案调研（2）&quot;&gt;&lt;/a&gt;解决方案调研（2）&lt;/h1&gt;&lt;p&gt;GOAL：针对上一次老师提出的点进行补充调研。&lt;a href=&quot;https://ie
      
    
    </summary>
    
    
      <category term="Works" scheme="http://canVa4.github.io/categories/Works/"/>
    
    
      <category term="单片机" scheme="http://canVa4.github.io/tags/%E5%8D%95%E7%89%87%E6%9C%BA/"/>
    
      <category term="STM32" scheme="http://canVa4.github.io/tags/STM32/"/>
    
      <category term="msp" scheme="http://canVa4.github.io/tags/msp/"/>
    
      <category term="TPU" scheme="http://canVa4.github.io/tags/TPU/"/>
    
  </entry>
  
  <entry>
    <title>CS231n Assignment3 遇到的问题</title>
    <link href="http://canva4.github.io/2020/08/27/CS231n-Assignment3-%E5%AE%9E%E7%8E%B0%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>http://canva4.github.io/2020/08/27/CS231n-Assignment3-%E5%AE%9E%E7%8E%B0%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</id>
    <published>2020-08-27T09:04:38.000Z</published>
    <updated>2020-09-13T09:23:11.892Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CS231n-Assignment3-遇到的问题"><a href="#CS231n-Assignment3-遇到的问题" class="headerlink" title="CS231n Assignment3 遇到的问题"></a>CS231n Assignment3 遇到的问题</h1><ul><li>实现基于2019年版的课程</li><li>主要记录遇到的问题</li></ul><p>我的assignment的<a href="https://github.com/canVa4/CS231n-Assignments">github仓库</a>，包含全部的代码和notebook。</p><h2 id="Image-Captioning-with-RNNs"><a href="#Image-Captioning-with-RNNs" class="headerlink" title="Image Captioning with RNNs"></a>Image Captioning with RNNs</h2><p>本部分主要是实现RNN的基础版本。即如下的RNN，不过需要注意的是在代码中实现时要注意矩阵相乘的顺序。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/03/FQu3U9OsD5gtvYi.png" alt="image-20200903233248910"></p><p>首先是每次time step时的forward的backward，这里比较简单，按照上图公式implement一下就ok了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_step_forward</span>(<span class="params">x, prev_h, Wx, Wh, b</span>):</span></span><br><span class="line">    next_h, cache = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    next_h = np.tanh(np.dot(prev_h, Wh) + np.dot(x, Wx) + b)</span><br><span class="line">    cache = Wx, Wh, next_h, prev_h, x, b</span><br><span class="line">    <span class="keyword">return</span> next_h, cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_step_backward</span>(<span class="params">dnext_h, cache</span>):</span></span><br><span class="line">    dx, dprev_h, dWx, dWh, db = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    Wx, Wh, next_h, prev_h, x, b = cache</span><br><span class="line">    dmid = (<span class="number">1</span> - np.square(next_h)) * dnext_h</span><br><span class="line">    dprev_h = np.dot(dmid, Wh.T)</span><br><span class="line">    dx = np.dot(dmid, Wx.T)</span><br><span class="line">    dWh = np.dot(prev_h.T, dmid)</span><br><span class="line">    dWx = np.dot(x.T, dmid)</span><br><span class="line">    db = np.sum(dmid, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> dx, dprev_h, dWx, dWh, db</span><br></pre></td></tr></table></figure><p>然后是在一定time sequence上的forward和backward，forward就是多层step forward的叠加，backward计算梯度就是将每次对x的梯度持续回传，将对W权值矩阵的梯度叠加即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_forward</span>(<span class="params">x, h0, Wx, Wh, b</span>):</span></span><br><span class="line">    h, cache = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    N, T, D = x.shape</span><br><span class="line">    cache = []</span><br><span class="line">    h = np.zeros((N, T, h0.shape[<span class="number">1</span>]))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(T):</span><br><span class="line">        h0, c = rnn_step_forward(x[:, i, :], h0, Wx, Wh, b)</span><br><span class="line">        h[:, i] += h0</span><br><span class="line">        cache.append(c)</span><br><span class="line">    <span class="keyword">return</span> h, cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_backward</span>(<span class="params">dh, cache</span>):</span></span><br><span class="line">    dx, dh0, dWx, dWh, db = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    N, T, H = dh.shape</span><br><span class="line">    D = cache[<span class="number">0</span>][<span class="number">0</span>].shape[<span class="number">0</span>]</span><br><span class="line">    dx = np.zeros((N, T, D))</span><br><span class="line">    dh0 = np.zeros((N, H))</span><br><span class="line">    dWx = np.zeros((D, H))</span><br><span class="line">    dWh = np.zeros((H, H))</span><br><span class="line">    db = np.zeros((H,))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> reversed(range(T)):</span><br><span class="line">        dx[:, i], dh0, dWx_mid, dWh_mid, db_mid = rnn_step_backward(dh[:, i] + dh0, cache.pop())</span><br><span class="line">        dWx += dWx_mid</span><br><span class="line">        dWh += dWh_mid</span><br><span class="line">        db += db_mid</span><br><span class="line">    <span class="keyword">return</span> dx, dh0, dWx, dWh, db</span><br></pre></td></tr></table></figure><p>实现这些基本核心组件后，还需要实现的就是根据word 生成 embedding，这里使用的是类似于查询的方法，有一个对应的生成embedding的矩阵，这个也是可以学习的。forward很简单，就是类似的查询，backward的实现我遇到了实现上的问题，最后借鉴了一下别人的code。:)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">word_embedding_forward</span>(<span class="params">x, W</span>):</span></span><br><span class="line">    out, cache = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    out = W[x]</span><br><span class="line">    cache = x, W</span><br><span class="line">    <span class="keyword">return</span> out, cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">word_embedding_backward</span>(<span class="params">dout, cache</span>):</span></span><br><span class="line">    dW = <span class="literal">None</span></span><br><span class="line">    x, W = cache</span><br><span class="line">    dW = np.zeros_like(W)</span><br><span class="line">    N, T, D = dout.shape</span><br><span class="line">    np.add.at(dW, x.flatten(), dout.reshape(<span class="number">-1</span>, D))     <span class="comment"># 这里借鉴了一下别人的代码</span></span><br><span class="line">    <span class="keyword">return</span> dW</span><br></pre></td></tr></table></figure><p>最后要实现的就是class RNN了。这个部分只要认真看代码中的提升，注意下细节根据流程和之前实现好的模块实现即可了。</p><p><strong>forward 函数</strong>，位于<code>rnn.py</code> rnn类内。这里的处理是将caption分为两部分：captions_in除了最后一个单词外，所有内容都将被输入到RNN； 而captions_out只不包含第一个单词。这就是期望RNN生成的东西。 它们彼此相对偏移一个，因为RNN在接收到单词t之后会产生单词（t + 1）。 captions_in的第一个元素将是START caption，我们的期望是captions_out的第一个元素将是第一个单词。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">self, features, captions</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute training-time loss for the RNN. We input image features and</span></span><br><span class="line"><span class="string">    ground-truth captions for those images, and use an RNN (or LSTM) to compute</span></span><br><span class="line"><span class="string">    loss and gradients on all parameters.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - features: Input image features, of shape (N, D)</span></span><br><span class="line"><span class="string">    - captions: Ground-truth captions; an integer array of shape (N, T) where</span></span><br><span class="line"><span class="string">      each element is in the range 0 &lt;= y[i, t] &lt; V</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - loss: Scalar loss</span></span><br><span class="line"><span class="string">    - grads: Dictionary of gradients parallel to self.params</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Cut captions into two pieces: captions_in has everything but the last word</span></span><br><span class="line">    <span class="comment"># and will be input to the RNN; captions_out has everything but the first</span></span><br><span class="line">    <span class="comment"># word and this is what we will expect the RNN to generate. These are offset</span></span><br><span class="line">    <span class="comment"># by one relative to each other because the RNN should produce word (t+1)</span></span><br><span class="line">    <span class="comment"># after receiving word t. The first element of captions_in will be the START</span></span><br><span class="line">    <span class="comment"># token, and the first element of captions_out will be the first word.</span></span><br><span class="line">    captions_in = captions[:, :<span class="number">-1</span>]</span><br><span class="line">    captions_out = captions[:, <span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># You&#x27;ll need this</span></span><br><span class="line">    mask = (captions_out != self._null)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Weight and bias for the affine transform from image features to initial</span></span><br><span class="line">    <span class="comment"># hidden state</span></span><br><span class="line">    W_proj, b_proj = self.params[<span class="string">&#x27;W_proj&#x27;</span>], self.params[<span class="string">&#x27;b_proj&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Word embedding matrix</span></span><br><span class="line">    W_embed = self.params[<span class="string">&#x27;W_embed&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Input-to-hidden, hidden-to-hidden, and biases for the RNN</span></span><br><span class="line">    Wx, Wh, b = self.params[<span class="string">&#x27;Wx&#x27;</span>], self.params[<span class="string">&#x27;Wh&#x27;</span>], self.params[<span class="string">&#x27;b&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Weight and bias for the hidden-to-vocab transformation.</span></span><br><span class="line">    W_vocab, b_vocab = self.params[<span class="string">&#x27;W_vocab&#x27;</span>], self.params[<span class="string">&#x27;b_vocab&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    loss, grads = <span class="number">0.0</span>, &#123;&#125;</span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Implement the forward and backward passes for the CaptioningRNN.   #</span></span><br><span class="line">    <span class="comment"># In the forward pass you will need to do the following:                   #</span></span><br><span class="line">    <span class="comment"># (1) Use an affine transformation to compute the initial hidden state     #</span></span><br><span class="line">    <span class="comment">#     from the image features. This should produce an array of shape (N, H)#</span></span><br><span class="line">    <span class="comment"># (2) Use a word embedding layer to transform the words in captions_in     #</span></span><br><span class="line">    <span class="comment">#     from indices to vectors, giving an array of shape (N, T, W).         #</span></span><br><span class="line">    <span class="comment"># (3) Use either a vanilla RNN or LSTM (depending on self.cell_type) to    #</span></span><br><span class="line">    <span class="comment">#     process the sequence of input word vectors and produce hidden state  #</span></span><br><span class="line">    <span class="comment">#     vectors for all timesteps, producing an array of shape (N, T, H).    #</span></span><br><span class="line">    <span class="comment"># (4) Use a (temporal) affine transformation to compute scores over the    #</span></span><br><span class="line">    <span class="comment">#     vocabulary at every timestep using the hidden states, giving an      #</span></span><br><span class="line">    <span class="comment">#     array of shape (N, T, V).                                            #</span></span><br><span class="line">    <span class="comment"># (5) Use (temporal) softmax to compute loss using captions_out, ignoring  #</span></span><br><span class="line">    <span class="comment">#     the points where the output word is &lt;NULL&gt; using the mask above.     #</span></span><br><span class="line">    <span class="comment">#                                                                          #</span></span><br><span class="line">    <span class="comment"># In the backward pass you will need to compute the gradient of the loss   #</span></span><br><span class="line">    <span class="comment"># with respect to all model parameters. Use the loss and grads variables   #</span></span><br><span class="line">    <span class="comment"># defined above to store loss and gradients; grads[k] should give the      #</span></span><br><span class="line">    <span class="comment"># gradients for self.params[k].                                            #</span></span><br><span class="line">    <span class="comment">#                                                                          #</span></span><br><span class="line">    <span class="comment"># Note also that you are allowed to make use of functions from layers.py   #</span></span><br><span class="line">    <span class="comment"># in your implementation, if needed.                                       #</span></span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">    caches = []</span><br><span class="line">    out, cache = affine_forward(features, W_proj, b_proj)</span><br><span class="line">    caches.append(cache)</span><br><span class="line">    word_in, cache = word_embedding_forward(captions_in, W_embed)</span><br><span class="line">    caches.append(cache)</span><br><span class="line">    <span class="keyword">if</span> self.cell_type == <span class="string">&#x27;rnn&#x27;</span>:  <span class="comment"># must rnn or lstm</span></span><br><span class="line">        out, cache = rnn_forward(word_in, out, Wx, Wh, b)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        out, cache = lstm_forward(word_in, out, Wx, Wh, b)</span><br><span class="line">    caches.append(cache)</span><br><span class="line">    out, cache = temporal_affine_forward(out, W_vocab, b_vocab)</span><br><span class="line">    caches.append(cache)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backward</span></span><br><span class="line">    loss, dx = temporal_softmax_loss(out, captions_out, mask)</span><br><span class="line"></span><br><span class="line">    dx, grads[<span class="string">&#x27;W_vocab&#x27;</span>], grads[<span class="string">&#x27;b_vocab&#x27;</span>] = temporal_affine_backward(dx, caches.pop())</span><br><span class="line">    <span class="keyword">if</span> self.cell_type == <span class="string">&#x27;rnn&#x27;</span>:</span><br><span class="line">        d_caption, dx, grads[<span class="string">&#x27;Wx&#x27;</span>], grads[<span class="string">&#x27;Wh&#x27;</span>], grads[<span class="string">&#x27;b&#x27;</span>] = rnn_backward(dx, caches.pop())</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        d_caption, dx, grads[<span class="string">&#x27;Wx&#x27;</span>], grads[<span class="string">&#x27;Wh&#x27;</span>], grads[<span class="string">&#x27;b&#x27;</span>] = lstm_backward(dx, caches.pop())</span><br><span class="line">    grads[<span class="string">&#x27;W_embed&#x27;</span>] = word_embedding_backward(d_caption, caches.pop())</span><br><span class="line">    _, grads[<span class="string">&#x27;W_proj&#x27;</span>], grads[<span class="string">&#x27;b_proj&#x27;</span>] = affine_backward(dx, caches.pop())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="comment">#                             END OF YOUR CODE                             #</span></span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss, grads</span><br></pre></td></tr></table></figure><p><strong>sample 函数</strong>，位于<code>rnn.py</code> rnn类内。其要实现的效果如下图所示。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/03/AtirSuRMczObNC9.png" alt="image-20200903234531509"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample</span>(<span class="params">self, features, max_length=<span class="number">30</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Run a test-time forward pass for the model, sampling captions for input</span></span><br><span class="line"><span class="string">    feature vectors.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    At each timestep, we embed the current word, pass it and the previous hidden</span></span><br><span class="line"><span class="string">    state to the RNN to get the next hidden state, use the hidden state to get</span></span><br><span class="line"><span class="string">    scores for all vocab words, and choose the word with the highest score as</span></span><br><span class="line"><span class="string">    the next word. The initial hidden state is computed by applying an affine</span></span><br><span class="line"><span class="string">    transform to the input image features, and the initial word is the &lt;START&gt;</span></span><br><span class="line"><span class="string">    token.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For LSTMs you will also have to keep track of the cell state; in that case</span></span><br><span class="line"><span class="string">    the initial cell state should be zero.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - features: Array of input image features of shape (N, D).</span></span><br><span class="line"><span class="string">    - max_length: Maximum length T of generated captions.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    - captions: Array of shape (N, max_length) giving sampled captions,</span></span><br><span class="line"><span class="string">      where each element is an integer in the range [0, V). The first element</span></span><br><span class="line"><span class="string">      of captions should be the first sampled word, not the &lt;START&gt; token.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    N = features.shape[<span class="number">0</span>]</span><br><span class="line">    captions = self._null * np.ones((N, max_length), dtype=np.int32)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Unpack parameters</span></span><br><span class="line">    W_proj, b_proj = self.params[<span class="string">&#x27;W_proj&#x27;</span>], self.params[<span class="string">&#x27;b_proj&#x27;</span>]</span><br><span class="line">    W_embed = self.params[<span class="string">&#x27;W_embed&#x27;</span>]</span><br><span class="line">    Wx, Wh, b = self.params[<span class="string">&#x27;Wx&#x27;</span>], self.params[<span class="string">&#x27;Wh&#x27;</span>], self.params[<span class="string">&#x27;b&#x27;</span>]</span><br><span class="line">    W_vocab, b_vocab = self.params[<span class="string">&#x27;W_vocab&#x27;</span>], self.params[<span class="string">&#x27;b_vocab&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">###########################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Implement test-time sampling for the model. You will need to      #</span></span><br><span class="line">    <span class="comment"># initialize the hidden state of the RNN by applying the learned affine   #</span></span><br><span class="line">    <span class="comment"># transform to the input image features. The first word that you feed to  #</span></span><br><span class="line">    <span class="comment"># the RNN should be the &lt;START&gt; token; its value is stored in the         #</span></span><br><span class="line">    <span class="comment"># variable self._start. At each timestep you will need to do to:          #</span></span><br><span class="line">    <span class="comment"># (1) Embed the previous word using the learned word embeddings           #</span></span><br><span class="line">    <span class="comment"># (2) Make an RNN step using the previous hidden state and the embedded   #</span></span><br><span class="line">    <span class="comment">#     current word to get the next hidden state.                          #</span></span><br><span class="line">    <span class="comment"># (3) Apply the learned affine transformation to the next hidden state to #</span></span><br><span class="line">    <span class="comment">#     get scores for all words in the vocabulary                          #</span></span><br><span class="line">    <span class="comment"># (4) Select the word with the highest score as the next word, writing it #</span></span><br><span class="line">    <span class="comment">#     (the word index) to the appropriate slot in the captions variable   #</span></span><br><span class="line">    <span class="comment">#                                                                         #</span></span><br><span class="line">    <span class="comment"># For simplicity, you do not need to stop generating after an &lt;END&gt; token #</span></span><br><span class="line">    <span class="comment"># is sampled, but you can if you want to.                                 #</span></span><br><span class="line">    <span class="comment">#                                                                         #</span></span><br><span class="line">    <span class="comment"># HINT: You will not be able to use the rnn_forward or lstm_forward       #</span></span><br><span class="line">    <span class="comment"># functions; you&#x27;ll need to call rnn_step_forward or lstm_step_forward in #</span></span><br><span class="line">    <span class="comment"># a loop.                                                                 #</span></span><br><span class="line">    <span class="comment">#                                                                         #</span></span><br><span class="line">    <span class="comment"># <span class="doctag">NOTE:</span> we are still working over minibatches in this function. Also if   #</span></span><br><span class="line">    <span class="comment"># you are using an LSTM, initialize the first cell state to zeros.        #</span></span><br><span class="line">    <span class="comment">###########################################################################</span></span><br><span class="line">    <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">    next_h, _ = affine_forward(features, W_proj, b_proj)</span><br><span class="line">    next_c = np.zeros((N, W_proj.shape[<span class="number">1</span>]))</span><br><span class="line">    word = self._start * np.ones((N,), dtype=np.int32)</span><br><span class="line">    <span class="comment"># generate start token</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(max_length):</span><br><span class="line">        word, _ = word_embedding_forward(word, W_embed)</span><br><span class="line">        <span class="comment"># embed the word to vector</span></span><br><span class="line">        <span class="keyword">if</span> self.cell_type == <span class="string">&#x27;rnn&#x27;</span>:</span><br><span class="line">            next_h, _ = rnn_step_forward(word, next_h, Wx, Wh, b)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            next_h, next_c, _ = lstm_step_forward(word, next_h, next_c, Wx, Wh, b)</span><br><span class="line"></span><br><span class="line">        out, _ = affine_forward(next_h, W_vocab, b_vocab)</span><br><span class="line">        <span class="comment"># get the output</span></span><br><span class="line">        word = out.argmax(axis=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># sample</span></span><br><span class="line">        captions[:, i] = word</span><br><span class="line">    <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="comment">#                             END OF YOUR CODE                             #</span></span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="keyword">return</span> captions</span><br></pre></td></tr></table></figure><h2 id="Image-Captioning-with-LSTMs"><a href="#Image-Captioning-with-LSTMs" class="headerlink" title="Image Captioning with LSTMs"></a>Image Captioning with LSTMs</h2><p>本部分主要就是将vanilla RNN变为LSTM在重复上述的任务。</p><p>首先是forward，根据公式敲一下就ok了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_step_forward</span>(<span class="params">x, prev_h, prev_c, Wx, Wh, b</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Forward pass for a single timestep of an LSTM.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The input data has dimension D, the hidden state has dimension H, and we use</span></span><br><span class="line"><span class="string">    a minibatch size of N.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Note that a sigmoid() function has already been provided for you in this file.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - x: Input data, of shape (N, D)</span></span><br><span class="line"><span class="string">    - prev_h: Previous hidden state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - prev_c: previous cell state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - Wx: Input-to-hidden weights, of shape (D, 4H)</span></span><br><span class="line"><span class="string">    - Wh: Hidden-to-hidden weights, of shape (H, 4H)</span></span><br><span class="line"><span class="string">    - b: Biases, of shape (4H,)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - next_h: Next hidden state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - next_c: Next cell state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - cache: Tuple of values needed for backward pass.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    next_h, next_c, cache = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    N, H = prev_h.shape</span><br><span class="line">    a = np.dot(x, Wx) + np.dot(prev_h, Wh) + b</span><br><span class="line">    i = sigmoid(a[:, :H])</span><br><span class="line">    f = sigmoid(a[:, H:<span class="number">2</span>*H])</span><br><span class="line">    o = sigmoid(a[:, <span class="number">2</span>*H:<span class="number">3</span>*H])</span><br><span class="line">    g = np.tanh(a[:, <span class="number">3</span>*H:])</span><br><span class="line">    next_c = f * prev_c + i * g</span><br><span class="line">    next_h = o * np.tanh(next_c)</span><br><span class="line">    cache = i, f, o, g, next_c, Wh, Wx, prev_c, prev_h, x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> next_h, next_c, cache</span><br></pre></td></tr></table></figure><p>经历过那么多次求导，出现的问题越来越少了，实现起来也比较顺畅，下面给出我整理后的求导过程。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/06/Z4HB6QspSybWL9A.png" alt="image-20200906111112135"></p><p>然后就是敲一下代码了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_step_backward</span>(<span class="params">dnext_h, dnext_c, cache</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Backward pass for a single timestep of an LSTM.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - dnext_h: Gradients of next hidden state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - dnext_c: Gradients of next cell state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - cache: Values from the forward pass</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - dx: Gradient of input data, of shape (N, D)</span></span><br><span class="line"><span class="string">    - dprev_h: Gradient of previous hidden state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - dprev_c: Gradient of previous cell state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - dWx: Gradient of input-to-hidden weights, of shape (D, 4H)</span></span><br><span class="line"><span class="string">    - dWh: Gradient of hidden-to-hidden weights, of shape (H, 4H)</span></span><br><span class="line"><span class="string">    - db: Gradient of biases, of shape (4H,)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dx, dprev_h, dprev_c, dWx, dWh, db = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    i, f, o, g, next_c, Wh, Wx, prev_c, prev_h, x = cache</span><br><span class="line">    dprev_c = dnext_c * f + dnext_h * o * f * (<span class="number">1</span> - np.tanh(next_c)**<span class="number">2</span>)</span><br><span class="line">    dc = dnext_c + (<span class="number">1</span> - np.tanh(next_c)**<span class="number">2</span>) * o * dnext_h     <span class="comment"># 这里遇到了问题</span></span><br><span class="line">    di = dc * g * i * (<span class="number">1</span> - i)</span><br><span class="line">    df = dc * prev_c * f * (<span class="number">1</span> - f)</span><br><span class="line">    do = dnext_h * np.tanh(next_c) * o * (<span class="number">1</span> - o)</span><br><span class="line">    dg = dc * i * (<span class="number">1</span> - g**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    da = np.hstack((di, df, do, dg))</span><br><span class="line">    dprev_h = np.dot(da, Wh.T)</span><br><span class="line">    dx = np.dot(da, Wx.T)</span><br><span class="line">    db = np.sum(da, axis=<span class="number">0</span>)</span><br><span class="line">    dWx = np.dot(x.T, da)</span><br><span class="line">    dWh = np.dot(prev_h.T, da)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dx, dprev_h, dprev_c, dWx, dWh, db</span><br></pre></td></tr></table></figure><p>接下来就是对于一个sequence而不是单独的time step使用LSTM了。首先是forward</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_forward</span>(<span class="params">x, h0, Wx, Wh, b</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Forward pass for an LSTM over an entire sequence of data. We assume an input</span></span><br><span class="line"><span class="string">    sequence composed of T vectors, each of dimension D. The LSTM uses a hidden</span></span><br><span class="line"><span class="string">    size of H, and we work over a minibatch containing N sequences. After running</span></span><br><span class="line"><span class="string">    the LSTM forward, we return the hidden states for all timesteps.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Note that the initial cell state is passed as input, but the initial cell</span></span><br><span class="line"><span class="string">    state is set to zero. Also note that the cell state is not returned; it is</span></span><br><span class="line"><span class="string">    an internal variable to the LSTM and is not accessed from outside.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - x: Input data of shape (N, T, D)</span></span><br><span class="line"><span class="string">    - h0: Initial hidden state of shape (N, H)</span></span><br><span class="line"><span class="string">    - Wx: Weights for input-to-hidden connections, of shape (D, 4H)</span></span><br><span class="line"><span class="string">    - Wh: Weights for hidden-to-hidden connections, of shape (H, 4H)</span></span><br><span class="line"><span class="string">    - b: Biases of shape (4H,)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - h: Hidden states for all timesteps of all sequences, of shape (N, T, H)</span></span><br><span class="line"><span class="string">    - cache: Values needed for the backward pass.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    h, cache = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    N, T, D = x.shape</span><br><span class="line">    N, H = h0.shape</span><br><span class="line">    h = np.zeros((N, T, H))</span><br><span class="line">    cache = []</span><br><span class="line">    c0 = np.zeros_like(h0)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(T):</span><br><span class="line">        h0, c0, c = lstm_step_forward(x[:, i, :], h0, c0, Wx, Wh, b)</span><br><span class="line">        h[:, i, :] = h0</span><br><span class="line">        cache.append(c)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> h, cache</span><br></pre></td></tr></table></figure><div class="note warning">            <p>需要注意的是，在backward时，如何传递梯度：up stream的当前time step的loss + 上一个step step传回来的loss</p>          </div><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_backward</span>(<span class="params">dh, cache</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Backward pass for an LSTM over an entire sequence of data.]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - dh: Upstream gradients of hidden states, of shape (N, T, H)</span></span><br><span class="line"><span class="string">    - cache: Values from the forward pass</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - dx: Gradient of input data of shape (N, T, D)</span></span><br><span class="line"><span class="string">    - dh0: Gradient of initial hidden state of shape (N, H)</span></span><br><span class="line"><span class="string">    - dWx: Gradient of input-to-hidden weight matrix of shape (D, 4H)</span></span><br><span class="line"><span class="string">    - dWh: Gradient of hidden-to-hidden weight matrix of shape (H, 4H)</span></span><br><span class="line"><span class="string">    - db: Gradient of biases, of shape (4H,)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dx, dh0, dWx, dWh, db = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    N, T, H = dh.shape</span><br><span class="line">    _, D = cache[<span class="number">0</span>][<span class="number">-1</span>].shape    <span class="comment"># cache[0][-1]对应x</span></span><br><span class="line">    dx = np.zeros((N, T, D))</span><br><span class="line">    dc = np.zeros((N, H))</span><br><span class="line">    dWx = np.zeros((D, <span class="number">4</span> * H))</span><br><span class="line">    dWh = np.zeros((H, <span class="number">4</span> * H))</span><br><span class="line">    db = np.zeros((<span class="number">4</span> * H,))</span><br><span class="line">    dh0 = np.zeros((N, H))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> reversed(range(T)):</span><br><span class="line">        dx[:, i, :], dh0, dc, dWx_, dWh_, db_ = lstm_step_backward(dh[:, i, :] + dh0, dc, cache.pop())</span><br><span class="line">        db += db_</span><br><span class="line">        dWx += dWx_</span><br><span class="line">        dWh += dWh_</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dx, dh0, dWx, dWh, db</span><br></pre></td></tr></table></figure><p>剩下的部分就比较ez了，只需对于上一个task的代码稍作修改即可，具体的代码就不再列出。</p><h2 id="Network-Visualization-PyTorch"><a href="#Network-Visualization-PyTorch" class="headerlink" title="Network Visualization (PyTorch)"></a>Network Visualization (PyTorch)</h2><p>本部分主要实现<strong>Saliency Maps,  Fooling image, Class visualization</strong> 三种的实现本质都是计算输入图片的梯度，Saliency Map是直接将关于正确label的loss的梯度的绝对值显示出来；Fooling Image 则是利用梯度信息，将一个A类别的输入变为网络识别为B类别；Class Visualization则是输入一个噪声，使用gradient ascent利用梯度信息将该图片在期望变成的类别下，神经网络的输出的期望类别的class score最大。由于使用pytorch，可以直接计算grad，整体实现比较简单，理解好这几个过程就可以了。代码部分不再单独给出，详情见我的github仓库。</p><div class="note warning">            <p>在代码运行时，可能会遇到使用numpy.load()函数报错的情况，提示需要将allow_pickle=Ture，此时只需要在该np.load的参数内加入‘allow_pickle=True’即可。具体细节可见<code>cs231n/data_utils.py/load_imagenet_val</code></p>          </div><h2 id="Style-Transfer"><a href="#Style-Transfer" class="headerlink" title="Style Transfer"></a>Style Transfer</h2><p>本部分就是实现style transfer的部分了！难度不高，核心就是实现好3个loss，并将整个流程梳理下来即可。实现后真的非常好玩！</p><p>首先是Style Transfer（2016）整体的框图</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/10/6FYEV92PxcUlXDH.png" alt="image-20200910100801040"></p><p>从图中就可以看出，包含两个loss，分别是：style image每层的每个filter的activation map的gram matrix（用来衡量相似性）和input image的gram matrix之间产生的loss（<strong>Style Loss</strong>）和 input image和content image之间的差异性（<strong>Content Loss</strong>）。最后为了使生成的图片更加真实，会加入一个正则项，这里使用的是<strong>Total-variation regularization</strong>。所以最终的loss就是：**Style Loss+Content Loss + Total-variation regularization **。之后使用这个loss计算输入图片的梯度，并使用Adam或者SDG等方法更新输入图片即可。</p><p>提取特征的网络使用的是squeeze net，因为其模型参数少，运算快且性能适中。</p><h3 id="Content-Loss"><a href="#Content-Loss" class="headerlink" title="Content Loss"></a>Content Loss</h3><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/10/3cBroD8hxIkadGQ.png" alt="image-20200910101647611"></p><p>比较简单，如框图所示，就是将input image和content image在某一层的activation map做一下reshape，从1*C*H<em>W变为1\</em>C*(H*W)即可。相减后逐元素平方再求和即可。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">content_loss</span>(<span class="params">content_weight, content_current, content_original</span>):</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Compute the content loss for style transfer.</span></span><br><span class="line"><span class="string">Inputs:</span></span><br><span class="line"><span class="string">- content_weight: Scalar giving the weighting for the content loss.</span></span><br><span class="line"><span class="string">- content_current: features of the current image; this is a PyTorch Tensor of shape</span></span><br><span class="line"><span class="string">  (1, C_l, H_l, W_l).</span></span><br><span class="line"><span class="string">- content_target: features of the content image, Tensor with shape (1, C_l, H_l, W_l).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">- scalar content loss</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">    loss = content_weight * torch.sum(torch.square(content_current.squeeze() - content_original.squeeze()))</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><h3 id="Style-Loss"><a href="#Style-Loss" class="headerlink" title="Style Loss"></a>Style Loss</h3><p>稍微复杂一点，核心就是计算一个Gram matrix，该矩阵用来衡量similarity。下图为Gram matrix计算的示意图。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/10/LSUCjJ5Y19N2AtF.png" alt="image-20200910102135973"></p><p>左边是某一层的activation map，之后将其变为C*(H*W)，所有行向量直接做內积，就有了C*C的gram matrix。</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gram_matrix</span>(<span class="params">features, normalize=True</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute the Gram matrix from features.</span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - features: PyTorch Tensor of shape (N, C, H, W) giving features for</span></span><br><span class="line"><span class="string">      a batch of N images.</span></span><br><span class="line"><span class="string">    - normalize: optional, whether to normalize the Gram matrix</span></span><br><span class="line"><span class="string">        If True, divide the Gram matrix by the number of neurons (H * W * C)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    - gram: PyTorch Tensor of shape (N, C, C) giving the</span></span><br><span class="line"><span class="string">      (optionally normalized) Gram matrices for the N input images.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    N,C,H,W = features.size()</span><br><span class="line">    new_features = features.reshape((N,C,H*W))</span><br><span class="line">    gram_mat = torch.zeros(N,C,C)</span><br><span class="line">    gram_mat = torch.bmm(new_features, new_features.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">if</span> normalize:</span><br><span class="line">        <span class="keyword">return</span> gram_mat / (H*W*C)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> gram_matm</span><br></pre></td></tr></table></figure><p>之后就是如框图所示，将style image各层的gram matrix和input image各层的gram matrix相减后逐元素平方再求和即可。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">style_loss</span>(<span class="params">feats, style_layers, style_targets, style_weights</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Computes the style loss at a set of layers.</span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - feats: list of the features at every layer of the current image, as produced by</span></span><br><span class="line"><span class="string">      the extract_features function.</span></span><br><span class="line"><span class="string">    - style_layers: List of layer indices into feats giving the layers to include in the</span></span><br><span class="line"><span class="string">      style loss.</span></span><br><span class="line"><span class="string">    - style_targets: List of the same length as style_layers, where style_targets[i] is</span></span><br><span class="line"><span class="string">      a PyTorch Tensor giving the Gram matrix of the source style image computed at</span></span><br><span class="line"><span class="string">      layer style_layers[i].</span></span><br><span class="line"><span class="string">    - style_weights: List of the same length as style_layers, where style_weights[i]</span></span><br><span class="line"><span class="string">      is a scalar giving the weight for the style loss at layer style_layers[i].</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    - style_loss: A PyTorch Tensor holding a scalar giving the style loss.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    tensor = torch.tensor(())</span><br><span class="line">    loss = tensor.new_zeros(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(style_layers)):</span><br><span class="line">        gram_mat = gram_matrix(feats[style_layers[i]])</span><br><span class="line">        loss += style_weights[i] * torch.sum((gram_mat - style_targets[i]).square())</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><h3 id="Total-variation-regularization"><a href="#Total-variation-regularization" class="headerlink" title="Total-variation regularization"></a>Total-variation regularization</h3><p>该项是一个正则化项，公式如下：</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/10/FXuz216PhIvrbx9.png" alt="image-20200910102605899"></p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tv_loss</span>(<span class="params">img, tv_weight</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute total variation loss.</span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - img: PyTorch Variable of shape (1, 3, H, W) holding an input image.</span></span><br><span class="line"><span class="string">    - tv_weight: Scalar giving the weight w_t to use for the TV loss.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    - loss: PyTorch Variable holding a scalar giving the total variation loss</span></span><br><span class="line"><span class="string">      for img weighted by tv_weight.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    loss = tv_weight * (torch.sum((img[<span class="number">0</span>,:,<span class="number">1</span>:,:] - img[<span class="number">0</span>,:,:<span class="number">-1</span>,:]).square()) + torch.sum((img[<span class="number">0</span>,:,:,<span class="number">1</span>:] - img[<span class="number">0</span>,:,:,:<span class="number">-1</span>]).square()))</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><h3 id="Over-ALL"><a href="#Over-ALL" class="headerlink" title="Over ALL"></a>Over ALL</h3><p>完成的上面的部分后就是整合了，note book中的代码已经给出。不再赘述。值得注意的是，使用同样的代码，我们还可以完成<strong>Feature Inversion</strong>和<strong>texture synthesis</strong>这两个任务。对于<strong>texture synthesis</strong>，只需将content loss置零即可。对于<strong>Feature Inversion</strong>只需将style loss置零即可。下面是一些自己测试的结果。</p><div class="fig figcenter fighighlight">  <img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/10/MojOJTfCVnYA46L.png" width="30%">  <img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/10/BrTLcfMZoCpSU98.png" width="20%" style="border-left: 1px solid black;">  <div class="figcaption">Style Transfer Left: Style img and Input img. Right: result(200 iteration).</div></div><div class="fig figcenter fighighlight">  <img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/10/yLZAnhrJ5VItsux.png" width="30%">  <img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/10/enD34UK7J1oqut5.png" width="20%" style="border-left: 1px solid black;">  <div class="figcaption">texture synthesis Left: Style img. Right: result(200 iteration).</div></div><h2 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h2><p>本部分的GAN实现了报过最原始的2014年 GoodFellow的原始GAN，以及Last Square GAN（优化了损失函数）和Deep Convolutional GANs。整体来讲使用pytorch建立模型和训练都比较简单，note book中主要实现的就是discriminator和generator的loss，将这个实现好即可。这部分的难度不是很高，就不再列出了，具体代码和结果可以参考我的github仓库。</p><h2 id="END"><a href="#END" class="headerlink" title="END"></a>END</h2><p>至此，整个CS231n的课程就结束啦！为期了一个多月，中间因为各种事前耽误了几天，本来计划1个月内就搞定的。感觉CS231n课程整体来讲的难度适中，在数学推倒部分设计的稍微少了一些，但可以建立很多intuition的东西，总之还是收获颇丰的。</p><p>最大的收获就是他的assignment了，有一定难度的同时也极大的加深了对于这些知识的理解。</p><p>TODO：</p><ul><li>下一步可能会写一个GAN相关的小总结。</li><li>看一些more mathematic的东西</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;CS231n-Assignment3-遇到的问题&quot;&gt;&lt;a href=&quot;#CS231n-Assignment3-遇到的问题&quot; class=&quot;headerlink&quot; title=&quot;CS231n Assignment3 遇到的问题&quot;&gt;&lt;/a&gt;CS231n Assignm
      
    
    </summary>
    
    
      <category term="Notes" scheme="http://canVa4.github.io/categories/Notes/"/>
    
    
      <category term="CS231n" scheme="http://canVa4.github.io/tags/CS231n/"/>
    
      <category term="python" scheme="http://canVa4.github.io/tags/python/"/>
    
      <category term="numpy" scheme="http://canVa4.github.io/tags/numpy/"/>
    
  </entry>
  
  <entry>
    <title>CS231n Assignment2 实现时遇到的问题</title>
    <link href="http://canva4.github.io/2020/08/12/CS231n-Assignment2-%E5%AE%9E%E7%8E%B0%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>http://canva4.github.io/2020/08/12/CS231n-Assignment2-%E5%AE%9E%E7%8E%B0%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</id>
    <published>2020-08-12T09:16:42.000Z</published>
    <updated>2020-08-26T14:09:37.651Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CS231n-Assignment2-遇到的问题"><a href="#CS231n-Assignment2-遇到的问题" class="headerlink" title="CS231n Assignment2 遇到的问题"></a>CS231n Assignment2 遇到的问题</h1><ul><li>实现基于2019年版的课程</li><li>主要记录遇到的问题</li></ul><p>我的assignment的<a href="https://github.com/canVa4/CS231n-Assignments">github仓库</a>，包含全部的代码和notebook。</p><h2 id="Fully-connected-Neural-Network"><a href="#Fully-connected-Neural-Network" class="headerlink" title="Fully-connected Neural Network"></a>Fully-connected Neural Network</h2><p>相比于Assignment1，对于整个网络的实现进行了进一步的封装，可以实现任意深度，大小的MLP。</p><div class="note info">            <p>值得一看的代码部分！solver.py中实现调用更新规则函数（在optim.py中实现），实现的很有趣！</p>          </div><p>基本思路为：使用getattr获取定义在optim.py中定义好的update rule函数！我是第一次见这种写法，感觉很巧妙，值得学习一波:)</p><p>当然，要先import optim。</p><p>Core Code(extract):</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">self.update_rule = kwargs.pop(<span class="string">&#x27;update_rule&#x27;</span>, <span class="string">&#x27;sgd&#x27;</span>)</span><br><span class="line">...</span><br><span class="line">   <span class="comment"># Make sure the update rule exists, then replace the string</span></span><br><span class="line">   <span class="comment"># name with the actual function</span></span><br><span class="line">   <span class="keyword">if</span> <span class="keyword">not</span> hasattr(optim, self.update_rule):</span><br><span class="line">       <span class="keyword">raise</span> ValueError(<span class="string">&#x27;Invalid update_rule &quot;%s&quot;&#x27;</span> % self.update_rule)</span><br><span class="line">self.update_rule = getattr(optim, self.update_rule)</span><br></pre></td></tr></table></figure><p>其余部分的实现（如：affine，ReLU的forward和backward；优化算法）注意好细节后都比较容易实现，因为比较复杂的代码框架已经提供好了。</p><p>值得注意的是，官方github仓库中的关于课程内容的markdown笔记值得一读。<a href="http://github.com/cs231n/cs231n.github.io" title="官方课程github仓库">课程github仓库</a>. </p><h2 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h2><p>本部分的实现我遇到了一些问题，在完成上也花费了很多时间，主要遇到的问题还是导数的求取，以及如何将其变化为numpy数组的形式。</p><h3 id="The-Gradient-of-Batch-Normalization"><a href="#The-Gradient-of-Batch-Normalization" class="headerlink" title="The Gradient of Batch Normalization"></a>The Gradient of Batch Normalization</h3><p>由于本部分想知道自己的代码是正确与否需要变为代码后，进行numerical check才能验证。所以，在第一次求导后，我花了很长时间debug，但最后发现是导数求错了。。。</p><p>求导中还是遇到了不少的问题，尤其是在使用链式法则的时候遇到了问题。看来是好久没有好好推公式了QuQ，于是重新复习了一下chain rule和矩阵求导之类的；并重新推到了一下公式。NOTE：以下推导可能并不非常严谨（部分可能不符合矩阵相乘维数），但作为示意和实现代码足够了。</p><p>首先是正向（forward pass）的公式。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/19/heQRF4Um6j7pOxk.png" alt="image-20200819013718586"></p><p>然后是backward计算梯度。这里在计算关于x的偏导时，我遇到了一些问题，很容易丢掉一个导数项；画出变量之间的关系图可以很好地解决这个问题。推导如下：</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/19/ovXSVBY5bPkcyA3.png" alt="image-20200819013948134.png"></p><p>有了这些部分，就可以实现第一个函数batchnorm_backward()和batchnorm_forward()了！</p><p>实际上，上式还可以继续化简，化简的结果更加简洁，省去很多中间变量。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/19/eudk5aMOFLJCApj.png" alt="image-20200819014219098"></p><p>至此，batch normalization的公式推导部分就OK了，下面就是代码实现了。</p><p>这里需要注意的是，由于在predict的时候，一般是没有batch数据的，所以此时没法直接使用batch normalization，所以一种方法就是利用训练时得到的均值和方差来作为predict时的均值和方差。其更新方法使用momentum更新为：</p><pre><code>running_mean = momentum * running_mean + (1 - momentum) * sample_meanrunning_var = momentum * running_var + (1 - momentum) * sample_var</code></pre><h3 id="Code-Implement-of-Batch-Normalization"><a href="#Code-Implement-of-Batch-Normalization" class="headerlink" title="Code Implement of Batch Normalization"></a>Code Implement of Batch Normalization</h3><p>forward没啥可说的，很easy，分开train与test即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batchnorm_forward</span>(<span class="params">x, gamma, beta, bn_param</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Forward pass for batch normalization.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    During training the sample mean and (uncorrected) sample variance are</span></span><br><span class="line"><span class="string">    computed from minibatch statistics and used to normalize the incoming data.</span></span><br><span class="line"><span class="string">    During training we also keep an exponentially decaying running mean of the</span></span><br><span class="line"><span class="string">    mean and variance of each feature, and these averages are used to normalize</span></span><br><span class="line"><span class="string">    data at test-time.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    At each timestep we update the running averages for mean and variance using</span></span><br><span class="line"><span class="string">    an exponential decay based on the momentum parameter:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    running_mean = momentum * running_mean + (1 - momentum) * sample_mean</span></span><br><span class="line"><span class="string">    running_var = momentum * running_var + (1 - momentum) * sample_var</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Note that the batch normalization paper suggests a different test-time</span></span><br><span class="line"><span class="string">    behavior: they compute sample mean and variance for each feature using a</span></span><br><span class="line"><span class="string">    large number of training images rather than using a running average. For</span></span><br><span class="line"><span class="string">    this implementation we have chosen to use running averages instead since</span></span><br><span class="line"><span class="string">    they do not require an additional estimation step; the torch7</span></span><br><span class="line"><span class="string">    implementation of batch normalization also uses running averages.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">    - x: Data of shape (N, D)</span></span><br><span class="line"><span class="string">    - gamma: Scale parameter of shape (D,)</span></span><br><span class="line"><span class="string">    - beta: Shift paremeter of shape (D,)</span></span><br><span class="line"><span class="string">    - bn_param: Dictionary with the following keys:</span></span><br><span class="line"><span class="string">      - mode: &#x27;train&#x27; or &#x27;test&#x27;; required</span></span><br><span class="line"><span class="string">      - eps: Constant for numeric stability</span></span><br><span class="line"><span class="string">      - momentum: Constant for running mean / variance.</span></span><br><span class="line"><span class="string">      - running_mean: Array of shape (D,) giving running mean of features</span></span><br><span class="line"><span class="string">      - running_var Array of shape (D,) giving running variance of features</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - out: of shape (N, D)</span></span><br><span class="line"><span class="string">    - cache: A tuple of values needed in the backward pass</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    mode = bn_param[<span class="string">&#x27;mode&#x27;</span>]</span><br><span class="line">    eps = bn_param.get(<span class="string">&#x27;eps&#x27;</span>, <span class="number">1e-5</span>)</span><br><span class="line">    momentum = bn_param.get(<span class="string">&#x27;momentum&#x27;</span>, <span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">    N, D = x.shape</span><br><span class="line">    running_mean = bn_param.get(<span class="string">&#x27;running_mean&#x27;</span>, np.zeros(D, dtype=x.dtype))</span><br><span class="line">    running_var = bn_param.get(<span class="string">&#x27;running_var&#x27;</span>, np.zeros(D, dtype=x.dtype))</span><br><span class="line"></span><br><span class="line">    out, cache = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> mode == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">        sample_mean = np.mean(x, axis=<span class="number">0</span>)</span><br><span class="line">        sample_var = np.var(x, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        running_mean = momentum * running_mean + (<span class="number">1</span> - momentum) * sample_mean</span><br><span class="line">        running_var = momentum * running_var + (<span class="number">1</span> - momentum) * sample_var</span><br><span class="line"></span><br><span class="line">        x_norm = (x - sample_mean) / np.sqrt(sample_var + eps)</span><br><span class="line">        out = gamma * x_norm + beta</span><br><span class="line">        cache = x, x_norm, sample_mean, sample_var, gamma, beta, eps</span><br><span class="line">    <span class="keyword">elif</span> mode == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">        x_norm = (x - running_mean) / np.sqrt(running_var + eps)</span><br><span class="line">        out = gamma * x_norm + beta</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&#x27;Invalid forward batchnorm mode &quot;%s&quot;&#x27;</span> % mode)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Store the updated running means back into bn_param</span></span><br><span class="line">    bn_param[<span class="string">&#x27;running_mean&#x27;</span>] = running_mean</span><br><span class="line">    bn_param[<span class="string">&#x27;running_var&#x27;</span>] = running_var</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> out, cache</span><br></pre></td></tr></table></figure><p>backward实现两个版本，我是一个根据未化简公式来计算，另一个是根据化简后公式来计算，对比后明显可以看到化简后大量减少了运算次数，可以达到原来速度的3倍。</p><p>未化简公式版：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batchnorm_backward</span>(<span class="params">dout, cache</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Backward pass for batch normalization.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For this implementation, you should write out a computation graph for</span></span><br><span class="line"><span class="string">    batch normalization on paper and propagate gradients backward through</span></span><br><span class="line"><span class="string">    intermediate nodes.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - dout: Upstream derivatives, of shape (N, D)</span></span><br><span class="line"><span class="string">    - cache: Variable of intermediates from batchnorm_forward.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - dx: Gradient with respect to inputs x, of shape (N, D)</span></span><br><span class="line"><span class="string">    - dgamma: Gradient with respect to scale parameter gamma, of shape (D,)</span></span><br><span class="line"><span class="string">    - dbeta: Gradient with respect to shift parameter beta, of shape (D,)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dx, dgamma, dbeta = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    x, x_norm, sample_mean, sample_var, gamma, beta, eps = cache</span><br><span class="line">    N, D = x_norm.shape</span><br><span class="line"></span><br><span class="line">    dbeta = np.sum(dout, axis=<span class="number">0</span>)</span><br><span class="line">    dgamma = np.sum(x_norm * dout, axis=<span class="number">0</span>)</span><br><span class="line">    dx_norm = dout * gamma</span><br><span class="line">    dL_dvar = <span class="number">-0.5</span> * np.sum(dx_norm * (x - sample_mean), axis=<span class="number">0</span>) * np.power(sample_var + eps, <span class="number">-1.5</span>)</span><br><span class="line">    <span class="comment"># add L--&gt;y--&gt;x_hat--&gt;x_i</span></span><br><span class="line">    dx = dx_norm / np.sqrt(sample_var + eps)</span><br><span class="line">    <span class="comment"># add L--&gt;mean--&gt;x_i</span></span><br><span class="line">    dx += (<span class="number">-1</span>/N) * np.sum(dx_norm / np.sqrt(sample_var + eps), axis=<span class="number">0</span>) + dL_dvar * np.sum(<span class="number">-2</span>*(x - sample_mean)/N, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># add L--&gt;var--&gt;x_i</span></span><br><span class="line">    dx += (<span class="number">2</span> / N) * (x - sample_mean) * dL_dvar</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dx, dgamma, dbeta</span><br></pre></td></tr></table></figure><p>化简公式版：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batchnorm_backward_alt</span>(<span class="params">dout, cache</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Alternative backward pass for batch normalization.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For this implementation you should work out the derivatives for the batch</span></span><br><span class="line"><span class="string">    normalizaton backward pass on paper and simplify as much as possible. You</span></span><br><span class="line"><span class="string">    should be able to derive a simple expression for the backward pass. </span></span><br><span class="line"><span class="string">    See the jupyter notebook for more hints.</span></span><br><span class="line"><span class="string">     </span></span><br><span class="line"><span class="string">    Note: This implementation should expect to receive the same cache variable</span></span><br><span class="line"><span class="string">    as batchnorm_backward, but might not use all of the values in the cache.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs / outputs: Same as batchnorm_backward</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dx, dgamma, dbeta = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    x, x_hat, sample_mean, sample_var, gamma, beta, eps = cache</span><br><span class="line">    N, D = x_hat.shape</span><br><span class="line">    mid = <span class="number">1</span> / np.sqrt(sample_var + eps)</span><br><span class="line">    dbeta = np.sum(dout, axis=<span class="number">0</span>)</span><br><span class="line">    dgamma = np.sum(x_hat * dout, axis=<span class="number">0</span>)</span><br><span class="line">    dxhat = dout * gamma</span><br><span class="line">    dx = (<span class="number">1</span> / N) * mid * (N * dxhat - np.sum(dxhat, axis=<span class="number">0</span>) - x_hat * np.sum(dxhat * x_hat, axis=<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dx, dgamma, dbeta</span><br></pre></td></tr></table></figure><h3 id="Layer-Normalization"><a href="#Layer-Normalization" class="headerlink" title="Layer Normalization"></a>Layer Normalization</h3><p>LN按照如下公式来输出，实际上就是把BN倒过来。。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/19/ugYP7bKtTAvhzOj.png" alt="image-20200819015437962"></p><p>LN的操作类似于将BN做了一个“<strong>转置</strong>”，对同一层网络的输出做一个标准化。注意，同一层的输出是单个图片的输出，比如对于一个batch为32的神经网络训练，会有32个均值和方差被得出，<strong>每个均值和方差都是由单个图片的所有channel之间做一个标准化</strong>。这么操作，就使得LN不受batch size的影响。</p><p>在代码的实现上只需将所有的相关矩阵装置一下就OK啦，即对于转置过来的输入x做BN即可！注意要保证输出的维数正确。</p><p>Layer Normalization Forward：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">layernorm_forward</span>(<span class="params">x, gamma, beta, ln_param</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Forward pass for layer normalization.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    During both training and test-time, the incoming data is normalized per data-point,</span></span><br><span class="line"><span class="string">    before being scaled by gamma and beta parameters identical to that of batch normalization.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Note that in contrast to batch normalization, the behavior during train and test-time for</span></span><br><span class="line"><span class="string">    layer normalization are identical, and we do not need to keep track of running averages</span></span><br><span class="line"><span class="string">    of any sort.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">    - x: Data of shape (N, D)</span></span><br><span class="line"><span class="string">    - gamma: Scale parameter of shape (D,)</span></span><br><span class="line"><span class="string">    - beta: Shift paremeter of shape (D,)</span></span><br><span class="line"><span class="string">    - ln_param: Dictionary with the following keys:</span></span><br><span class="line"><span class="string">        - eps: Constant for numeric stability</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - out: of shape (N, D)</span></span><br><span class="line"><span class="string">    - cache: A tuple of values needed in the backward pass</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    out, cache = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    sample_var = np.var(x.T, axis=<span class="number">0</span>)</span><br><span class="line">    x_norm = (x.T - sample_mean) / np.sqrt(sample_var + eps)</span><br><span class="line">    out = gamma * x_norm.T + beta</span><br><span class="line">    cache = x, x_norm.T, sample_mean, sample_var, gamma, beta, eps</span><br><span class="line">    <span class="keyword">return</span> out, cache</span><br></pre></td></tr></table></figure><p>Layer Normalization Backward：这里我实现了两个版本，分别是基于化简后的公式和未化简后的公式，均通过测试。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">layernorm_backward</span>(<span class="params">dout, cache</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Backward pass for layer normalization.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For this implementation, you can heavily rely on the work you&#x27;ve done already</span></span><br><span class="line"><span class="string">    for batch normalization.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - dout: Upstream derivatives, of shape (N, D)</span></span><br><span class="line"><span class="string">    - cache: Variable of intermediates from layernorm_forward.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - dx: Gradient with respect to inputs x, of shape (N, D)</span></span><br><span class="line"><span class="string">    - dgamma: Gradient with respect to scale parameter gamma, of shape (D,)</span></span><br><span class="line"><span class="string">    - dbeta: Gradient with respect to shift parameter beta, of shape (D,)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dx, dgamma, dbeta = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    x, x_hat, sample_mean, sample_var, gamma, beta, eps = cache</span><br><span class="line">    N, D = x_hat.shape</span><br><span class="line"></span><br><span class="line">    mid = <span class="number">1</span> / np.sqrt(sample_var + eps)</span><br><span class="line">    dbeta = np.sum(dout, axis=<span class="number">0</span>)</span><br><span class="line">    dgamma = np.sum(x_hat * dout, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    dxhat = dout * gamma</span><br><span class="line">    dxhat = dxhat.T</span><br><span class="line">    x_hat = x_hat.T</span><br><span class="line">    dx = (<span class="number">1</span> / D) * mid * (D * dxhat - np.sum(dxhat, axis=<span class="number">0</span>) - x_hat * np.sum(dxhat * x_hat, axis=<span class="number">0</span>))</span><br><span class="line">    dx = dx.T</span><br><span class="line"></span><br><span class="line">    <span class="comment">#####################################################################################</span></span><br><span class="line">    <span class="comment">#    Another vision of  LN backward (based on the origin vision of bn backward)     #</span></span><br><span class="line">    <span class="comment">#####################################################################################</span></span><br><span class="line">    <span class="comment"># x, x_norm, sample_mean, sample_var, gamma, beta, eps = cache</span></span><br><span class="line">    <span class="comment"># N, D = x_norm.shape</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># dbeta = np.sum(dout, axis=0)</span></span><br><span class="line">    <span class="comment"># dgamma = np.sum(x_norm * dout, axis=0)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># x = x.T</span></span><br><span class="line">    <span class="comment"># dout = dout.T</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># dx_norm = dout.T * gamma</span></span><br><span class="line">    <span class="comment"># dx_norm = dx_norm.T</span></span><br><span class="line">    <span class="comment"># dL_dvar = -0.5 * np.sum(dx_norm * (x - sample_mean), axis=0) * np.power(sample_var + eps, -1.5)</span></span><br><span class="line">    <span class="comment"># # add L--&gt;y--&gt;x_hat--&gt;x_i</span></span><br><span class="line">    <span class="comment"># dx = dx_norm / np.sqrt(sample_var + eps)</span></span><br><span class="line">    <span class="comment"># # add L--&gt;mean--&gt;x_i</span></span><br><span class="line">    <span class="comment"># dx += (-1/D) * np.sum(dx_norm / np.sqrt(sample_var + eps), axis=0) + dL_dvar * np.sum(-2*(x - sample_mean)/N, axis=0)</span></span><br><span class="line">    <span class="comment"># # add L--&gt;var--&gt;x_i</span></span><br><span class="line">    <span class="comment"># dx += (2 / D) * (x - sample_mean) * dL_dvar</span></span><br><span class="line">    <span class="comment"># dx = dx.T</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dx, dgamma, dbeta</span><br></pre></td></tr></table></figure><h3 id="BN-vs-LN"><a href="#BN-vs-LN" class="headerlink" title="BN vs LN"></a>BN vs LN</h3><h4 id="BN"><a href="#BN" class="headerlink" title="BN"></a>BN</h4><p>首先是BN，BN是通过mini-batch来对相应的activation做规范化操作，使得输出的各个维度的均值为0，方差为1（标准化）。而最后的“scale and shift”，即加入一个放射变换，则是为了让因训练所需而“刻意”加入的BN能够有可能还原最初的输入，同时也缓解因为数据可能会因此丢失了一些信息，所以再加上beta和gama来恢复原始数据，这里beta和gama是可学习的。</p><p><strong>BN的好处：</strong></p><p>(1) 减轻了对参数、权重初始化的依赖。</p><p>(2) 训练更快，可以使用更高的学习率。</p><p>(3) BN一定程度上增加了泛化能力。</p><p><strong>BN的缺点：</strong></p><p>batch normalization依赖于batch的大小，当batch值很小时，计算的均值和方差不稳定。会引入很多噪声误差，若网络队伍差很敏感，则会难以训练和收敛。</p><p>这一个特性，导致batch normalization不适合以下的几种场景。</p><p>(1)batch非常小，比如训练资源有限无法应用较大的batch。</p><p>(2)RNN，因为它是一个动态的网络结构，即输入的size是不固定的，同一个batch中训练实例有长有短，无法根据BN的公式进行标准化。</p><p>关于Normalization的<strong>有效的原因</strong>：</p><p>Batch Normalization调整了数据的分布，不考虑激活函数，它让每一层的输出归一化到了均值为0方差为1的分布，这保证了梯度的有效性，目前大部分资料都这样解释，比如BN的原始论文认为的缓解了Internal Covariate Shift(ICS)问题。加入了BN的反向传播过程中，就不易出现梯度消失或梯度爆炸，梯度将始终保持在一个合理的范围内。而这样带来的好处就是，基于梯度的训练过程可以更加有效的进行，即加快收敛速度，减轻梯度消失或爆炸导致的无法训练的问题。</p><h4 id="LN"><a href="#LN" class="headerlink" title="LN"></a>LN</h4><p>BN 的一个缺点是需要较大的 batchsize 才能合理估训练数据的均值和方差，这在计算资源比较有限的时候往往不能达到，同时它也很难应用在数据长度不同的 RNN 模型上。Layer Normalization (LN) 的一个优势是不需要批训练，在单条数据内部就能归一化，他是针对于per datapoint的更新。</p><p>整体而言，LN用于RNN效果比较明显，但是在CNN上，不如BN。</p><h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><p>Dropout的代码部分非常简单，material中已经给出了代码实现，只需要实现一下forward和backw以及更新一下计算loss的函数即可。需要注意的是增加loss的部分，这里我使用caches当做<strong>堆栈</strong>存储前向计算loss时产生的caches，这样反向传播时只需要依次pop并根据网络结构计算梯度即可。本部分代码位于：<code>cs231n/classifiers/fc_net.py</code>。 该loss位于为FullyConnectedNet类内。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">self, X, y=None</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute loss and gradient for the fully-connected net.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Input / output: Same as TwoLayerNet above.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    X = X.astype(self.dtype)</span><br><span class="line">    mode = <span class="string">&#x27;test&#x27;</span> <span class="keyword">if</span> y <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="string">&#x27;train&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set train/test mode for batchnorm params and dropout param since they</span></span><br><span class="line">    <span class="comment"># behave differently during training and testing.</span></span><br><span class="line">    <span class="keyword">if</span> self.use_dropout:</span><br><span class="line">        self.dropout_param[<span class="string">&#x27;mode&#x27;</span>] = mode</span><br><span class="line">    <span class="keyword">if</span> self.normalization==<span class="string">&#x27;batchnorm&#x27;</span>:</span><br><span class="line">        <span class="keyword">for</span> bn_param <span class="keyword">in</span> self.bn_params:</span><br><span class="line">            bn_param[<span class="string">&#x27;mode&#x27;</span>] = mode</span><br><span class="line">    scores = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    caches = []</span><br><span class="line">    scores = X</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(self.num_layers):</span><br><span class="line">        W = self.params[<span class="string">&#x27;W&#x27;</span> + str(i+<span class="number">1</span>)]</span><br><span class="line">        b = self.params[<span class="string">&#x27;b&#x27;</span> + str(i+<span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">if</span> i == self.num_layers - <span class="number">1</span>:</span><br><span class="line">            scores, cache = affine_forward(scores, W, b)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> self.normalization <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                scores, cache = affine_relu_forward(scores, W, b)</span><br><span class="line">            <span class="keyword">elif</span> self.normalization == <span class="string">&quot;batchnorm&quot;</span>:</span><br><span class="line">                gamma = self.params[<span class="string">&#x27;gamma&#x27;</span> + str(i + <span class="number">1</span>)]</span><br><span class="line">                beta = self.params[<span class="string">&#x27;beta&#x27;</span> + str(i + <span class="number">1</span>)]</span><br><span class="line">                scores, cache = affine_bn_relu_forward(scores, W, b, gamma, beta, self.bn_params[i])</span><br><span class="line">            <span class="keyword">elif</span> self.normalization == <span class="string">&quot;layernorm&quot;</span>:</span><br><span class="line">                gamma = self.params[<span class="string">&#x27;gamma&#x27;</span> + str(i + <span class="number">1</span>)]</span><br><span class="line">                beta = self.params[<span class="string">&#x27;beta&#x27;</span> + str(i + <span class="number">1</span>)]</span><br><span class="line">                scores, cache = affine_ln_relu_forward(scores, W, b, gamma, beta, self.bn_params[i])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                cache = <span class="literal">None</span></span><br><span class="line">        caches.append(cache)</span><br><span class="line">        <span class="keyword">if</span> self.use_dropout <span class="keyword">and</span> i != self.num_layers<span class="number">-1</span>:</span><br><span class="line">            scores, cache = dropout_forward(scores, self.dropout_param)</span><br><span class="line">            caches.append(cache)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># If test mode return early</span></span><br><span class="line">    <span class="keyword">if</span> mode == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> scores</span><br><span class="line"></span><br><span class="line">    loss, grads = <span class="number">0.0</span>, &#123;&#125;</span><br><span class="line">    reg = self.reg</span><br><span class="line">    loss, dx = softmax_loss(scores, y)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> reversed(range(self.num_layers)):</span><br><span class="line">        w = <span class="string">&#x27;W&#x27;</span> + str(i + <span class="number">1</span>)</span><br><span class="line">        b = <span class="string">&#x27;b&#x27;</span> + str(i + <span class="number">1</span>)</span><br><span class="line">        gamma = <span class="string">&#x27;gamma&#x27;</span> + str(i + <span class="number">1</span>)</span><br><span class="line">        beta = <span class="string">&#x27;beta&#x27;</span> + str(i + <span class="number">1</span>)</span><br><span class="line">        loss += <span class="number">0.5</span> * reg * np.sum(W * W)  <span class="comment"># add reg term</span></span><br><span class="line">        <span class="keyword">if</span> i == self.num_layers - <span class="number">1</span>:</span><br><span class="line">            dx, grads[w], grads[b] = affine_backward(dx, caches.pop())</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> self.use_dropout:</span><br><span class="line">                dx = dropout_backward(dx, caches.pop())</span><br><span class="line">            <span class="keyword">if</span> self.normalization <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                dx, grads[w], grads[b] = affine_relu_backward(dx, caches.pop())</span><br><span class="line">            <span class="keyword">if</span> self.normalization == <span class="string">&#x27;batchnorm&#x27;</span>:</span><br><span class="line">                dx, grads[w], grads[b], grads[gamma], grads[beta] = affine_bn_relu_backward(dx, caches.pop())</span><br><span class="line">            <span class="keyword">if</span> self.normalization == <span class="string">&#x27;layernorm&#x27;</span>:</span><br><span class="line">                dx, grads[w], grads[b], grads[gamma], grads[beta] = affine_ln_relu_backward(dx, caches.pop())</span><br><span class="line">        grads[w] += reg * self.params[w]</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> loss, grads</span><br></pre></td></tr></table></figure><h2 id="Convolutional-Networks"><a href="#Convolutional-Networks" class="headerlink" title="Convolutional Networks"></a>Convolutional Networks</h2><p>这部分就是实现CNN了！核心就是实现好卷积层和pooling层。同时也修改batch normalization以便适用于CNN，同时增加group normalization。</p><h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>由于在实现时并不需要考虑计算复杂度和时间复杂度，我使用了最简单直接的方法，在forward时，同官方给的note一样，每次更新一个激活神经元的值，即使用4层循环嵌套，直观的实现卷积的过程。TODO：向量化方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_forward_naive</span>(<span class="params">x, w, b, conv_param</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    A naive implementation of the forward pass for a convolutional layer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The input consists of N data points, each with C channels, height H and</span></span><br><span class="line"><span class="string">    width W. We convolve each input with F different filters, where each filter</span></span><br><span class="line"><span class="string">    spans all C channels and has height HH and width WW.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">    - x: Input data of shape (N, C, H, W)</span></span><br><span class="line"><span class="string">    - w: Filter weights of shape (F, C, HH, WW)</span></span><br><span class="line"><span class="string">    - b: Biases, of shape (F,)</span></span><br><span class="line"><span class="string">    - conv_param: A dictionary with the following keys:</span></span><br><span class="line"><span class="string">      - &#x27;stride&#x27;: The number of pixels between adjacent receptive fields in the</span></span><br><span class="line"><span class="string">        horizontal and vertical directions.</span></span><br><span class="line"><span class="string">      - &#x27;pad&#x27;: The number of pixels that will be used to zero-pad the input. </span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    During padding, &#x27;pad&#x27; zeros should be placed symmetrically (i.e equally on both sides)</span></span><br><span class="line"><span class="string">    along the height and width axes of the input. Be careful not to modfiy the original</span></span><br><span class="line"><span class="string">    input x directly.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - out: Output data, of shape (N, F, H&#x27;, W&#x27;) where H&#x27; and W&#x27; are given by</span></span><br><span class="line"><span class="string">      H&#x27; = 1 + (H + 2 * pad - HH) / stride</span></span><br><span class="line"><span class="string">      W&#x27; = 1 + (W + 2 * pad - WW) / stride</span></span><br><span class="line"><span class="string">    - cache: (x, w, b, conv_param)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    out = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">    pad = conv_param[<span class="string">&#x27;pad&#x27;</span>]</span><br><span class="line">    stride = conv_param[<span class="string">&#x27;stride&#x27;</span>]</span><br><span class="line">    x_pad = np.pad(x, ((<span class="number">0</span>, <span class="number">0</span>), (<span class="number">0</span>, <span class="number">0</span>), (pad, pad), (pad, pad)), mode=<span class="string">&#x27;constant&#x27;</span>, constant_values=<span class="number">0</span>)</span><br><span class="line">    N, C, H, W = x.shape</span><br><span class="line">    F, C, HH, WW = w.shape</span><br><span class="line">    H_out = int(<span class="number">1</span> + (H + <span class="number">2</span> * pad - HH) / stride)</span><br><span class="line">    W_out = int(<span class="number">1</span> + (W + <span class="number">2</span> * pad - WW) / stride)</span><br><span class="line">    out = np.zeros((N, F, H_out, W_out))</span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> range(N):</span><br><span class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> range(F):</span><br><span class="line">            <span class="keyword">for</span> h <span class="keyword">in</span> range(H_out):</span><br><span class="line">                <span class="keyword">for</span> w_mid <span class="keyword">in</span> range(W_out):</span><br><span class="line">                    out[n, f, h, w_mid] = np.sum(</span><br><span class="line">                        x_pad[n, :, h * stride:h * stride + HH, w_mid * stride:w_mid * stride + WW] * w[f, :, :, :]) + b[f]</span><br><span class="line"></span><br><span class="line">    cache = (x, w, b, conv_param)</span><br><span class="line">    <span class="keyword">return</span> out, cache</span><br></pre></td></tr></table></figure><p>在实现backward时，我也写出了简单情况下更新的公式，并根据这个最简单的展开形式以此来反向求梯度。如下图所示</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/26/7R2qvGbEiOLPgZw.png" alt="image-20200826005100903"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_backward_naive</span>(<span class="params">dout, cache</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    A naive implementation of the backward pass for a convolutional layer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - dout: Upstream derivatives.</span></span><br><span class="line"><span class="string">    - cache: A tuple of (x, w, b, conv_param) as in conv_forward_naive</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - dx: Gradient with respect to x</span></span><br><span class="line"><span class="string">    - dw: Gradient with respect to w</span></span><br><span class="line"><span class="string">    - db: Gradient with respect to b</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dx, dw, db = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    x, w, b, conv_param = cache</span><br><span class="line">    pad = conv_param[<span class="string">&#x27;pad&#x27;</span>]</span><br><span class="line">    stride = conv_param[<span class="string">&#x27;stride&#x27;</span>]</span><br><span class="line">    x_pad = np.pad(x, ((<span class="number">0</span>, <span class="number">0</span>), (<span class="number">0</span>, <span class="number">0</span>), (pad, pad), (pad, pad)), mode=<span class="string">&#x27;constant&#x27;</span>, constant_values=<span class="number">0</span>)</span><br><span class="line">    N, F, H_out, W_out = dout.shape</span><br><span class="line">    F, C, HH, WW = w.shape</span><br><span class="line">    N, C, H, W = x.shape</span><br><span class="line">    dx_pad = np.zeros_like(x_pad)</span><br><span class="line">    dw = np.zeros_like(w)</span><br><span class="line">    db = np.sum(dout, (<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> range(N):</span><br><span class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> range(F):</span><br><span class="line">            <span class="keyword">for</span> h_mid <span class="keyword">in</span> range(H_out):</span><br><span class="line">                <span class="keyword">for</span> w_mid <span class="keyword">in</span> range(W_out):</span><br><span class="line">                    window = x_pad[n, :, stride * h_mid:stride * h_mid + HH, stride * w_mid:stride * w_mid + WW]</span><br><span class="line">                    dx_pad[n, :, stride * h_mid:stride * h_mid + HH, stride * w_mid:stride * w_mid + WW] += \</span><br><span class="line">                        dout[n, f, h_mid, w_mid] * w[f, :, :, :]</span><br><span class="line">                    dw[f, :, :, :] += window * dout[n, f, h_mid, w_mid]</span><br><span class="line">    dx = dx_pad[:, :, pad:pad + H, pad:pad + W]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dx, dw, db</span><br></pre></td></tr></table></figure><h3 id="Max-Pooling"><a href="#Max-Pooling" class="headerlink" title="Max Pooling"></a>Max Pooling</h3><p>forward很简单，只需取respect field中最大的即可；backward时，将取最大值的位置处的梯度直接回传，其余置一即可。比较简单。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_forward_naive</span>(<span class="params">x, pool_param</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    A naive implementation of the forward pass for a max-pooling layer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - x: Input data, of shape (N, C, H, W)</span></span><br><span class="line"><span class="string">    - pool_param: dictionary with the following keys:</span></span><br><span class="line"><span class="string">      - &#x27;pool_height&#x27;: The height of each pooling region</span></span><br><span class="line"><span class="string">      - &#x27;pool_width&#x27;: The width of each pooling region</span></span><br><span class="line"><span class="string">      - &#x27;stride&#x27;: The distance between adjacent pooling regions</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    No padding is necessary here. Output size is given by </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - out: Output data, of shape (N, C, H&#x27;, W&#x27;) where H&#x27; and W&#x27; are given by</span></span><br><span class="line"><span class="string">      H&#x27; = 1 + (H - pool_height) / stride</span></span><br><span class="line"><span class="string">      W&#x27; = 1 + (W - pool_width) / stride</span></span><br><span class="line"><span class="string">    - cache: (x, pool_param)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    out = <span class="literal">None</span></span><br><span class="line">    pool_height = pool_param[<span class="string">&#x27;pool_height&#x27;</span>]</span><br><span class="line">    pool_width = pool_param[<span class="string">&#x27;pool_width&#x27;</span>]</span><br><span class="line">    stride = pool_param[<span class="string">&#x27;stride&#x27;</span>]</span><br><span class="line">    N, C, H, W = x.shape</span><br><span class="line">    H_out = int(<span class="number">1</span> + (H - pool_height) / stride)</span><br><span class="line">    W_out = int(<span class="number">1</span> + (W - pool_width) / stride)</span><br><span class="line">    out = np.zeros((N, C, H_out, W_out))</span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> range(N):</span><br><span class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> range(C):</span><br><span class="line">            <span class="keyword">for</span> h <span class="keyword">in</span> range(H_out):</span><br><span class="line">                <span class="keyword">for</span> w_mid <span class="keyword">in</span> range(W_out):</span><br><span class="line">                    out[n, f, h, w_mid] = np.max(</span><br><span class="line">                        x[n, f, h * stride:h * stride + pool_height, w_mid * stride:w_mid * stride + pool_width])</span><br><span class="line"></span><br><span class="line">    cache = (x, pool_param)</span><br><span class="line">    <span class="keyword">return</span> out, cache</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_backward_naive</span>(<span class="params">dout, cache</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    A naive implementation of the backward pass for a max-pooling layer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - dout: Upstream derivatives</span></span><br><span class="line"><span class="string">    - cache: A tuple of (x, pool_param) as in the forward pass.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    - dx: Gradient with respect to x</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dx = <span class="literal">None</span></span><br><span class="line">    x, pool_param = cache</span><br><span class="line">    pool_height = pool_param[<span class="string">&#x27;pool_height&#x27;</span>]</span><br><span class="line">    pool_width = pool_param[<span class="string">&#x27;pool_width&#x27;</span>]</span><br><span class="line">    stride = pool_param[<span class="string">&#x27;stride&#x27;</span>]</span><br><span class="line">    N, C, H_out, W_out = dout.shape</span><br><span class="line">    dx = np.zeros_like(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> range(N):</span><br><span class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> range(C):</span><br><span class="line">            <span class="keyword">for</span> h_mid <span class="keyword">in</span> range(H_out):</span><br><span class="line">                <span class="keyword">for</span> w_mid <span class="keyword">in</span> range(W_out):</span><br><span class="line">                    window = x[n, f, stride * h_mid:stride * h_mid + pool_height,</span><br><span class="line">                             stride * w_mid:stride * w_mid + pool_width]</span><br><span class="line">                    mask = window == np.max(window)</span><br><span class="line">                    dx[n, f, stride * h_mid:stride * h_mid + pool_height,</span><br><span class="line">                    stride * w_mid:stride * w_mid + pool_width] = mask * dout[n, f, h_mid, w_mid]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dx</span><br></pre></td></tr></table></figure><h3 id="Spatial-Batch-Normalization"><a href="#Spatial-Batch-Normalization" class="headerlink" title="Spatial Batch Normalization"></a>Spatial Batch Normalization</h3><p>实现起来非常简单，只需要重新reshape输入，之后使用之前实现过的正常的Batch Normalization就OK了，代码请看我的github仓库，这部分没有遇到问题。</p><h3 id="Group-Normalization"><a href="#Group-Normalization" class="headerlink" title="Group Normalization"></a>Group Normalization</h3><p>forward只需要稍微修改正常的Batch Normalization即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">spatial_groupnorm_forward</span>(<span class="params">x, gamma, beta, G, gn_param</span>):</span></span><br><span class="line">    out, cache = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    eps = gn_param.get(<span class="string">&#x27;eps&#x27;</span>, <span class="number">1e-5</span>)</span><br><span class="line">    N, C, H, W = x.shape</span><br><span class="line">    x_new = x.reshape((N, G, C // G, H, W))</span><br><span class="line">    mean = np.mean(x_new, axis=(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), keepdims=<span class="literal">True</span>)</span><br><span class="line">    var = np.var(x_new, axis=(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    x_norm = (x_new - mean) / np.sqrt(var + eps)</span><br><span class="line">    x_norm = x_norm.reshape((N, C, H, W))</span><br><span class="line">    gamma_new = gamma.reshape((<span class="number">1</span>, C, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    beta_new = beta.reshape((<span class="number">1</span>, C, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    out = gamma_new * x_norm + beta_new</span><br><span class="line">    cache = G, x, x_norm, mean, var, gamma, beta, eps</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> out, cache</span><br></pre></td></tr></table></figure><p>backward也并不复杂，本质上的求导与正常的batch normalization一致，不过在多个导数求和时，需要注意怎么进行sum。这里如果想要通过Gradient check也有一个小坑。。。 ps: 这里我调试了很久。。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">spatial_groupnorm_backward</span>(<span class="params">dout, cache</span>):</span></span><br><span class="line">    dx, dgamma, dbeta = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    N, C, H, W = dout.shape</span><br><span class="line">    G, x, x_norm, mean, var, gamma, beta, eps = cache</span><br><span class="line"></span><br><span class="line">    dgamma = np.sum(dout * x_norm, axis=(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>)).reshape(<span class="number">1</span>, C, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    x = x.reshape(N, G, C // G, H, W)</span><br><span class="line">    <span class="comment"># 这里想通过Gradientcheck必须需要将其reshape为(1, C, 1, 1)</span></span><br><span class="line">    dbeta = np.sum(dout, axis=(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>)).reshape(<span class="number">1</span>, C, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    dx_norm = (dout * gamma).reshape(N, G, C // G, H, W)</span><br><span class="line">    mean = mean.reshape(N, G, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    var = var.reshape(N, G, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    dL_dvar = <span class="number">-0.5</span> * np.sum(dx_norm * (x - mean), axis=(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)) * np.power(var.squeeze() + eps, <span class="number">-1.5</span>)</span><br><span class="line">    dL_dvar = dL_dvar.reshape(N, G, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    mid = H * W * C // G</span><br><span class="line">    <span class="comment"># add L--&gt;y--&gt;x_hat--&gt;x_i</span></span><br><span class="line">    dx = dx_norm / np.sqrt(var + eps)</span><br><span class="line">    <span class="comment"># add L--&gt;mean--&gt;x_i</span></span><br><span class="line">    dx += ((<span class="number">-1</span> / mid) * np.sum(dx_norm / np.sqrt(var + eps), axis=(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>))).reshape(N, G, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>) + dL_dvar * (</span><br><span class="line">        np.sum(<span class="number">-2</span> * (x - mean) / mid, axis=(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>))).reshape(N, G, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># add L--&gt;var--&gt;x_i</span></span><br><span class="line">    dx += (<span class="number">2</span> / mid) * (x - mean) * dL_dvar</span><br><span class="line">    dx = dx.reshape((N, C, H, W))</span><br><span class="line">    <span class="keyword">return</span> dx, dgamma, dbeta</span><br></pre></td></tr></table></figure><h2 id="PyTorch-on-CIFAR-10"><a href="#PyTorch-on-CIFAR-10" class="headerlink" title="PyTorch on CIFAR-10"></a>PyTorch on CIFAR-10</h2><p>这部分比较简单，我在实现时没有遇到问题。偷了懒，没有实现最后的CIFAR-10 open-ended challenge。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;CS231n-Assignment2-遇到的问题&quot;&gt;&lt;a href=&quot;#CS231n-Assignment2-遇到的问题&quot; class=&quot;headerlink&quot; title=&quot;CS231n Assignment2 遇到的问题&quot;&gt;&lt;/a&gt;CS231n Assignm
      
    
    </summary>
    
    
      <category term="Notes" scheme="http://canVa4.github.io/categories/Notes/"/>
    
    
      <category term="CS231n" scheme="http://canVa4.github.io/tags/CS231n/"/>
    
      <category term="python" scheme="http://canVa4.github.io/tags/python/"/>
    
      <category term="numpy" scheme="http://canVa4.github.io/tags/numpy/"/>
    
  </entry>
  
  <entry>
    <title>单片机解决方案调研</title>
    <link href="http://canva4.github.io/2020/08/12/%E5%8D%95%E7%89%87%E6%9C%BA%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B0%83%E7%A0%94/"/>
    <id>http://canva4.github.io/2020/08/12/%E5%8D%95%E7%89%87%E6%9C%BA%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B0%83%E7%A0%94/</id>
    <published>2020-08-12T02:35:36.000Z</published>
    <updated>2020-09-14T12:36:24.179Z</updated>
    
    <content type="html"><![CDATA[<h1 id="单片机解决方案调研"><a href="#单片机解决方案调研" class="headerlink" title="单片机解决方案调研"></a>单片机解决方案调研</h1><p>目标：<strong>模块化强；底层开发难度低、成本低；低功耗（电池供电）；支持无线通信；具有一定的算力</strong></p><p>本文主要讨论3种不同解决方案。Arduino，stm32和C51系列。列出的这三种都是我有过使用经历的。我经验较多的是stm32，没有用arduino做过比较大型的东西。</p><p>实际上三者并不能直接比较，Arduino算是一个硬件平台，他的早期，也是最广泛的核心是基于AVR单片机（这种芯片我没单独用过）。</p><p>后两者stm32与C51则是两种特定系列的单片机了。</p><table><thead><tr><th></th><th>Arduino</th><th>stm32</th><th>C51</th></tr></thead><tbody><tr><td>模块化</td><td>强（有很多各种各样现成的模块）</td><td>中（配合开发板使用，可以达到部分模块化的效果）</td><td>中（同stm32）</td></tr><tr><td>运算能力</td><td>中、高（一般使用AVR的算力差，现在有支持STM32系列的和esp32的了）</td><td>中、高</td><td>低</td></tr><tr><td>功耗</td><td>低、电池供电足够</td><td>低（极低）、电池供电足够</td><td>极低、电池供电足够</td></tr><tr><td>开发难度</td><td>低、开发速度快、代码易于迭代更新，不必考虑寄存器层面编程</td><td>较高（寄存器复杂，但ST提供封装的的库函数）</td><td>中（硬件资源少，编程难度高）</td></tr><tr><td>价格</td><td>较高</td><td>中</td><td>极低</td></tr><tr><td>支持无线通信</td><td>支持</td><td>支持</td><td>支持</td></tr><tr><td>优点</td><td>开放周期较短，模块化强，代码移植性强，社区丰富</td><td>功能强大，增加功能灵活，社区丰富</td><td>极其便宜，功耗低</td></tr><tr><td>缺点</td><td>扩展模块可选有限；算力有限；</td><td>开发难度大；程序移植性差；</td><td>算力低下，框架老旧</td></tr><tr><td>总结&amp;建议</td><td><strong>可选方案</strong>。方便开发，算力比较OK；但价格较高。</td><td><strong>可选方案</strong>。芯片功能极其强大；但开发周期和难度可能较长。</td><td>不建议使用，如果要批量生成且算力要求不高，可以考虑</td></tr></tbody></table><h2 id="Arduino"><a href="#Arduino" class="headerlink" title="Arduino"></a>Arduino</h2><p>Arduino准确的说是一个单片机及其外设的集合，比较经典板子的主控是ATMEL出的AVR单片机，比51系列性能强一点。这个集合之所以出名在于其操作简单，不需要涉及很多底层、寄存器层面的编程。例如，stm32库函数的一大堆命令，在这里只需要一句即可完成功能，并且有相当丰富的外设模块。</p><p>总体而言做原型，快速开发的时候，硬件搭设方便，基本不用去设计电路板，画板子之类的，基本上导线连接模块就OK了。代码比较简单易懂的。基本不涉及到寄存器级的操作。总得来说就是开发快。小量定制化还是划算，做产品或者较多数量的成本很高；且由于其代码的高度封装会导致程序效率底下以及资源开销大。</p><p>我个人对于Arduino的使用不是很多，还需进一步调研。</p><p>该图为比较常见的Arduino型号的单片机的性能参数。<a href="https://www.arduino.cn/thread-42417-1-1.html">原文链接</a> 原文发布于2017年</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/17/aodKOxTjRWQztpb.jpg" alt="211543xjgg8attjataqkgk"></p><h2 id="STM32系列单片机"><a href="#STM32系列单片机" class="headerlink" title="STM32系列单片机"></a>STM32系列单片机</h2><p>stm32是st半导体公司向arm公司购买了核心(嵌入式)版权，加上自己的外设生产的一个系列的芯片。其特点是：功能强大、速度快、外设多。STM32比较常见的框架是ARM CORTEX-m3或m4。并且其：寄存器复杂，直接用汇编操作比较麻烦，但ST官方了提供封装的的库函数，现在还出了专门的代码生成软件cube来简化操作。</p><p>一个STM32常用型号之间对比：<a href="https://blog.csdn.net/ybhuangfugui/article/details/88266385">https://blog.csdn.net/ybhuangfugui/article/details/88266385</a></p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/17/nkjBiR6fT2lSQb7.jpg" alt="en.microcontrollers_FM141.jpg"></p><p>上图为ST官网对于其系列芯片的简介与分类。</p><p>我对于STM32系列芯片的使用比较有经验，我使用的型号为主要为：STM32F1系列和F4系列。</p><p>STM32F407这款芯片，使我们机器人队使用的主控芯片，其最高主频可达<strong>168MHz</strong>（远远大于Arduino的常见型号的16MHz），可见其算力的强大。</p><p>我们队内并没有使用STM32系列的开发板，而是买了裸的芯片，之后自己设计了电路板（设计部分我不是很擅长），画板子、印板子、焊板子、改板子这样进行开发，导致开发一代新的主控板周期比较长。</p><p>不过市面上也有很多STM32现成的开发板，预留了很多IO接口，初步观察感觉基本满足需求，价格适中，如STM32F4系列的开发板不足100元。使用这种开发板一般也不需要自己设计电路，只需购买不同的模块即可交互使用。</p><center class="half">    <img src= "/img/loading.gif" data-lazy-src=https://i.loli.net/2020/08/17/7DGvqR42cTMiNVA.jpg width="400"/><img src= "/img/loading.gif" data-lazy-src=https://i.loli.net/2020/08/17/gTPjAvzL4KEnIFC.jpg width="400"/> </center><p>左图的为我近期购买的STM32F1系列的的开发板；右图为STM32F4系列的开发板。例如左边的F1开发板，可以看到这种开发板也像Arduino一样支持很多的扩展功能，而且只需要插接即可。</p><p>整体而言，使用STM32系列也绝对可以实现我们的预期目标，使用开发板也基本可以避免电路的设计等工作。由于STM32系列芯片本身功能强大，其上限应该是高于Arduino方案的。但其开发难度会比Arduino方案难上不少。这里指的STM32开发方案是指使用STM32 CUBEMX硬件配置和生成代码模板（HAL库），之后在代码模板上进行开发（一般使用IAR作为IDE）。</p><h2 id="Arduino-与-STM32"><a href="#Arduino-与-STM32" class="headerlink" title="Arduino 与 STM32"></a>Arduino 与 STM32</h2><p>通过进一步的了解，我发现了arduino支持了STM32的开发！即可以使用Arduino的IDE来编程。这样可能会降低部分开发难度。</p><p>github链接<a href="https://github.com/rogerclarkmelbourne/Arduino_STM32">https://github.com/rogerclarkmelbourne/Arduino_STM32</a>。目前支持STM32F4和F1系列，其可以将Stm32F103（主要）系列单片机刷入Arduino的Bootloader，并且使用Arduino的编译器和IDE来完成代码的编写，省去了一大部分配置寄存器和学习的时间，完整的性能和灵活性还有待探究。</p><p>同时也有一个类似于arduino+STM32的project，其链接如下。<a href="https://www.leaflabs.com/maple">https://www.leaflabs.com/maple</a>。该板子在淘宝有售，其芯片使stm32f103 arm cortex-M3 32位处理器，主频最高可达72MHz，远远大于常见的Arduino的8位（AVR）MCU。</p><p>Leaf Maple 是一个类似Arduino的开发平台，使用的Cotrex M3内核的32位MCU，所以要比Arduino的8位（AVR）MCU强悍很多，有更高的主频，更丰富的资源。 Leaf Maple也提供了一个类似Arduino IDE的IDE， 并且很多简单上层函数兼容Arduino的函数库，让移植库和代码变得相当简单。比起使用CubeMX+IAR来开发一个STM32项目，使用leaf maple会节省很多时间，更适合初学者和需要快速原型开发的用户。</p><h2 id="Arduino新品M5Stack（使用esp32）"><a href="#Arduino新品M5Stack（使用esp32）" class="headerlink" title="Arduino新品M5Stack（使用esp32）"></a>Arduino新品M5Stack（使用esp32）</h2><p>Arduino的生态总体来讲还是很好用的，目前了解到一款<strong>模块化极强</strong>，性能出色，上市时间不长的支持Arduino开发平台的开发板。M5系列。</p><p>M5Stack是一种模块化、可堆叠扩展的开发板，每个模块一般为5cmX5cm的尺寸，这也是M5Stack名字的由来。与常规的开发板不同，M5Stack更注重产品形态的完整性，更注重用户的应用场景和研发的简易性，M5没有密密麻麻的飞线，没有错乱无章的接口插头，不需要繁琐的开发流程，简简单单、轻轻松松地完成高质量的电子原型创作。（官方介绍）</p><p>M5Stack主要采用ESP32芯片体系，CORE主机内已集成了240M双核主频CPU（esp32）、 WiFi、蓝牙、2.0寸彩色屏幕LCD、扬声器、按键、TF卡、陀螺仪以及内置电池（部分有）。CORE基本满足一般的功能需求，功能模块Function Module则根据应用的情况选择，比如电机驱动、信号采集、通信等功能。另外，也会配备不同的应用底座及配件，方便用户做出高质量的研发。</p><p><a href="https://github.com/m5stack">官方github</a> 与 <a href="https://m5stack.taobao.com/index.htm?spm=2013.1.w5002-22404213498.2.2149622fvBd0zs">官方淘宝链接</a></p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/27/oXGRIYD8r7OMFq6.jpg" alt="img"></p><p>比如其Basic款。其内含2.4G Wi-Fi和蓝牙4.0。外设接口有Type-c，I2C，GPIO和UART接口（数量较少）。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/27/gRsKaQhdYloI5Ut.png" alt="image-20200827162008345"></p><h2 id="简易方案"><a href="#简易方案" class="headerlink" title="简易方案"></a>简易方案</h2><p>简易方案均假定使用2个加速度传感器，并且保证支持WIFI通信，均基本不需要大量焊接（基本做线之类的还是需要的）</p><table><thead><tr><th></th><th>Arduino(M5Stack)</th><th>STM32</th></tr></thead><tbody><tr><td>CORE MCU Unit</td><td><a href="https://item.taobao.com/item.htm?spm=a1z10.1-c-s.w5003-22404213505.1.582d7ef3sJFgr9&ft=t&id=610634829528&scene=taobao_shop">M5Stack Basic</a> 支持I2C总线，内置WiFi  200￥</td><td><a href="https://detail.tmall.com/item.htm?spm=a220o.1000855.0.0.45dd72b09Nb8ev&id=609293737870&skuId=4571066386420">STM32F103最小开发板 </a> 100￥</td></tr><tr><td>Senor</td><td><a href="https://item.taobao.com/item.htm?spm=a1z10.5-c-s.w4002-22404213529.21.23df38edwHEAwd&id=610411236397">ADXL345三轴加速度</a> * 2 (I2C总线 ±16g 13位分辨率) 30￥</td><td><a href="https://item.taobao.com/item.htm?id=45567315525&ali_refid=a3_430582_1006:1103191143:N:nfpYj0PVRKdxrBfSBLtPWA==:e32ca8378afe7d9c3b105a70f8d92779&ali_trackid=1_e32ca8378afe7d9c3b105a70f8d92779&spm=a230r.1.14.13#detail">MPU6050</a> 三轴加速度+三轴陀螺仪 I2C接口 25￥</td></tr><tr><td>WiFi</td><td></td><td><a href="https://detail.tmall.com/item.htm?id=609757779633&ali_refid=a3_430582_1006:1267360122:N:9/mfWI1BJMLzXLT4ATlUnA==:de4e276b258975c722c4a03cf64e8c17&ali_trackid=1_de4e276b258975c722c4a03cf64e8c17&spm=a230r.1.14.8">ATK-ESP8266</a> 串口转WIFI模块 28￥</td></tr><tr><td>Battery</td><td>内置110mAh 锂电池</td><td><a href="https://item.taobao.com/item.htm?spm=a230r.1.14.137.5c3d9640Qtfoh2&id=546584044959&ns=1&abbucket=18#detail">5V锂电池</a> 20￥</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;单片机解决方案调研&quot;&gt;&lt;a href=&quot;#单片机解决方案调研&quot; class=&quot;headerlink&quot; title=&quot;单片机解决方案调研&quot;&gt;&lt;/a&gt;单片机解决方案调研&lt;/h1&gt;&lt;p&gt;目标：&lt;strong&gt;模块化强；底层开发难度低、成本低；低功耗（电池供电）；支持无线
      
    
    </summary>
    
    
      <category term="Works" scheme="http://canVa4.github.io/categories/Works/"/>
    
    
      <category term="单片机" scheme="http://canVa4.github.io/tags/%E5%8D%95%E7%89%87%E6%9C%BA/"/>
    
      <category term="arduino" scheme="http://canVa4.github.io/tags/arduino/"/>
    
      <category term="STM32" scheme="http://canVa4.github.io/tags/STM32/"/>
    
  </entry>
  
  <entry>
    <title>Python学习杂记(1)</title>
    <link href="http://canva4.github.io/2020/08/08/Python%E5%AD%A6%E4%B9%A0%E6%9D%82%E8%AE%B0-1/"/>
    <id>http://canva4.github.io/2020/08/08/Python%E5%AD%A6%E4%B9%A0%E6%9D%82%E8%AE%B0-1/</id>
    <published>2020-08-08T13:09:52.000Z</published>
    <updated>2020-08-15T13:03:30.917Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Python学习杂记-1"><a href="#Python学习杂记-1" class="headerlink" title="Python学习杂记(1)"></a>Python学习杂记(1)</h1><p>本篇文章是为了记录进一步学习python时遇到的一些问题和相对陌生的知识点。</p><ul><li><p>range()函数返回的是一个独特的“范围类”对象！</p></li><li><p>for 变量 in 字符串|集合|范围|任何可迭代对象:</p><p> <strong>可迭代对象：指该对象中包含一个–iter–方法</strong></p></li><li><p><strong>isinstance()函数</strong>，判断某个变量是否为指定类型的实例，前一个参数是要判断的变量，后一个参数是类型。如：isinstance(2, int)</p></li><li><p>zip()函数，将多个列表压缩为一个zip对象（可迭代对象），这样就可以使用一个循环遍历两个列表</p></li><li><p>reversed()函数：接受序列（元组、列表、区间等），然后返回一个“反序排列”的迭代器，sorted()类似</p></li><li></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Python学习杂记-1&quot;&gt;&lt;a href=&quot;#Python学习杂记-1&quot; class=&quot;headerlink&quot; title=&quot;Python学习杂记(1)&quot;&gt;&lt;/a&gt;Python学习杂记(1)&lt;/h1&gt;&lt;p&gt;本篇文章是为了记录进一步学习python时遇到的一些问题
      
    
    </summary>
    
    
      <category term="Notes" scheme="http://canVa4.github.io/categories/Notes/"/>
    
    
      <category term="python" scheme="http://canVa4.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>CS231n Assignment1 实现时遇到的问题</title>
    <link href="http://canva4.github.io/2020/08/07/CS231n-Assignment1-%E5%AE%9E%E7%8E%B0%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>http://canva4.github.io/2020/08/07/CS231n-Assignment1-%E5%AE%9E%E7%8E%B0%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</id>
    <published>2020-08-07T08:21:14.000Z</published>
    <updated>2020-08-08T13:01:59.970Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CS231n-Assignment1-遇到的问题"><a href="#CS231n-Assignment1-遇到的问题" class="headerlink" title="CS231n Assignment1 遇到的问题"></a>CS231n Assignment1 遇到的问题</h1><ul><li>实现基于2019年版的课程</li><li>主要记录遇到的问题</li></ul><h2 id="Softmax-implement"><a href="#Softmax-implement" class="headerlink" title="Softmax implement"></a>Softmax implement</h2><p>不论是实现softmax，SVM损失函数，二者遇到的问题都比较相似，主要为<strong>导数的推导</strong>和<strong>numpy的使用</strong>。由于softmax的实现稍微复杂一些，这里只记录softmax实现时的问题。</p><h3 id="Gradient"><a href="#Gradient" class="headerlink" title="Gradient"></a>Gradient</h3><p>使用SGD核心的工作就是计算softmax关于权值W的梯度。课程中没有给出推导过程，这里推导一下。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/07/mg9rJC2LzVaAxO3.png" alt="image-20200807173340447"></p><h3 id="Numeric-Stability-Trick"><a href="#Numeric-Stability-Trick" class="headerlink" title="Numeric Stability Trick"></a>Numeric Stability Trick</h3><p>为了防止出现数值计算不稳定，要在计算损失函数式加入修正项（对Gradient无影响）。</p><p>原始为：<img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/07/w469bMc7skBYd52.png" alt="image-20200807174209667" style="zoom:50%;" /></p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/07/t7zyhReGVp6QEi2.png" alt="image-20200807174255380" style="zoom: 80%;" /><h3 id="Implement-with-numpy"><a href="#Implement-with-numpy" class="headerlink" title="Implement with numpy"></a>Implement with numpy</h3><h4 id="Navie-Version"><a href="#Navie-Version" class="headerlink" title="Navie Version"></a>Navie Version</h4><p>给出naive版本的代码。如何计算的示意图已在推导过程中给出。naive版本的代码基本按照推导的公式梳理下来即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax_loss_naive</span>(<span class="params">W, X, y, reg</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Softmax loss function, naive implementation (with loops)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Inputs have dimension D, there are C classes, and we operate on minibatches</span></span><br><span class="line"><span class="string">    of N examples.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - W: A numpy array of shape (D, C) containing weights.</span></span><br><span class="line"><span class="string">    - X: A numpy array of shape (N, D) containing a minibatch of data.</span></span><br><span class="line"><span class="string">    - y: A numpy array of shape (N,) containing training labels; y[i] = c means</span></span><br><span class="line"><span class="string">      that X[i] has label c, where 0 &lt;= c &lt; C.</span></span><br><span class="line"><span class="string">    - reg: (float) regularization strength</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - loss as single float</span></span><br><span class="line"><span class="string">    - gradient with respect to weights W; an array of same shape as W</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Initialize the loss and gradient to zero.</span></span><br><span class="line">    loss = <span class="number">0.0</span></span><br><span class="line">    dW = np.zeros_like(W)</span><br><span class="line"></span><br><span class="line">    num_classes = W.shape[<span class="number">1</span>]</span><br><span class="line">    num_train = X.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_train):</span><br><span class="line">        scores = X[i].dot(W)</span><br><span class="line">        scores -= np.max(scores)    <span class="comment"># 一个数值修正的技巧，防止出现数值不稳定的问题</span></span><br><span class="line">        scores = np.exp(scores)</span><br><span class="line"></span><br><span class="line">        sum_scores = np.sum(scores)        <span class="comment"># 可以简化写法，节省空间，懒得修改了</span></span><br><span class="line">        P = scores / sum_scores</span><br><span class="line">        L = -np.log(P)</span><br><span class="line"></span><br><span class="line">        loss += L[y[i]]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(num_classes):    <span class="comment"># 计算梯度，分类讨论</span></span><br><span class="line">            <span class="keyword">if</span> j == y[i]:</span><br><span class="line">                dW[:, j] += (<span class="number">-1</span> + P[y[i]])*X[i].T</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dW[:, j] += P[j]*X[i].T</span><br><span class="line"></span><br><span class="line">    dW /= num_train</span><br><span class="line">    dW += reg * W</span><br><span class="line">    loss /= num_train</span><br><span class="line">    loss += <span class="number">0.5</span> * reg * np.sum(W * W)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss, dW</span><br></pre></td></tr></table></figure><h4 id="Vectorized-Version"><a href="#Vectorized-Version" class="headerlink" title="Vectorized Version"></a>Vectorized Version</h4><p>向量化版本。这里就有非常多的细节需要注意了。首先还是给出完整代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax_loss_vectorized</span>(<span class="params">W, X, y, reg</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Softmax loss function, vectorized version.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs and outputs are the same as softmax_loss_naive.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Initialize the loss and gradient to zero.</span></span><br><span class="line">    loss = <span class="number">0.0</span></span><br><span class="line">    dW = np.zeros_like(W)</span><br><span class="line"></span><br><span class="line">    num_classes = W.shape[<span class="number">1</span>]</span><br><span class="line">    num_train = X.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    scores = X @ W  <span class="comment"># ( N*C )</span></span><br><span class="line">    scores -= np.max(scores, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    scores = np.exp(scores)</span><br><span class="line">    sum_scores = np.sum(scores, axis=<span class="number">1</span>,keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    P = scores / sum_scores</span><br><span class="line">    L = -np.log(P)</span><br><span class="line">    loss += np.sum(L[np.arange(num_train), y])</span><br><span class="line"></span><br><span class="line">    loss /= num_train</span><br><span class="line">    loss += <span class="number">0.5</span> * reg * np.sum(W * W)   <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算gradient</span></span><br><span class="line">    mid = np.zeros_like(P)  <span class="comment"># 生成一个和P一样的0矩阵</span></span><br><span class="line">    mid[np.arange(num_train), y] = <span class="number">1</span>  <span class="comment"># 对矩阵中Y所对应的部分加一个1，因为一会要构造出需要的梯度计算</span></span><br><span class="line">    dW = X.T @ (-mid + P)</span><br><span class="line">    dW = dW / num_train + reg * W</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss, dW</span><br></pre></td></tr></table></figure><p>首先应该画图明白计算中各个量的关系，以及他们是怎么来的，这个很重要。如下图所示</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/07/Knh24oeJ53Nydqj.png" alt="image-20200807175314544"></p><p>第一处就是在计算Numeric Stability Trick时，要找到每一个输入向量的最大元素，这里注意需要保证keepdims=True。</p><p>其控制了返回数组的shape，这样返回的shape为(N,1)。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scores -= np.max(scores, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>同理在sum时，也要进行类似的处理，这样在归一化时才能work。</p><h4 id="An-Important-Trick"><a href="#An-Important-Trick" class="headerlink" title="An Important Trick!!!"></a>An Important Trick!!!</h4><p>在这里我遇到了不少的问题，主要是numpy使用的不熟练。。。:( 所以特此记录下来。</p><p><strong>L[np.arange(num_train), y] **与 **L[:,y]</strong> 的区别！</p><p>一开始的代码使用的是后者，因为目标就是获得所有行i中，列位置为y[i]的元素。所以想当然的使用了后者。但实际上，后者返回的是所有行x[i]中，x[i,y[j]]的元素！！！</p><p>示例如下：</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/07/dKFBsGk3qzxbV5c.png" alt="image-20200807180256834"></p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/07/QbpEhW9DK63ex1F.png" alt="image-20200807180318182"></p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/07/2meKSxGVvcsb3zA.png" alt="image-20200807180331281"></p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/07/jJGhMKFWD7iTULy.png" alt="image-20200807180431683"></p><p>而**L[np.arange(num_train), y] **则为：</p><p>如果将np.arange(num_train)看为list，则其长度必须与y相同！！！其效果就是二者分别迭代，每次返回二者迭代结果下标位置处的元素。如图所示。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/07/d7nQCOvX8Goue9z.png" alt="image-20200807180731248"></p><p>所以可见，基于我们的需要，后者才能满足要求。</p><h2 id="Two-Layer-Neural-Network"><a href="#Two-Layer-Neural-Network" class="headerlink" title="Two-Layer Neural Network"></a>Two-Layer Neural Network</h2><p>本部分的工作也与之前的部分比较相似，这里遇到主要问题还是如何处理求导的问题。</p><p>由于在这里我也遇到了一些问题，所以再次给出部分求导流程。</p><p>首先先给出网络的结构。</p><h3 id="Gradient-1"><a href="#Gradient-1" class="headerlink" title="Gradient"></a>Gradient</h3><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/07/8yBxLVldSgqsrmZ.png" alt="image-20200807221946519"></p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/07/pb8PvAu7RjhNJHT.png" alt="image-20200807223402245"></p><h3 id="Implement-with-numpy-1"><a href="#Implement-with-numpy-1" class="headerlink" title="Implement with numpy"></a>Implement with numpy</h3><p>下面给出代码实现。由于主要难点就是loss的实现了，之后的SGD和predict函数都非常简单，我没有遇到什么问题，这里只给出遇到了部分问题的loss与grad计算的部分。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">self, X, y=None, reg=<span class="number">0.0</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute the loss and gradients for a two layer fully connected neural</span></span><br><span class="line"><span class="string">    network.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - X: Input data of shape (N, D). Each X[i] is a training sample.</span></span><br><span class="line"><span class="string">    - y: Vector of training labels. y[i] is the label for X[i], and each y[i] is</span></span><br><span class="line"><span class="string">      an integer in the range 0 &lt;= y[i] &lt; C. This parameter is optional; if it</span></span><br><span class="line"><span class="string">      is not passed then we only return scores, and if it is passed then we</span></span><br><span class="line"><span class="string">      instead return the loss and gradients.</span></span><br><span class="line"><span class="string">    - reg: Regularization strength.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    If y is None, return a matrix scores of shape (N, C) where scores[i, c] is</span></span><br><span class="line"><span class="string">    the score for class c on input X[i].</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    If y is not None, instead return a tuple of:</span></span><br><span class="line"><span class="string">    - loss: Loss (data loss and regularization loss) for this batch of training</span></span><br><span class="line"><span class="string">      samples.</span></span><br><span class="line"><span class="string">    - grads: Dictionary mapping parameter names to gradients of those parameters</span></span><br><span class="line"><span class="string">      with respect to the loss function; has the same keys as self.params.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Unpack variables from the params dictionary</span></span><br><span class="line">    W1, b1 = self.params[<span class="string">&#x27;W1&#x27;</span>], self.params[<span class="string">&#x27;b1&#x27;</span>]</span><br><span class="line">    W2, b2 = self.params[<span class="string">&#x27;W2&#x27;</span>], self.params[<span class="string">&#x27;b2&#x27;</span>]</span><br><span class="line">    N, D = X.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute the forward pass</span></span><br><span class="line">    scores = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    h = np.maximum(X @ W1 + b1, <span class="number">0</span>)</span><br><span class="line">    scores = h @ W2 + b2</span><br><span class="line"></span><br><span class="line">    <span class="comment"># If the targets are not given then jump out, we&#x27;re done</span></span><br><span class="line">    <span class="keyword">if</span> y <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> scores</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute the loss</span></span><br><span class="line">    loss = <span class="literal">None</span></span><br><span class="line">    scores = np.exp(scores)</span><br><span class="line">    sum_scores = np.sum(scores, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    P = scores / sum_scores</span><br><span class="line">    L = -np.log(P)</span><br><span class="line">    loss = np.sum(L[np.arange(N), y])</span><br><span class="line"></span><br><span class="line">    loss /= N</span><br><span class="line">    loss += <span class="number">1</span> * reg * (np.sum(W1 * W1) + np.sum(W2 * W2))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backward pass: compute gradients</span></span><br><span class="line">    grads = &#123;&#125;</span><br><span class="line">    <span class="comment"># 计算W2，b2</span></span><br><span class="line">    dscore = P</span><br><span class="line">    dscore[np.arange(N), y] -= <span class="number">1</span></span><br><span class="line">    dscore /= N        <span class="comment"># 这里需要注意！！！</span></span><br><span class="line">    <span class="comment"># 计算梯度时只需要除一次N，这里debug花了很久。。</span></span><br><span class="line">    grads[<span class="string">&#x27;W2&#x27;</span>] = h.T @ dscore + <span class="number">2</span> * reg * W2</span><br><span class="line">    grads[<span class="string">&#x27;b2&#x27;</span>] = np.sum(dscore, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 计算W1，b1</span></span><br><span class="line">    dh = dscore @ W2.T      <span class="comment"># 目标函数对于h的偏导</span></span><br><span class="line">    dh[h &lt;= <span class="number">0</span>] = <span class="number">0</span>          <span class="comment"># 此时dh变为关于w1@x+b1的导数</span></span><br><span class="line">    grads[<span class="string">&#x27;W1&#x27;</span>] = X.T @ dh + <span class="number">2</span> * reg * W1</span><br><span class="line">    grads[<span class="string">&#x27;b1&#x27;</span>] = np.sum(dh, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss, grads</span><br></pre></td></tr></table></figure><p>基本上按照公式并注意矩阵维数和细节就OK了，遇到不太会的画个图就解决了。</p><div class="note warning">            <p>需要注意的是，在除以输入个数的时候，只需要除一次</p>          </div><p>这里一开始没有注意到，我一开始在每次计算梯度的时候都除了N，导致出现了误差，这里居然debug了很久。。</p><h3 id="Parameter-Tuning"><a href="#Parameter-Tuning" class="headerlink" title="Parameter Tuning"></a>Parameter Tuning</h3><p>有点懒，这部分工作没有完成。</p><h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><p>其余的部分（k-Nearest Neighbor classifier, SVM, Higher Level Representations: Image Features）并未遇到很多的问题。具体详情代码见我的github仓库。<a href="https://github.com/canVa4/CS231n-Assignments">https://github.com/canVa4/CS231n-Assignments</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;CS231n-Assignment1-遇到的问题&quot;&gt;&lt;a href=&quot;#CS231n-Assignment1-遇到的问题&quot; class=&quot;headerlink&quot; title=&quot;CS231n Assignment1 遇到的问题&quot;&gt;&lt;/a&gt;CS231n Assignm
      
    
    </summary>
    
    
      <category term="Notes" scheme="http://canVa4.github.io/categories/Notes/"/>
    
    
      <category term="CS231n" scheme="http://canVa4.github.io/tags/CS231n/"/>
    
      <category term="python" scheme="http://canVa4.github.io/tags/python/"/>
    
      <category term="numpy" scheme="http://canVa4.github.io/tags/numpy/"/>
    
  </entry>
  
  <entry>
    <title>SimCLR论文复现</title>
    <link href="http://canva4.github.io/2020/08/06/SimCLR%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/"/>
    <id>http://canva4.github.io/2020/08/06/SimCLR%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/</id>
    <published>2020-08-05T16:31:51.000Z</published>
    <updated>2020-08-08T03:30:00.768Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在开头"><a href="#写在开头" class="headerlink" title="写在开头"></a>写在开头</h2><p>整体的代码使用pytorch实现，基于<a href="https://github.com/sthalles/SimCLR">https://github.com/sthalles/SimCLR</a> （用pytorch实现simCLR中star最多的）实现了Logistic Loss（支持使用欠采样、改变权重和无操作）和margin triplet loss（支持semi-hard mining），并可选LARS（experimental）和ADAM优化。代码框架支持resnet50和resnet18；dataset支持STL10和CIARF10（测试时使用CIARF10）</p><a id="more"></a><p>训练为：<em>run.py</em>；修改训练参数、Loss、数据集等需要修改：<em>config.yaml</em> ；评估使用<em>evluation.py</em>（测试训练分开的原因是因为我租了GPU，用GPU训练，用我的PC测试，这样可以更快一些）</p><p>个人运行环境：win10 + pytorch 1.5 + cuda 10.2（租的GPU 1080ti）</p><table><thead><tr><th>日期</th><th>进度</th></tr></thead><tbody><tr><td>5-19 Tue（基本满课+实验）</td><td>论文阅读，选定使用pytorch实现和决定基于上文链接实现代码</td></tr><tr><td>5-20 Wed</td><td>熟悉基础知识、了解代码整体框架，理解loss function，并进行初步尝试编写loss，未调试</td></tr><tr><td>5-21 Thu（满课+实验）</td><td>写完了evaluation部分</td></tr><tr><td>5-22 Fri（基本满课）</td><td>跑代码，发现只用CPU究极龟速；于是装cuda，结果装了一白天的cuda T.T，晚上测试代码并初步验证loss function是否书写正确；初步移植LARS</td></tr><tr><td>5-23 Sat</td><td>测试三个Loss并尝试调参，尝试使用resnet18作为backbone网络，旁晚开始租了个GPU来跑模型，实现triplet loss(sh)</td></tr><tr><td>5-24 Sun</td><td>调参、修复bug、跑代码、微调loss（Logistic loss增加欠采样和改变权重）</td></tr><tr><td>5-25 Mon</td><td>调参、跑代码</td></tr></tbody></table><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><p>Linear evaluation均使用Logistic Regression，均train from scratch（no pretrain）</p><p>GPU: 1080ti    resnet50训练+测试一次需5.5h；resnet18训练+测试一次需2.6h；总代码运行时间：约75h（包括未列出测试）</p><table><thead><tr><th>batch</th><th>epoch</th><th>out dim</th><th>optimizer</th><th>Loss</th><th>BackBone</th><th>t/m</th><th>CIARF10 Top-1</th></tr></thead><tbody><tr><td>128</td><td>80</td><td>128</td><td>ADAM</td><td>NT-Xent</td><td>resnet50</td><td>0.1</td><td>78.1%</td></tr><tr><td>128</td><td>80</td><td>128</td><td>ADAM</td><td>NT-xent</td><td>resnet50</td><td>0.5</td><td>79.3%</td></tr><tr><td>128</td><td>80</td><td>128</td><td>ADAM</td><td>NT-Xent</td><td>resnet50</td><td>1</td><td>77.2%</td></tr><tr><td>128</td><td>80</td><td>128</td><td>ADAM</td><td>Triplet Loss</td><td>resnet50</td><td>0.4</td><td>65.1%</td></tr><tr><td>128</td><td>80</td><td>128</td><td>ADAM</td><td>Triplet Loss</td><td>resnet50</td><td>0.8</td><td>70.7%</td></tr><tr><td>128</td><td>80</td><td>128</td><td>ADAM</td><td>Triplet Loss(sh)</td><td>resnet50</td><td>0.8</td><td>73.5%</td></tr><tr><td>128</td><td>80</td><td>128</td><td>ADAM</td><td>NT-Logistic(none)</td><td>resnet50</td><td>0.2</td><td>37.5%</td></tr><tr><td>128</td><td>80</td><td>128</td><td>ADAM</td><td>NT-Logistic (sampling)</td><td>resnet50</td><td>0.2</td><td>62.4%</td></tr><tr><td>128</td><td>80</td><td>128</td><td>ADAM</td><td>NT-Logistic (sampling)</td><td>resnet50</td><td>0.5</td><td>69.9%</td></tr><tr><td>128</td><td>80</td><td>128</td><td>ADAM</td><td>NT-Logistic (sampling)</td><td>resnet50</td><td>1</td><td>65.2%</td></tr><tr><td>128</td><td>80</td><td>128</td><td>LARS</td><td>NT-xent</td><td>resnet50</td><td>0.5</td><td>TODO</td></tr><tr><td>128</td><td>80</td><td>128</td><td>ADAM</td><td>NT-xent</td><td>resnet18</td><td>0.5</td><td>71.4%</td></tr><tr><td>128</td><td>80</td><td>128</td><td>ADAM</td><td>NT-Logistic(weight)</td><td>resnet18</td><td>0.2</td><td>66.5%</td></tr></tbody></table><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>对于每一个输入图片，模型会生成两个representation，最终优化的目标可以理解为：同一个batch内来自同一张图片的两个representation的距离近，让来自不同输入图片的representation的距离远。注意，论文中给出的是negative loss function</p><h3 id="Logistic-Loss"><a href="#Logistic-Loss" class="headerlink" title="Logistic Loss"></a>Logistic Loss</h3><p>首先给出论文中的形式（negative loss function）：</p><ul><li>$$ log \sigma(u^Tv^+/\tau) + log\sigma(-u^T v^-/ \tau) $$</li></ul><p>这里对于此公式，我一开始是没有理解的，于是自己尝试推理了一下。</p><p>对于每一个输入样本，模型会生成两个representation，对于一个有N个输入的batch的，就会产生2*N个representation，对于每一对representation计算一个cosine similarity。而每一对representation（下文用 $(i,j)$ 序偶来表示他们）可以根据他们的来源来确定他们label（即：来自同一输入的为正类，来自不同输入的为反类），这样就构成了一个监督任务。</p><p>将这个任务看为监督后，因为论文中提到的这个损失函数的名字是logistic loss，我自然地想到了logistics regression。于是从这个角度入手，来推理这个loss function。</p><p>用$ P(i,j) $表示一对representation为正类的概率。设正类y=1，反类y=0</p><p>那么写出整个数据集的对数似然函数$$ LL(\theta;X)=\sum_{each(i,j)} (y_{(i,j)} logP(i,j)+(1-y_{(i,j)})log(1-P(i,j)) )$$</p><p>对上式化简可以得到：$$ LL(\theta;X)=\sum_{正类} logP(i,j)+\sum_{反类}log(1-P(i,j)) $$</p><p>而cosine similarity并不是一个[0,1]之间的数（或者说没有概率的意义），参照logistics regression，将cosine similarity经过一个sigmoid函数$$ \sigma( \cdot) $$ 之后就变为了一个[0,1之间的数]，而且对于sigmoid有$$ \sigma(-x)=1-\sigma(x) $$,所以有：$$ LL(\theta;X)=\sum_{正类} log[\sigma(sim(i,j))]+\sum_{反类}log[\sigma(-sim(i,j))] , sim(i,j)为(i,j)的相似度指标$$</p><p>只需引入temperature就可将上式变为与论文中公式相同的形式。</p><p>在使用原版loss时，发现最终结果效果很差（见result中的NT-Logistics none）。个人猜测原因如下：</p><ul><li>样本非常不均衡，正例对远远少于反例。</li></ul><p>解决办法：</p><ul><li>对反例样本对使用简单的<em>under-sampling</em>（欠采样）</li><li>对于loss计算时，正反例样本<em>设置不同的权重</em>（效果更好，因为欠采样会丢失部分信息）</li></ul><p>（注：由于训练时间太久，没有来得多次跑weight测试效果）</p><p>代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, zis, zjs</span>):</span></span><br><span class="line">    representations = torch.cat([zjs, zis], dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    similarity_matrix = self.similarity_function(representations, representations)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># filter out the scores from the positive samples</span></span><br><span class="line">    l_pos = torch.diag(similarity_matrix, self.batch_size)</span><br><span class="line">    r_pos = torch.diag(similarity_matrix, -self.batch_size)</span><br><span class="line">    positives = torch.cat([l_pos, r_pos]).view(<span class="number">2</span> * self.batch_size, <span class="number">1</span>)</span><br><span class="line">    negatives = similarity_matrix[self.mask_samples_from_same_repr].view(<span class="number">2</span> * self.batch_size, <span class="number">-1</span>) * <span class="number">-1</span></span><br><span class="line"></span><br><span class="line">    logits_pos = self.sigmoid(positives / self.temperature).log_()</span><br><span class="line">    logits_neg = self.sigmoid(negatives / self.temperature).log_()</span><br><span class="line">    <span class="keyword">if</span> self.method == <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># under-sampling</span></span><br><span class="line">        all_one_vec = np.ones((<span class="number">1</span>, <span class="number">2</span> * self.batch_size,))</span><br><span class="line">        all_zero_vec = np.zeros((<span class="number">1</span>, <span class="number">2</span> * self.batch_size * (<span class="number">2</span> * self.batch_size - <span class="number">3</span>)))</span><br><span class="line">        under_sampling_matrix = np.column_stack((all_one_vec, all_zero_vec)).flatten()</span><br><span class="line">        np.random.shuffle(under_sampling_matrix)</span><br><span class="line">        under_sampling_matrix = torch.tensor(under_sampling_matrix).view(</span><br><span class="line">            (<span class="number">2</span> * self.batch_size, <span class="number">2</span> * self.batch_size - <span class="number">2</span>)).type(torch.bool).to(self.device)</span><br><span class="line"></span><br><span class="line">        logits_neg = logits_neg[under_sampling_matrix]</span><br><span class="line">        loss = torch.sum(logits_pos) + torch.sum(logits_neg)</span><br><span class="line">        <span class="keyword">return</span> -loss</span><br><span class="line">    <span class="keyword">elif</span> self.method == <span class="number">2</span>:</span><br><span class="line">        <span class="comment"># change weight</span></span><br><span class="line">        neg_count = <span class="number">2</span>*self.batch_size*(<span class="number">2</span>*self.batch_size - <span class="number">2</span>)</span><br><span class="line">        pos_count = <span class="number">2</span>*self.batch_size</span><br><span class="line">        loss = neg_count * torch.sum(logits_pos) + pos_count*torch.sum(logits_neg)</span><br><span class="line">        <span class="keyword">return</span> -loss/(pos_count+neg_count)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># none</span></span><br><span class="line">        total_logits = torch.cat((logits_pos, logits_neg), dim=<span class="number">1</span>)</span><br><span class="line">        loss = torch.sum(total_logits)</span><br><span class="line">        <span class="keyword">return</span> -loss</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Margin-Triplet"><a href="#Margin-Triplet" class="headerlink" title="Margin Triplet"></a>Margin Triplet</h3><p>首先给出论文中的形式（negative loss function）：</p><ul><li>$$ -max(u^Tv^–u^Tv^+m,0)$$</li></ul><p>此公式理解起来相对直观，即对于一个输入样本，计算其和一个负样本相似度减去和正样本的相似度在加上m，并与0取max。该m可以理解：m越大为希望正反样本分开的距离越大。其目标是希望输入样本和正样本的相似度减去和负样本的相似度可以大于阈值m值。下图很形象的描述了这些关系。</p><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/08/08/NwCTG5rc3J4D7R9.png" alt="triplet1"></p><p>所以，对于每一个输入样本k，该样本的<strong>margin tripl loss</strong>为$$ \sum_{i}^{所有反类}max(u_k^Tv_i^–u_k^Tv^+m,0) $$</p><p>所以总的loss就是将所有输入样本的loss加起来</p><ul><li><p>$$ \frac{1}{2N*(2N-2)}\sum_{k}^{所有样本}\sum_{i}^{所有反类}max(u_k^Tv_i^–u_k^Tv^++m,0) $$</p></li><li><p>同时也实现了semi-hard negative mining. 即计算loss（梯度）时，只考虑上图中semi-hard negatives的loss。即选择满足：$$ u^Tv^++m&gt;u^Tv^-$$</p></li></ul><p>代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, zis, zjs</span>):</span></span><br><span class="line"> representations = torch.cat([zjs, zis], dim=<span class="number">0</span>)</span><br><span class="line"> similarity_matrix = self.similarity_function(representations, representations)</span><br><span class="line"> <span class="comment"># filter out the scores from the positive samples</span></span><br><span class="line"> l_pos = torch.diag(similarity_matrix, self.batch_size)</span><br><span class="line"> r_pos = torch.diag(similarity_matrix, -self.batch_size)</span><br><span class="line"> positives = torch.cat([l_pos, r_pos]).view(<span class="number">2</span> * self.batch_size, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"> mid = similarity_matrix[self.mask_samples_from_same_repr]</span><br><span class="line"> negatives = mid.view(<span class="number">2</span> * self.batch_size, <span class="number">-1</span>)</span><br><span class="line"> zero = torch.zeros(<span class="number">1</span>).to(self.device)</span><br><span class="line"> triplet_matrix = torch.max(zero, negatives - positives + self.m_param)</span><br><span class="line"> <span class="comment"># max( sim(neg) - sim(pos) + m, 0)</span></span><br><span class="line"> <span class="comment"># 2N,2N-2 每一行代表了对于一个z关于其正类（z+batch）和其他反类的triplet loss</span></span><br><span class="line"> <span class="keyword">if</span> self.semi_hard == <span class="literal">True</span>:</span><br><span class="line">     <span class="comment"># semi-hard</span></span><br><span class="line">     semi_hard = - negatives + positives + self.m_param</span><br><span class="line">     <span class="comment"># print(semi_hard)</span></span><br><span class="line">     semi_hard_mask = torch.max(semi_hard, zero).type(torch.bool)</span><br><span class="line">     <span class="comment"># print(semi_hard_mask)</span></span><br><span class="line">     triplet_matrix_sh = triplet_matrix[semi_hard_mask]</span><br><span class="line">     <span class="comment"># print(triplet_matrix)</span></span><br><span class="line">     <span class="comment"># print(triplet_matrix_sh)</span></span><br><span class="line">     loss = torch.sum(triplet_matrix_sh)</span><br><span class="line">     <span class="keyword">return</span> loss</span><br><span class="line"> <span class="keyword">else</span>:    <span class="comment"># normal</span></span><br><span class="line">     loss = torch.sum(triplet_matrix)     </span><br><span class="line">     <span class="keyword">return</span> loss / (<span class="number">2</span>*self.batch_size*(<span class="number">2</span>*self.batch_size - <span class="number">2</span>))</span><br></pre></td></tr></table></figure><h3 id="NT-Xent"><a href="#NT-Xent" class="headerlink" title="NT-Xent"></a>NT-Xent</h3><p>论文中的形式：</p><ul><li>$$l(i,j)=-log \frac{exp(s_{i,j}/\tau)}{\sum^{2N}<em>{k=1}1</em>{k\not=i}exp(s_{i,j}/\tau)}$$  </li><li>$$ L = \frac{1}{2N} \sum^{N}_{k=1}[l(2k-1,2k)+l(2k,2k-1)]$$</li></ul><p>代码实现未进行修改。</p><h2 id="simCLR模型"><a href="#simCLR模型" class="headerlink" title="simCLR模型"></a>simCLR模型</h2><p>主要使用ResNet-50来实现，参照论文B.9中所写：将Resnet第一个卷积层改为了3*3的Conv，stride=1，并去除第一个max pooling层；在augmentation中去除了Guassian Blur。</p><p>projection head同论文中一样，使用两层的MLP。</p><h2 id="遇到的问题与解决方法"><a href="#遇到的问题与解决方法" class="headerlink" title="遇到的问题与解决方法"></a>遇到的问题与解决方法</h2><p>Q1：使用个人笔记本训练，显存不足，使用cpu训练耗时过久。</p><p>A1：尝试使用过resnet18，仍时间仍很长，最终决定租GPU（1080ti）来训练。</p><p>Q2：训练时发现最终测试结果不好。</p><p>A2：最终控制变量，与未修改的代码对比测试，发现个人版本在sampler的时候不小心去掉了很多的训练样例，已修复为同原版。修复后，基本同原版效果</p><p>Q3：使用LARS效果不好，loss不能稳定下降，震荡严重。（unsolve）</p><p>A3：尝试修改debug，修改学习率，由于时间不足，暂未解决。</p><h2 id="关于Loss的个人想法"><a href="#关于Loss的个人想法" class="headerlink" title="关于Loss的个人想法"></a>关于Loss的个人想法</h2><p>从测试结果和论文结果可以看出，NT-xent的效果更佳。个人认为其主要的优势在于：</p><ul><li>NT-xent（cross entropy）利用的是相对相似度，而其余二者不是。这样可以缓解个别样本差异过大导致的不均衡（感觉类似于input的normalization）。</li><li>NT-xent计算了所有positive pair的loss。而NT-logistic和Margin Triplet则使用全部的pair来计算，不使用semi-hard mining的话，可能会造成坍塌。对于此模型生成的样本，可以看到其样本类别并不均衡，对于NT-logistic，这可能会导致训练效果下降。（使用semi-hard negative mining、采样、改变权重可以缓解这个问题）</li></ul><p>经过自己的implement之后，实在是羡慕google的TPU集群了！</p><p>这是我第一次真正接触self-supervised learning，之前只是有所耳闻，感觉这种contrastive learning的想法真的很有趣。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;写在开头&quot;&gt;&lt;a href=&quot;#写在开头&quot; class=&quot;headerlink&quot; title=&quot;写在开头&quot;&gt;&lt;/a&gt;写在开头&lt;/h2&gt;&lt;p&gt;整体的代码使用pytorch实现，基于&lt;a href=&quot;https://github.com/sthalles/SimCLR&quot;&gt;https://github.com/sthalles/SimCLR&lt;/a&gt; （用pytorch实现simCLR中star最多的）实现了Logistic Loss（支持使用欠采样、改变权重和无操作）和margin triplet loss（支持semi-hard mining），并可选LARS（experimental）和ADAM优化。代码框架支持resnet50和resnet18；dataset支持STL10和CIARF10（测试时使用CIARF10）&lt;/p&gt;
    
    </summary>
    
    
      <category term="Papers" scheme="http://canVa4.github.io/categories/Papers/"/>
    
    
      <category term="论文复现" scheme="http://canVa4.github.io/tags/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/"/>
    
  </entry>
  
  <entry>
    <title>First test Blog</title>
    <link href="http://canva4.github.io/2020/08/05/First-test-Blog/"/>
    <id>http://canva4.github.io/2020/08/05/First-test-Blog/</id>
    <published>2020-08-05T15:54:29.000Z</published>
    <updated>2020-08-05T15:57:36.175Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第一个测试博客！！！"><a href="#第一个测试博客！！！" class="headerlink" title="第一个测试博客！！！"></a>第一个测试博客！！！</h1><p>语无伦次语无伦次语无伦次</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;第一个测试博客！！！&quot;&gt;&lt;a href=&quot;#第一个测试博客！！！&quot; class=&quot;headerlink&quot; title=&quot;第一个测试博客！！！&quot;&gt;&lt;/a&gt;第一个测试博客！！！&lt;/h1&gt;&lt;p&gt;语无伦次语无伦次语无伦次&lt;/p&gt;

      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://canva4.github.io/2020/08/05/hello-world/"/>
    <id>http://canva4.github.io/2020/08/05/hello-world/</id>
    <published>2020-08-05T15:41:38.862Z</published>
    <updated>2020-08-05T15:41:38.862Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for
      
    
    </summary>
    
    
    
  </entry>
  
</feed>
