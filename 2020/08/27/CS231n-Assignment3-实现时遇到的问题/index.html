<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>CS231n Assignment3 遇到的问题 | Xiang's Blog</title><meta name="description" content="CS231n Assignment3 遇到的问题 实现基于2019年版的课程 主要记录遇到的问题  我的assignment的github仓库，包含全部的代码和notebook。 Image Captioning with RNNs本部分主要是实现RNN的基础版本。即如下的RNN，不过需要注意的是在代码中实现时要注意矩阵相乘的顺序。  首先是每次time step时的forward的backwar"><meta name="keywords" content="CS231n,python,numpy"><meta name="author" content="阿翔"><meta name="copyright" content="阿翔"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/assets/Radiohead.jpg"><link rel="canonical" href="http://canva4.github.io/2020/08/27/CS231n-Assignment3-%E5%AE%9E%E7%8E%B0%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="article"><meta property="og:title" content="CS231n Assignment3 遇到的问题"><meta property="og:url" content="http://canva4.github.io/2020/08/27/CS231n-Assignment3-%E5%AE%9E%E7%8E%B0%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"><meta property="og:site_name" content="Xiang's Blog"><meta property="og:description" content="CS231n Assignment3 遇到的问题 实现基于2019年版的课程 主要记录遇到的问题  我的assignment的github仓库，包含全部的代码和notebook。 Image Captioning with RNNs本部分主要是实现RNN的基础版本。即如下的RNN，不过需要注意的是在代码中实现时要注意矩阵相乘的顺序。  首先是每次time step时的forward的backwar"><meta property="og:image" content="https://i.loli.net/2020/08/07/mFLqAkHvWTX97tS.png"><meta property="article:published_time" content="2020-08-27T09:04:38.000Z"><meta property="article:modified_time" content="2020-09-13T09:23:11.892Z"><meta name="twitter:card" content="summary"><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: {"limitCount":50,"languages":{"author":"作者: 阿翔","link":"链接: ","source":"来源: Xiang's Blog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: false    
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2020-09-13 17:23:11'
}</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img {
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 5.0.0"><link rel="alternate" href="/atom.xml" title="Xiang's Blog" type="application/atom+xml"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" data-lazy-src="https://i.loli.net/2020/09/06/hCrie9pkUMQRzsg.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">16</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">21</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">4</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div id="body-wrap"><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#CS231n-Assignment3-%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">1.</span> <span class="toc-text">CS231n Assignment3 遇到的问题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Image-Captioning-with-RNNs"><span class="toc-number">1.1.</span> <span class="toc-text">Image Captioning with RNNs</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Image-Captioning-with-LSTMs"><span class="toc-number">1.2.</span> <span class="toc-text">Image Captioning with LSTMs</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Network-Visualization-PyTorch"><span class="toc-number">1.3.</span> <span class="toc-text">Network Visualization (PyTorch)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Style-Transfer"><span class="toc-number">1.4.</span> <span class="toc-text">Style Transfer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Content-Loss"><span class="toc-number">1.4.1.</span> <span class="toc-text">Content Loss</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Style-Loss"><span class="toc-number">1.4.2.</span> <span class="toc-text">Style Loss</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Total-variation-regularization"><span class="toc-number">1.4.3.</span> <span class="toc-text">Total-variation regularization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Over-ALL"><span class="toc-number">1.4.4.</span> <span class="toc-text">Over ALL</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GAN"><span class="toc-number">1.5.</span> <span class="toc-text">GAN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#END"><span class="toc-number">1.6.</span> <span class="toc-text">END</span></a></li></ol></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://i.loli.net/2020/08/07/mFLqAkHvWTX97tS.png)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">Xiang's Blog</a></span><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">CS231n Assignment3 遇到的问题</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-08-27T09:04:38.000Z" title="发表于 2020-08-27 17:04:38">2020-08-27</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-09-13T09:23:11.892Z" title="更新于 2020-09-13 17:23:11">2020-09-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Notes/">Notes</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="CS231n-Assignment3-遇到的问题"><a href="#CS231n-Assignment3-遇到的问题" class="headerlink" title="CS231n Assignment3 遇到的问题"></a>CS231n Assignment3 遇到的问题</h1><ul>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><li>实现基于2019年版的课程</li>
<li>主要记录遇到的问题</li>
</ul>
<p>我的assignment的<a target="_blank" rel="noopener" href="https://github.com/canVa4/CS231n-Assignments">github仓库</a>，包含全部的代码和notebook。</p>
<h2 id="Image-Captioning-with-RNNs"><a href="#Image-Captioning-with-RNNs" class="headerlink" title="Image Captioning with RNNs"></a>Image Captioning with RNNs</h2><p>本部分主要是实现RNN的基础版本。即如下的RNN，不过需要注意的是在代码中实现时要注意矩阵相乘的顺序。</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/03/FQu3U9OsD5gtvYi.png" alt="image-20200903233248910"></p>
<p>首先是每次time step时的forward的backward，这里比较简单，按照上图公式implement一下就ok了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_step_forward</span>(<span class="params">x, prev_h, Wx, Wh, b</span>):</span></span><br><span class="line">    next_h, cache = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    next_h = np.tanh(np.dot(prev_h, Wh) + np.dot(x, Wx) + b)</span><br><span class="line">    cache = Wx, Wh, next_h, prev_h, x, b</span><br><span class="line">    <span class="keyword">return</span> next_h, cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_step_backward</span>(<span class="params">dnext_h, cache</span>):</span></span><br><span class="line">    dx, dprev_h, dWx, dWh, db = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    Wx, Wh, next_h, prev_h, x, b = cache</span><br><span class="line">    dmid = (<span class="number">1</span> - np.square(next_h)) * dnext_h</span><br><span class="line">    dprev_h = np.dot(dmid, Wh.T)</span><br><span class="line">    dx = np.dot(dmid, Wx.T)</span><br><span class="line">    dWh = np.dot(prev_h.T, dmid)</span><br><span class="line">    dWx = np.dot(x.T, dmid)</span><br><span class="line">    db = np.sum(dmid, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> dx, dprev_h, dWx, dWh, db</span><br></pre></td></tr></table></figure>

<p>然后是在一定time sequence上的forward和backward，forward就是多层step forward的叠加，backward计算梯度就是将每次对x的梯度持续回传，将对W权值矩阵的梯度叠加即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_forward</span>(<span class="params">x, h0, Wx, Wh, b</span>):</span></span><br><span class="line">    h, cache = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    N, T, D = x.shape</span><br><span class="line">    cache = []</span><br><span class="line">    h = np.zeros((N, T, h0.shape[<span class="number">1</span>]))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(T):</span><br><span class="line">        h0, c = rnn_step_forward(x[:, i, :], h0, Wx, Wh, b)</span><br><span class="line">        h[:, i] += h0</span><br><span class="line">        cache.append(c)</span><br><span class="line">    <span class="keyword">return</span> h, cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_backward</span>(<span class="params">dh, cache</span>):</span></span><br><span class="line">    dx, dh0, dWx, dWh, db = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    N, T, H = dh.shape</span><br><span class="line">    D = cache[<span class="number">0</span>][<span class="number">0</span>].shape[<span class="number">0</span>]</span><br><span class="line">    dx = np.zeros((N, T, D))</span><br><span class="line">    dh0 = np.zeros((N, H))</span><br><span class="line">    dWx = np.zeros((D, H))</span><br><span class="line">    dWh = np.zeros((H, H))</span><br><span class="line">    db = np.zeros((H,))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> reversed(range(T)):</span><br><span class="line">        dx[:, i], dh0, dWx_mid, dWh_mid, db_mid = rnn_step_backward(dh[:, i] + dh0, cache.pop())</span><br><span class="line">        dWx += dWx_mid</span><br><span class="line">        dWh += dWh_mid</span><br><span class="line">        db += db_mid</span><br><span class="line">    <span class="keyword">return</span> dx, dh0, dWx, dWh, db</span><br></pre></td></tr></table></figure>

<p>实现这些基本核心组件后，还需要实现的就是根据word 生成 embedding，这里使用的是类似于查询的方法，有一个对应的生成embedding的矩阵，这个也是可以学习的。forward很简单，就是类似的查询，backward的实现我遇到了实现上的问题，最后借鉴了一下别人的code。:)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">word_embedding_forward</span>(<span class="params">x, W</span>):</span></span><br><span class="line">    out, cache = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    out = W[x]</span><br><span class="line">    cache = x, W</span><br><span class="line">    <span class="keyword">return</span> out, cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">word_embedding_backward</span>(<span class="params">dout, cache</span>):</span></span><br><span class="line">    dW = <span class="literal">None</span></span><br><span class="line">    x, W = cache</span><br><span class="line">    dW = np.zeros_like(W)</span><br><span class="line">    N, T, D = dout.shape</span><br><span class="line">    np.add.at(dW, x.flatten(), dout.reshape(<span class="number">-1</span>, D))     <span class="comment"># 这里借鉴了一下别人的代码</span></span><br><span class="line">    <span class="keyword">return</span> dW</span><br></pre></td></tr></table></figure>

<p>最后要实现的就是class RNN了。这个部分只要认真看代码中的提升，注意下细节根据流程和之前实现好的模块实现即可了。</p>
<p><strong>forward 函数</strong>，位于<code>rnn.py</code> rnn类内。这里的处理是将caption分为两部分：captions_in除了最后一个单词外，所有内容都将被输入到RNN； 而captions_out只不包含第一个单词。这就是期望RNN生成的东西。 它们彼此相对偏移一个，因为RNN在接收到单词t之后会产生单词（t + 1）。 captions_in的第一个元素将是START caption，我们的期望是captions_out的第一个元素将是第一个单词。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">self, features, captions</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute training-time loss for the RNN. We input image features and</span></span><br><span class="line"><span class="string">    ground-truth captions for those images, and use an RNN (or LSTM) to compute</span></span><br><span class="line"><span class="string">    loss and gradients on all parameters.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - features: Input image features, of shape (N, D)</span></span><br><span class="line"><span class="string">    - captions: Ground-truth captions; an integer array of shape (N, T) where</span></span><br><span class="line"><span class="string">      each element is in the range 0 &lt;= y[i, t] &lt; V</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - loss: Scalar loss</span></span><br><span class="line"><span class="string">    - grads: Dictionary of gradients parallel to self.params</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Cut captions into two pieces: captions_in has everything but the last word</span></span><br><span class="line">    <span class="comment"># and will be input to the RNN; captions_out has everything but the first</span></span><br><span class="line">    <span class="comment"># word and this is what we will expect the RNN to generate. These are offset</span></span><br><span class="line">    <span class="comment"># by one relative to each other because the RNN should produce word (t+1)</span></span><br><span class="line">    <span class="comment"># after receiving word t. The first element of captions_in will be the START</span></span><br><span class="line">    <span class="comment"># token, and the first element of captions_out will be the first word.</span></span><br><span class="line">    captions_in = captions[:, :<span class="number">-1</span>]</span><br><span class="line">    captions_out = captions[:, <span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># You&#x27;ll need this</span></span><br><span class="line">    mask = (captions_out != self._null)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Weight and bias for the affine transform from image features to initial</span></span><br><span class="line">    <span class="comment"># hidden state</span></span><br><span class="line">    W_proj, b_proj = self.params[<span class="string">&#x27;W_proj&#x27;</span>], self.params[<span class="string">&#x27;b_proj&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Word embedding matrix</span></span><br><span class="line">    W_embed = self.params[<span class="string">&#x27;W_embed&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Input-to-hidden, hidden-to-hidden, and biases for the RNN</span></span><br><span class="line">    Wx, Wh, b = self.params[<span class="string">&#x27;Wx&#x27;</span>], self.params[<span class="string">&#x27;Wh&#x27;</span>], self.params[<span class="string">&#x27;b&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Weight and bias for the hidden-to-vocab transformation.</span></span><br><span class="line">    W_vocab, b_vocab = self.params[<span class="string">&#x27;W_vocab&#x27;</span>], self.params[<span class="string">&#x27;b_vocab&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    loss, grads = <span class="number">0.0</span>, &#123;&#125;</span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Implement the forward and backward passes for the CaptioningRNN.   #</span></span><br><span class="line">    <span class="comment"># In the forward pass you will need to do the following:                   #</span></span><br><span class="line">    <span class="comment"># (1) Use an affine transformation to compute the initial hidden state     #</span></span><br><span class="line">    <span class="comment">#     from the image features. This should produce an array of shape (N, H)#</span></span><br><span class="line">    <span class="comment"># (2) Use a word embedding layer to transform the words in captions_in     #</span></span><br><span class="line">    <span class="comment">#     from indices to vectors, giving an array of shape (N, T, W).         #</span></span><br><span class="line">    <span class="comment"># (3) Use either a vanilla RNN or LSTM (depending on self.cell_type) to    #</span></span><br><span class="line">    <span class="comment">#     process the sequence of input word vectors and produce hidden state  #</span></span><br><span class="line">    <span class="comment">#     vectors for all timesteps, producing an array of shape (N, T, H).    #</span></span><br><span class="line">    <span class="comment"># (4) Use a (temporal) affine transformation to compute scores over the    #</span></span><br><span class="line">    <span class="comment">#     vocabulary at every timestep using the hidden states, giving an      #</span></span><br><span class="line">    <span class="comment">#     array of shape (N, T, V).                                            #</span></span><br><span class="line">    <span class="comment"># (5) Use (temporal) softmax to compute loss using captions_out, ignoring  #</span></span><br><span class="line">    <span class="comment">#     the points where the output word is &lt;NULL&gt; using the mask above.     #</span></span><br><span class="line">    <span class="comment">#                                                                          #</span></span><br><span class="line">    <span class="comment"># In the backward pass you will need to compute the gradient of the loss   #</span></span><br><span class="line">    <span class="comment"># with respect to all model parameters. Use the loss and grads variables   #</span></span><br><span class="line">    <span class="comment"># defined above to store loss and gradients; grads[k] should give the      #</span></span><br><span class="line">    <span class="comment"># gradients for self.params[k].                                            #</span></span><br><span class="line">    <span class="comment">#                                                                          #</span></span><br><span class="line">    <span class="comment"># Note also that you are allowed to make use of functions from layers.py   #</span></span><br><span class="line">    <span class="comment"># in your implementation, if needed.                                       #</span></span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">    caches = []</span><br><span class="line">    out, cache = affine_forward(features, W_proj, b_proj)</span><br><span class="line">    caches.append(cache)</span><br><span class="line">    word_in, cache = word_embedding_forward(captions_in, W_embed)</span><br><span class="line">    caches.append(cache)</span><br><span class="line">    <span class="keyword">if</span> self.cell_type == <span class="string">&#x27;rnn&#x27;</span>:  <span class="comment"># must rnn or lstm</span></span><br><span class="line">        out, cache = rnn_forward(word_in, out, Wx, Wh, b)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        out, cache = lstm_forward(word_in, out, Wx, Wh, b)</span><br><span class="line">    caches.append(cache)</span><br><span class="line">    out, cache = temporal_affine_forward(out, W_vocab, b_vocab)</span><br><span class="line">    caches.append(cache)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backward</span></span><br><span class="line">    loss, dx = temporal_softmax_loss(out, captions_out, mask)</span><br><span class="line"></span><br><span class="line">    dx, grads[<span class="string">&#x27;W_vocab&#x27;</span>], grads[<span class="string">&#x27;b_vocab&#x27;</span>] = temporal_affine_backward(dx, caches.pop())</span><br><span class="line">    <span class="keyword">if</span> self.cell_type == <span class="string">&#x27;rnn&#x27;</span>:</span><br><span class="line">        d_caption, dx, grads[<span class="string">&#x27;Wx&#x27;</span>], grads[<span class="string">&#x27;Wh&#x27;</span>], grads[<span class="string">&#x27;b&#x27;</span>] = rnn_backward(dx, caches.pop())</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        d_caption, dx, grads[<span class="string">&#x27;Wx&#x27;</span>], grads[<span class="string">&#x27;Wh&#x27;</span>], grads[<span class="string">&#x27;b&#x27;</span>] = lstm_backward(dx, caches.pop())</span><br><span class="line">    grads[<span class="string">&#x27;W_embed&#x27;</span>] = word_embedding_backward(d_caption, caches.pop())</span><br><span class="line">    _, grads[<span class="string">&#x27;W_proj&#x27;</span>], grads[<span class="string">&#x27;b_proj&#x27;</span>] = affine_backward(dx, caches.pop())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="comment">#                             END OF YOUR CODE                             #</span></span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss, grads</span><br></pre></td></tr></table></figure>

<p><strong>sample 函数</strong>，位于<code>rnn.py</code> rnn类内。其要实现的效果如下图所示。</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/03/AtirSuRMczObNC9.png" alt="image-20200903234531509"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample</span>(<span class="params">self, features, max_length=<span class="number">30</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Run a test-time forward pass for the model, sampling captions for input</span></span><br><span class="line"><span class="string">    feature vectors.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    At each timestep, we embed the current word, pass it and the previous hidden</span></span><br><span class="line"><span class="string">    state to the RNN to get the next hidden state, use the hidden state to get</span></span><br><span class="line"><span class="string">    scores for all vocab words, and choose the word with the highest score as</span></span><br><span class="line"><span class="string">    the next word. The initial hidden state is computed by applying an affine</span></span><br><span class="line"><span class="string">    transform to the input image features, and the initial word is the &lt;START&gt;</span></span><br><span class="line"><span class="string">    token.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For LSTMs you will also have to keep track of the cell state; in that case</span></span><br><span class="line"><span class="string">    the initial cell state should be zero.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - features: Array of input image features of shape (N, D).</span></span><br><span class="line"><span class="string">    - max_length: Maximum length T of generated captions.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    - captions: Array of shape (N, max_length) giving sampled captions,</span></span><br><span class="line"><span class="string">      where each element is an integer in the range [0, V). The first element</span></span><br><span class="line"><span class="string">      of captions should be the first sampled word, not the &lt;START&gt; token.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    N = features.shape[<span class="number">0</span>]</span><br><span class="line">    captions = self._null * np.ones((N, max_length), dtype=np.int32)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Unpack parameters</span></span><br><span class="line">    W_proj, b_proj = self.params[<span class="string">&#x27;W_proj&#x27;</span>], self.params[<span class="string">&#x27;b_proj&#x27;</span>]</span><br><span class="line">    W_embed = self.params[<span class="string">&#x27;W_embed&#x27;</span>]</span><br><span class="line">    Wx, Wh, b = self.params[<span class="string">&#x27;Wx&#x27;</span>], self.params[<span class="string">&#x27;Wh&#x27;</span>], self.params[<span class="string">&#x27;b&#x27;</span>]</span><br><span class="line">    W_vocab, b_vocab = self.params[<span class="string">&#x27;W_vocab&#x27;</span>], self.params[<span class="string">&#x27;b_vocab&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">###########################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Implement test-time sampling for the model. You will need to      #</span></span><br><span class="line">    <span class="comment"># initialize the hidden state of the RNN by applying the learned affine   #</span></span><br><span class="line">    <span class="comment"># transform to the input image features. The first word that you feed to  #</span></span><br><span class="line">    <span class="comment"># the RNN should be the &lt;START&gt; token; its value is stored in the         #</span></span><br><span class="line">    <span class="comment"># variable self._start. At each timestep you will need to do to:          #</span></span><br><span class="line">    <span class="comment"># (1) Embed the previous word using the learned word embeddings           #</span></span><br><span class="line">    <span class="comment"># (2) Make an RNN step using the previous hidden state and the embedded   #</span></span><br><span class="line">    <span class="comment">#     current word to get the next hidden state.                          #</span></span><br><span class="line">    <span class="comment"># (3) Apply the learned affine transformation to the next hidden state to #</span></span><br><span class="line">    <span class="comment">#     get scores for all words in the vocabulary                          #</span></span><br><span class="line">    <span class="comment"># (4) Select the word with the highest score as the next word, writing it #</span></span><br><span class="line">    <span class="comment">#     (the word index) to the appropriate slot in the captions variable   #</span></span><br><span class="line">    <span class="comment">#                                                                         #</span></span><br><span class="line">    <span class="comment"># For simplicity, you do not need to stop generating after an &lt;END&gt; token #</span></span><br><span class="line">    <span class="comment"># is sampled, but you can if you want to.                                 #</span></span><br><span class="line">    <span class="comment">#                                                                         #</span></span><br><span class="line">    <span class="comment"># HINT: You will not be able to use the rnn_forward or lstm_forward       #</span></span><br><span class="line">    <span class="comment"># functions; you&#x27;ll need to call rnn_step_forward or lstm_step_forward in #</span></span><br><span class="line">    <span class="comment"># a loop.                                                                 #</span></span><br><span class="line">    <span class="comment">#                                                                         #</span></span><br><span class="line">    <span class="comment"># <span class="doctag">NOTE:</span> we are still working over minibatches in this function. Also if   #</span></span><br><span class="line">    <span class="comment"># you are using an LSTM, initialize the first cell state to zeros.        #</span></span><br><span class="line">    <span class="comment">###########################################################################</span></span><br><span class="line">    <span class="comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">    next_h, _ = affine_forward(features, W_proj, b_proj)</span><br><span class="line">    next_c = np.zeros((N, W_proj.shape[<span class="number">1</span>]))</span><br><span class="line">    word = self._start * np.ones((N,), dtype=np.int32)</span><br><span class="line">    <span class="comment"># generate start token</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(max_length):</span><br><span class="line">        word, _ = word_embedding_forward(word, W_embed)</span><br><span class="line">        <span class="comment"># embed the word to vector</span></span><br><span class="line">        <span class="keyword">if</span> self.cell_type == <span class="string">&#x27;rnn&#x27;</span>:</span><br><span class="line">            next_h, _ = rnn_step_forward(word, next_h, Wx, Wh, b)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            next_h, next_c, _ = lstm_step_forward(word, next_h, next_c, Wx, Wh, b)</span><br><span class="line"></span><br><span class="line">        out, _ = affine_forward(next_h, W_vocab, b_vocab)</span><br><span class="line">        <span class="comment"># get the output</span></span><br><span class="line">        word = out.argmax(axis=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># sample</span></span><br><span class="line">        captions[:, i] = word</span><br><span class="line">    <span class="comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span></span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="comment">#                             END OF YOUR CODE                             #</span></span><br><span class="line">    <span class="comment">############################################################################</span></span><br><span class="line">    <span class="keyword">return</span> captions</span><br></pre></td></tr></table></figure>

<h2 id="Image-Captioning-with-LSTMs"><a href="#Image-Captioning-with-LSTMs" class="headerlink" title="Image Captioning with LSTMs"></a>Image Captioning with LSTMs</h2><p>本部分主要就是将vanilla RNN变为LSTM在重复上述的任务。</p>
<p>首先是forward，根据公式敲一下就ok了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_step_forward</span>(<span class="params">x, prev_h, prev_c, Wx, Wh, b</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Forward pass for a single timestep of an LSTM.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The input data has dimension D, the hidden state has dimension H, and we use</span></span><br><span class="line"><span class="string">    a minibatch size of N.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Note that a sigmoid() function has already been provided for you in this file.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - x: Input data, of shape (N, D)</span></span><br><span class="line"><span class="string">    - prev_h: Previous hidden state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - prev_c: previous cell state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - Wx: Input-to-hidden weights, of shape (D, 4H)</span></span><br><span class="line"><span class="string">    - Wh: Hidden-to-hidden weights, of shape (H, 4H)</span></span><br><span class="line"><span class="string">    - b: Biases, of shape (4H,)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - next_h: Next hidden state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - next_c: Next cell state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - cache: Tuple of values needed for backward pass.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    next_h, next_c, cache = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    N, H = prev_h.shape</span><br><span class="line">    a = np.dot(x, Wx) + np.dot(prev_h, Wh) + b</span><br><span class="line">    i = sigmoid(a[:, :H])</span><br><span class="line">    f = sigmoid(a[:, H:<span class="number">2</span>*H])</span><br><span class="line">    o = sigmoid(a[:, <span class="number">2</span>*H:<span class="number">3</span>*H])</span><br><span class="line">    g = np.tanh(a[:, <span class="number">3</span>*H:])</span><br><span class="line">    next_c = f * prev_c + i * g</span><br><span class="line">    next_h = o * np.tanh(next_c)</span><br><span class="line">    cache = i, f, o, g, next_c, Wh, Wx, prev_c, prev_h, x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> next_h, next_c, cache</span><br></pre></td></tr></table></figure>

<p>经历过那么多次求导，出现的问题越来越少了，实现起来也比较顺畅，下面给出我整理后的求导过程。</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/06/Z4HB6QspSybWL9A.png" alt="image-20200906111112135"></p>
<p>然后就是敲一下代码了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_step_backward</span>(<span class="params">dnext_h, dnext_c, cache</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Backward pass for a single timestep of an LSTM.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - dnext_h: Gradients of next hidden state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - dnext_c: Gradients of next cell state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - cache: Values from the forward pass</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - dx: Gradient of input data, of shape (N, D)</span></span><br><span class="line"><span class="string">    - dprev_h: Gradient of previous hidden state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - dprev_c: Gradient of previous cell state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - dWx: Gradient of input-to-hidden weights, of shape (D, 4H)</span></span><br><span class="line"><span class="string">    - dWh: Gradient of hidden-to-hidden weights, of shape (H, 4H)</span></span><br><span class="line"><span class="string">    - db: Gradient of biases, of shape (4H,)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dx, dprev_h, dprev_c, dWx, dWh, db = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    i, f, o, g, next_c, Wh, Wx, prev_c, prev_h, x = cache</span><br><span class="line">    dprev_c = dnext_c * f + dnext_h * o * f * (<span class="number">1</span> - np.tanh(next_c)**<span class="number">2</span>)</span><br><span class="line">    dc = dnext_c + (<span class="number">1</span> - np.tanh(next_c)**<span class="number">2</span>) * o * dnext_h     <span class="comment"># 这里遇到了问题</span></span><br><span class="line">    di = dc * g * i * (<span class="number">1</span> - i)</span><br><span class="line">    df = dc * prev_c * f * (<span class="number">1</span> - f)</span><br><span class="line">    do = dnext_h * np.tanh(next_c) * o * (<span class="number">1</span> - o)</span><br><span class="line">    dg = dc * i * (<span class="number">1</span> - g**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    da = np.hstack((di, df, do, dg))</span><br><span class="line">    dprev_h = np.dot(da, Wh.T)</span><br><span class="line">    dx = np.dot(da, Wx.T)</span><br><span class="line">    db = np.sum(da, axis=<span class="number">0</span>)</span><br><span class="line">    dWx = np.dot(x.T, da)</span><br><span class="line">    dWh = np.dot(prev_h.T, da)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dx, dprev_h, dprev_c, dWx, dWh, db</span><br></pre></td></tr></table></figure>

<p>接下来就是对于一个sequence而不是单独的time step使用LSTM了。首先是forward</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_forward</span>(<span class="params">x, h0, Wx, Wh, b</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Forward pass for an LSTM over an entire sequence of data. We assume an input</span></span><br><span class="line"><span class="string">    sequence composed of T vectors, each of dimension D. The LSTM uses a hidden</span></span><br><span class="line"><span class="string">    size of H, and we work over a minibatch containing N sequences. After running</span></span><br><span class="line"><span class="string">    the LSTM forward, we return the hidden states for all timesteps.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Note that the initial cell state is passed as input, but the initial cell</span></span><br><span class="line"><span class="string">    state is set to zero. Also note that the cell state is not returned; it is</span></span><br><span class="line"><span class="string">    an internal variable to the LSTM and is not accessed from outside.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - x: Input data of shape (N, T, D)</span></span><br><span class="line"><span class="string">    - h0: Initial hidden state of shape (N, H)</span></span><br><span class="line"><span class="string">    - Wx: Weights for input-to-hidden connections, of shape (D, 4H)</span></span><br><span class="line"><span class="string">    - Wh: Weights for hidden-to-hidden connections, of shape (H, 4H)</span></span><br><span class="line"><span class="string">    - b: Biases of shape (4H,)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - h: Hidden states for all timesteps of all sequences, of shape (N, T, H)</span></span><br><span class="line"><span class="string">    - cache: Values needed for the backward pass.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    h, cache = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    N, T, D = x.shape</span><br><span class="line">    N, H = h0.shape</span><br><span class="line">    h = np.zeros((N, T, H))</span><br><span class="line">    cache = []</span><br><span class="line">    c0 = np.zeros_like(h0)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(T):</span><br><span class="line">        h0, c0, c = lstm_step_forward(x[:, i, :], h0, c0, Wx, Wh, b)</span><br><span class="line">        h[:, i, :] = h0</span><br><span class="line">        cache.append(c)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> h, cache</span><br></pre></td></tr></table></figure>

<div class="note warning">
            <p>需要注意的是，在backward时，如何传递梯度：up stream的当前time step的loss + 上一个step step传回来的loss</p>
          </div>

<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_backward</span>(<span class="params">dh, cache</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Backward pass for an LSTM over an entire sequence of data.]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - dh: Upstream gradients of hidden states, of shape (N, T, H)</span></span><br><span class="line"><span class="string">    - cache: Values from the forward pass</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - dx: Gradient of input data of shape (N, T, D)</span></span><br><span class="line"><span class="string">    - dh0: Gradient of initial hidden state of shape (N, H)</span></span><br><span class="line"><span class="string">    - dWx: Gradient of input-to-hidden weight matrix of shape (D, 4H)</span></span><br><span class="line"><span class="string">    - dWh: Gradient of hidden-to-hidden weight matrix of shape (H, 4H)</span></span><br><span class="line"><span class="string">    - db: Gradient of biases, of shape (4H,)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dx, dh0, dWx, dWh, db = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    N, T, H = dh.shape</span><br><span class="line">    _, D = cache[<span class="number">0</span>][<span class="number">-1</span>].shape    <span class="comment"># cache[0][-1]对应x</span></span><br><span class="line">    dx = np.zeros((N, T, D))</span><br><span class="line">    dc = np.zeros((N, H))</span><br><span class="line">    dWx = np.zeros((D, <span class="number">4</span> * H))</span><br><span class="line">    dWh = np.zeros((H, <span class="number">4</span> * H))</span><br><span class="line">    db = np.zeros((<span class="number">4</span> * H,))</span><br><span class="line">    dh0 = np.zeros((N, H))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> reversed(range(T)):</span><br><span class="line">        dx[:, i, :], dh0, dc, dWx_, dWh_, db_ = lstm_step_backward(dh[:, i, :] + dh0, dc, cache.pop())</span><br><span class="line">        db += db_</span><br><span class="line">        dWx += dWx_</span><br><span class="line">        dWh += dWh_</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dx, dh0, dWx, dWh, db</span><br></pre></td></tr></table></figure>

<p>剩下的部分就比较ez了，只需对于上一个task的代码稍作修改即可，具体的代码就不再列出。</p>
<h2 id="Network-Visualization-PyTorch"><a href="#Network-Visualization-PyTorch" class="headerlink" title="Network Visualization (PyTorch)"></a>Network Visualization (PyTorch)</h2><p>本部分主要实现<strong>Saliency Maps,  Fooling image, Class visualization</strong> 三种的实现本质都是计算输入图片的梯度，Saliency Map是直接将关于正确label的loss的梯度的绝对值显示出来；Fooling Image 则是利用梯度信息，将一个A类别的输入变为网络识别为B类别；Class Visualization则是输入一个噪声，使用gradient ascent利用梯度信息将该图片在期望变成的类别下，神经网络的输出的期望类别的class score最大。由于使用pytorch，可以直接计算grad，整体实现比较简单，理解好这几个过程就可以了。代码部分不再单独给出，详情见我的github仓库。</p>
<div class="note warning">
            <p>在代码运行时，可能会遇到使用numpy.load()函数报错的情况，提示需要将allow_pickle=Ture，此时只需要在该np.load的参数内加入‘allow_pickle=True’即可。具体细节可见<code>cs231n/data_utils.py/load_imagenet_val</code></p>
          </div>

<h2 id="Style-Transfer"><a href="#Style-Transfer" class="headerlink" title="Style Transfer"></a>Style Transfer</h2><p>本部分就是实现style transfer的部分了！难度不高，核心就是实现好3个loss，并将整个流程梳理下来即可。实现后真的非常好玩！</p>
<p>首先是Style Transfer（2016）整体的框图</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/10/6FYEV92PxcUlXDH.png" alt="image-20200910100801040"></p>
<p>从图中就可以看出，包含两个loss，分别是：style image每层的每个filter的activation map的gram matrix（用来衡量相似性）和input image的gram matrix之间产生的loss（<strong>Style Loss</strong>）和 input image和content image之间的差异性（<strong>Content Loss</strong>）。最后为了使生成的图片更加真实，会加入一个正则项，这里使用的是<strong>Total-variation regularization</strong>。所以最终的loss就是：**Style Loss+Content Loss + Total-variation regularization **。之后使用这个loss计算输入图片的梯度，并使用Adam或者SDG等方法更新输入图片即可。</p>
<p>提取特征的网络使用的是squeeze net，因为其模型参数少，运算快且性能适中。</p>
<h3 id="Content-Loss"><a href="#Content-Loss" class="headerlink" title="Content Loss"></a>Content Loss</h3><p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/10/3cBroD8hxIkadGQ.png" alt="image-20200910101647611"></p>
<p>比较简单，如框图所示，就是将input image和content image在某一层的activation map做一下reshape，从1*C*H<em>W变为1\</em>C*(H*W)即可。相减后逐元素平方再求和即可。代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">content_loss</span>(<span class="params">content_weight, content_current, content_original</span>):</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Compute the content loss for style transfer.</span></span><br><span class="line"><span class="string">Inputs:</span></span><br><span class="line"><span class="string">- content_weight: Scalar giving the weighting for the content loss.</span></span><br><span class="line"><span class="string">- content_current: features of the current image; this is a PyTorch Tensor of shape</span></span><br><span class="line"><span class="string">  (1, C_l, H_l, W_l).</span></span><br><span class="line"><span class="string">- content_target: features of the content image, Tensor with shape (1, C_l, H_l, W_l).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">- scalar content loss</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">    loss = content_weight * torch.sum(torch.square(content_current.squeeze() - content_original.squeeze()))</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
<h3 id="Style-Loss"><a href="#Style-Loss" class="headerlink" title="Style Loss"></a>Style Loss</h3><p>稍微复杂一点，核心就是计算一个Gram matrix，该矩阵用来衡量similarity。下图为Gram matrix计算的示意图。</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/10/LSUCjJ5Y19N2AtF.png" alt="image-20200910102135973"></p>
<p>左边是某一层的activation map，之后将其变为C*(H*W)，所有行向量直接做內积，就有了C*C的gram matrix。</p>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gram_matrix</span>(<span class="params">features, normalize=True</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute the Gram matrix from features.</span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - features: PyTorch Tensor of shape (N, C, H, W) giving features for</span></span><br><span class="line"><span class="string">      a batch of N images.</span></span><br><span class="line"><span class="string">    - normalize: optional, whether to normalize the Gram matrix</span></span><br><span class="line"><span class="string">        If True, divide the Gram matrix by the number of neurons (H * W * C)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    - gram: PyTorch Tensor of shape (N, C, C) giving the</span></span><br><span class="line"><span class="string">      (optionally normalized) Gram matrices for the N input images.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    N,C,H,W = features.size()</span><br><span class="line">    new_features = features.reshape((N,C,H*W))</span><br><span class="line">    gram_mat = torch.zeros(N,C,C)</span><br><span class="line">    gram_mat = torch.bmm(new_features, new_features.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">if</span> normalize:</span><br><span class="line">        <span class="keyword">return</span> gram_mat / (H*W*C)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> gram_matm</span><br></pre></td></tr></table></figure>
<p>之后就是如框图所示，将style image各层的gram matrix和input image各层的gram matrix相减后逐元素平方再求和即可。代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">style_loss</span>(<span class="params">feats, style_layers, style_targets, style_weights</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Computes the style loss at a set of layers.</span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - feats: list of the features at every layer of the current image, as produced by</span></span><br><span class="line"><span class="string">      the extract_features function.</span></span><br><span class="line"><span class="string">    - style_layers: List of layer indices into feats giving the layers to include in the</span></span><br><span class="line"><span class="string">      style loss.</span></span><br><span class="line"><span class="string">    - style_targets: List of the same length as style_layers, where style_targets[i] is</span></span><br><span class="line"><span class="string">      a PyTorch Tensor giving the Gram matrix of the source style image computed at</span></span><br><span class="line"><span class="string">      layer style_layers[i].</span></span><br><span class="line"><span class="string">    - style_weights: List of the same length as style_layers, where style_weights[i]</span></span><br><span class="line"><span class="string">      is a scalar giving the weight for the style loss at layer style_layers[i].</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    - style_loss: A PyTorch Tensor holding a scalar giving the style loss.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    tensor = torch.tensor(())</span><br><span class="line">    loss = tensor.new_zeros(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(style_layers)):</span><br><span class="line">        gram_mat = gram_matrix(feats[style_layers[i]])</span><br><span class="line">        loss += style_weights[i] * torch.sum((gram_mat - style_targets[i]).square())</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
<h3 id="Total-variation-regularization"><a href="#Total-variation-regularization" class="headerlink" title="Total-variation regularization"></a>Total-variation regularization</h3><p>该项是一个正则化项，公式如下：</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/10/FXuz216PhIvrbx9.png" alt="image-20200910102605899"></p>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tv_loss</span>(<span class="params">img, tv_weight</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute total variation loss.</span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - img: PyTorch Variable of shape (1, 3, H, W) holding an input image.</span></span><br><span class="line"><span class="string">    - tv_weight: Scalar giving the weight w_t to use for the TV loss.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    - loss: PyTorch Variable holding a scalar giving the total variation loss</span></span><br><span class="line"><span class="string">      for img weighted by tv_weight.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    loss = tv_weight * (torch.sum((img[<span class="number">0</span>,:,<span class="number">1</span>:,:] - img[<span class="number">0</span>,:,:<span class="number">-1</span>,:]).square()) + torch.sum((img[<span class="number">0</span>,:,:,<span class="number">1</span>:] - img[<span class="number">0</span>,:,:,:<span class="number">-1</span>]).square()))</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
<h3 id="Over-ALL"><a href="#Over-ALL" class="headerlink" title="Over ALL"></a>Over ALL</h3><p>完成的上面的部分后就是整合了，note book中的代码已经给出。不再赘述。值得注意的是，使用同样的代码，我们还可以完成<strong>Feature Inversion</strong>和<strong>texture synthesis</strong>这两个任务。对于<strong>texture synthesis</strong>，只需将content loss置零即可。对于<strong>Feature Inversion</strong>只需将style loss置零即可。下面是一些自己测试的结果。</p>
<div class="fig figcenter fighighlight">
  <img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/10/MojOJTfCVnYA46L.png" width="30%">
  <img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/10/BrTLcfMZoCpSU98.png" width="20%" style="border-left: 1px solid black;">
  <div class="figcaption">Style Transfer Left: Style img and Input img. Right: result(200 iteration).</div>
</div>

<div class="fig figcenter fighighlight">
  <img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/10/yLZAnhrJ5VItsux.png" width="30%">
  <img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/09/10/enD34UK7J1oqut5.png" width="20%" style="border-left: 1px solid black;">
  <div class="figcaption">texture synthesis Left: Style img. Right: result(200 iteration).</div>
</div>

<h2 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h2><p>本部分的GAN实现了报过最原始的2014年 GoodFellow的原始GAN，以及Last Square GAN（优化了损失函数）和Deep Convolutional GANs。整体来讲使用pytorch建立模型和训练都比较简单，note book中主要实现的就是discriminator和generator的loss，将这个实现好即可。这部分的难度不是很高，就不再列出了，具体代码和结果可以参考我的github仓库。</p>
<h2 id="END"><a href="#END" class="headerlink" title="END"></a>END</h2><p>至此，整个CS231n的课程就结束啦！为期了一个多月，中间因为各种事前耽误了几天，本来计划1个月内就搞定的。感觉CS231n课程整体来讲的难度适中，在数学推倒部分设计的稍微少了一些，但可以建立很多intuition的东西，总之还是收获颇丰的。</p>
<p>最大的收获就是他的assignment了，有一定难度的同时也极大的加深了对于这些知识的理解。</p>
<p>TODO：</p>
<ul>
<li>下一步可能会写一个GAN相关的小总结。</li>
<li>看一些more mathematic的东西</li>
</ul>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">阿翔</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://canva4.github.io/2020/08/27/CS231n-Assignment3-%E5%AE%9E%E7%8E%B0%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/">http://canva4.github.io/2020/08/27/CS231n-Assignment3-%E5%AE%9E%E7%8E%B0%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://canVa4.github.io" target="_blank">Xiang's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/CS231n/">CS231n</a><a class="post-meta__tags" href="/tags/python/">python</a><a class="post-meta__tags" href="/tags/numpy/">numpy</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2020/08/07/mFLqAkHvWTX97tS.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/09/14/%E5%8D%95%E7%89%87%E6%9C%BA%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B0%83%E7%A0%94%EF%BC%882%EF%BC%89/"><img class="prev-cover" data-lazy-src="https://i.loli.net/2020/08/07/pKzI96f48mHGYdQ.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">单片机解决方案调研（2）</div></div></a></div><div class="next-post pull-right"><a href="/2020/08/12/CS231n-Assignment2-%E5%AE%9E%E7%8E%B0%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"><img class="next-cover" data-lazy-src="https://i.loli.net/2020/08/07/mFLqAkHvWTX97tS.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">CS231n Assignment2 实现时遇到的问题</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/08/07/CS231n-Assignment1-实现时遇到的问题/" title="CS231n Assignment1 实现时遇到的问题"><img class="relatedPosts_cover" data-lazy-src="https://i.loli.net/2020/08/07/mFLqAkHvWTX97tS.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fas fa-history fa-fw"></i> 2020-08-08</div><div class="relatedPosts_title">CS231n Assignment1 实现时遇到的问题</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/12/CS231n-Assignment2-实现时遇到的问题/" title="CS231n Assignment2 实现时遇到的问题"><img class="relatedPosts_cover" data-lazy-src="https://i.loli.net/2020/08/07/mFLqAkHvWTX97tS.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fas fa-history fa-fw"></i> 2020-08-26</div><div class="relatedPosts_title">CS231n Assignment2 实现时遇到的问题</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/08/Python学习杂记-1/" title="Python学习杂记(1)"><img class="relatedPosts_cover" data-lazy-src="https://i.loli.net/2020/08/08/SFMvY6R41egqPCA.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fas fa-history fa-fw"></i> 2020-08-15</div><div class="relatedPosts_title">Python学习杂记(1)</div></div></a></div></div></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By 阿翔</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my Blog~</div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font_plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font_minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  var script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({{ JSON.stringify(config) }});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="{{ src }}">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end --></body></html>